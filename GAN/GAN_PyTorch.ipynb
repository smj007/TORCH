{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GAN - PyTorch",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "6tWrvB7kJp0C",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "961a12f3-c394-4866-ecbb-29712e7babc3"
      },
      "source": [
        "%tensorflow_version 2.x\n",
        "import tensorflow as tf\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  raise SystemError('GPU device not found')\n",
        "print('Found GPU at: {}'.format(device_name))"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found GPU at: /device:GPU:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rNOuxo5LT3NO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "16f25131-c2e3-41e4-f689-29d6d8d6453b"
      },
      "source": [
        "# %tensorflow_version 2.x\n",
        "# import tensorflow as tf\n",
        "# import timeit\n",
        "\n",
        "# device_name = tf.test.gpu_device_name()\n",
        "# if device_name != '/device:GPU:0':\n",
        "#   print(\n",
        "#       '\\n\\nThis error most likely means that this notebook is not '\n",
        "#       'configured to use a GPU.  Change this in Notebook Settings via the '\n",
        "#       'command palette (cmd/ctrl-shift-P) or the Edit menu.\\n\\n')\n",
        "#   raise SystemError('GPU device not found')\n",
        "\n",
        "# def cpu():\n",
        "#   with tf.device('/cpu:0'):\n",
        "#     random_image_cpu = tf.random.normal((100, 100, 100, 3))\n",
        "#     net_cpu = tf.keras.layers.Conv2D(32, 7)(random_image_cpu)\n",
        "#     return tf.math.reduce_sum(net_cpu)\n",
        "\n",
        "# def gpu():\n",
        "#   with tf.device('/device:GPU:0'):\n",
        "#     random_image_gpu = tf.random.normal((100, 100, 100, 3))\n",
        "#     net_gpu = tf.keras.layers.Conv2D(32, 7)(random_image_gpu)\n",
        "#     return tf.math.reduce_sum(net_gpu)\n",
        "  \n",
        "# # We run each op once to warm up; see: https://stackoverflow.com/a/45067900\n",
        "# cpu()\n",
        "# gpu()\n",
        "\n",
        "# # Run the op several times.\n",
        "# print('Time (s) to convolve 32x7x7x3 filter over random 100x100x100x3 images '\n",
        "#       '(batch x height x width x channel). Sum of ten runs.')\n",
        "# print('CPU (s):')\n",
        "# cpu_time = timeit.timeit('cpu()', number=10, setup=\"from __main__ import cpu\")\n",
        "# print(cpu_time)\n",
        "# print('GPU (s):')\n",
        "# gpu_time = timeit.timeit('gpu()', number=10, setup=\"from __main__ import gpu\")\n",
        "# print(gpu_time)\n",
        "# print('GPU speedup over CPU: {}x'.format(int(cpu_time/gpu_time)))"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Time (s) to convolve 32x7x7x3 filter over random 100x100x100x3 images (batch x height x width x channel). Sum of ten runs.\n",
            "CPU (s):\n",
            "3.13971086499987\n",
            "GPU (s):\n",
            "0.1043293469992932\n",
            "GPU speedup over CPU: 30x\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gMQp8cGGVnx2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.parallel\n",
        "import torch.optim as optim\n",
        "import torch.utils.data\n",
        "import torchvision.datasets as dset\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.utils as vutils\n",
        "from torch.autograd import Variable"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sVhvkkgqWVTt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size = 64\n",
        "image_size = 64 #64x64 is the image size"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qEfrsuarWpsJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "transform = transforms.Compose([transforms.Resize(image_size),\n",
        "                                transforms.ToTensor(),\n",
        "                                transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZLFIce0TXLNd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "3e266038-e489-4f60-a1e8-f873772f25cd"
      },
      "source": [
        "dataset = dset.CIFAR10(root = './data', download = True, transform = transform)\n",
        "dataloader = torch.utils.data.DataLoader(dataset, batch_size = batch_size, shuffle = True, num_workers=2)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GfjDOF_PJ_B0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "17ef9526-8db5-4842-c792-066cfc64f04b"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lvp9A0qIKd4e",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9e8d2d78-efb1-4fcb-87fd-e83b4c62dcfe"
      },
      "source": [
        "import os\n",
        "os.chdir('/content/drive/My Drive/GAN')\n",
        "os.getcwd()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/drive/My Drive/GAN'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mz5EsJN_YALz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def weights_init(m):    #m is a neural network \n",
        "    classname = m.__class__.__name__\n",
        "    if classname.find('Conv') != -1:\n",
        "        m.weight.data.normal_(0.0, 0.02)\n",
        "\n",
        "    elif classname.find('BatchNorm') != -1:\n",
        "        m.weight.data.normal_(1.0, 0.02)\n",
        "        m.bias.data.fill_(0)    "
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hCXP5Kl5ZaTK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 332
        },
        "outputId": "47e24815-186e-4bb6-be7f-5ed5a215cb6a"
      },
      "source": [
        "class G(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super(G, self).__init__()\n",
        "        self.main = nn.Sequential(\n",
        "            nn.ConvTranspose2d(100, 512, 4, 1, 0, bias = False), #100 dims for random noise ip (channel dims)\n",
        "            nn.BatchNorm2d(512),\n",
        "            nn.ReLU(True),\n",
        "            nn.ConvTranspose2d(512, 256, 4, 2, 1, bias = False),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.ReLU(True),\n",
        "            nn.ConvTranspose2d(256, 128, 4, 2, 1, bias = False),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.ReLU(True),\n",
        "            nn.ConvTranspose2d(128, 64, 4, 2, 1, bias = False),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(True),\n",
        "            nn.ConvTranspose2d(64, 3, 4, 2, 1, bias = False),\n",
        "            nn.Tanh()\n",
        "        ) \n",
        "\n",
        "    def forward(self, input):\n",
        "        output = self.main(input)\n",
        "        return output\n",
        "\n",
        "netG = G()\n",
        "netG.apply(weights_init)\n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "G(\n",
              "  (main): Sequential(\n",
              "    (0): ConvTranspose2d(100, 512, kernel_size=(4, 4), stride=(1, 1), bias=False)\n",
              "    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (2): ReLU(inplace=True)\n",
              "    (3): ConvTranspose2d(512, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "    (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (5): ReLU(inplace=True)\n",
              "    (6): ConvTranspose2d(256, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "    (7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (8): ReLU(inplace=True)\n",
              "    (9): ConvTranspose2d(128, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "    (10): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (11): ReLU(inplace=True)\n",
              "    (12): ConvTranspose2d(64, 3, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "    (13): Tanh()\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xn2JCkC4mfb_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 314
        },
        "outputId": "b5b3b0ae-e401-4fd2-bcc1-8f00d0a1221f"
      },
      "source": [
        "class D(nn.Module):\n",
        "\n",
        "      def __init__(self):\n",
        "          super(D, self).__init__()\n",
        "          self.main = nn.Sequential(\n",
        "            nn.Conv2d(3, 64, 4, 2, 1, bias = False),\n",
        "            nn.LeakyReLU(0.2, inplace = True),\n",
        "            nn.Conv2d(64, 128, 4, 2, 1, bias = False),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.LeakyReLU(0.2, inplace = True),\n",
        "            nn.Conv2d(128, 256, 4, 2, 1, bias = False),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.LeakyReLU(0.2, inplace = True),\n",
        "            nn.Conv2d(256, 512, 4, 2, 1, bias = False),\n",
        "            nn.BatchNorm2d(512),\n",
        "            nn.LeakyReLU(0.2, inplace = True),\n",
        "            nn.Conv2d(512, 1, 4, 1, 0, bias = False),\n",
        "            nn.Sigmoid()   #Returns a matrix of 0-1 discriminatoy valus where 0 is reject and 1 is accept\n",
        "          )\n",
        "\n",
        "\n",
        "      def forward(self, input):\n",
        "          output = self.main(input)\n",
        "          return output.view(-1)\n",
        "\n",
        "\n",
        "netD = D()\n",
        "netD.apply(weights_init)          "
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "D(\n",
              "  (main): Sequential(\n",
              "    (0): Conv2d(3, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "    (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
              "    (2): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "    (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (4): LeakyReLU(negative_slope=0.2, inplace=True)\n",
              "    (5): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "    (6): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (7): LeakyReLU(negative_slope=0.2, inplace=True)\n",
              "    (8): Conv2d(256, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "    (9): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (10): LeakyReLU(negative_slope=0.2, inplace=True)\n",
              "    (11): Conv2d(512, 1, kernel_size=(4, 4), stride=(1, 1), bias=False)\n",
              "    (12): Sigmoid()\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KoPhZmGzFLya",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "criterion = nn.BCELoss()\n",
        "optim_D = optim.Adam(netD.parameters(), lr = 0.0002, betas = (0.5, 0.999))\n",
        "optim_G = optim.Adam(netG.parameters(), lr = 0.0002, betas = (0.5, 0.999))"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1HDNyBoGFLsC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "df8325fd-57e6-4476-df9d-ef560b193b80"
      },
      "source": [
        "for epoch in range(17):\n",
        "    for i, data in enumerate(dataloader, 0):   #This holds a batch at a time, and we can perform minibatch SGD, index 0 is to denote the start value of i\n",
        "\n",
        "        #Discriminator training\n",
        "        netD.zero_grad()\n",
        "        real, _ = data #return value 2 will hold class info\n",
        "        input = Variable(real)\n",
        "        output = netD(input)\n",
        "        target = Variable(torch.ones(input.size()[0]))\n",
        "        errD_real = criterion(output, target)\n",
        "\n",
        "        #Fake data\n",
        "        noise = Variable(torch.randn(input.size()[0], 100, 1, 1)) #Variable with noise, 100 matrices of 1x1 each (acc to network size req)\n",
        "        fake = netG(noise)\n",
        "        target = Variable(torch.zeros(input.size()[0]))\n",
        "        output = netD(fake.detach())  #fake has grad info from G n/w, it is not needed , speed up the computation by detaching\n",
        "        errD_fake = criterion(output, target)\n",
        "\n",
        "        d_error = errD_real + errD_fake\n",
        "        d_error.backward()\n",
        "        optim_D.step()\n",
        "\n",
        "\n",
        "        #Generator training\n",
        "        netG.zero_grad()\n",
        "        target = Variable(torch.ones(input.size()[0]))\n",
        "        output = netD(fake) #do not detach the gradient as we need it for backprop in G\n",
        "        g_error = criterion(output, target)\n",
        "        g_error.backward()\n",
        "        optim_G.step()\n",
        "\n",
        "        print('[%d/%d][%d/%d] Loss_D: %.4f Loss_G: %.4f' % (epoch, 25, i, len(dataloader), d_error.data, g_error.data))\n",
        "\n",
        "        if i % 100 == 0:\n",
        "\n",
        "            vutils.save_image(real, '%s/real_samples.png' % \"./results\", normalize = True)\n",
        "            fake = netG(noise)\n",
        "            vutils.save_image(fake.data, '%s/fake_samples_epoch_%03d.png' %(\"./results\", epoch), normalize = True)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0/25][0/782] Loss_D: 0.5330 Loss_G: 6.0857\n",
            "[0/25][1/782] Loss_D: 0.4194 Loss_G: 4.2773\n",
            "[0/25][2/782] Loss_D: 0.4782 Loss_G: 8.1539\n",
            "[0/25][3/782] Loss_D: 1.1990 Loss_G: 1.3737\n",
            "[0/25][4/782] Loss_D: 2.0992 Loss_G: 11.3177\n",
            "[0/25][5/782] Loss_D: 2.7082 Loss_G: 7.0745\n",
            "[0/25][6/782] Loss_D: 0.4328 Loss_G: 2.5920\n",
            "[0/25][7/782] Loss_D: 1.4336 Loss_G: 6.2953\n",
            "[0/25][8/782] Loss_D: 0.6306 Loss_G: 4.5373\n",
            "[0/25][9/782] Loss_D: 0.3995 Loss_G: 3.8564\n",
            "[0/25][10/782] Loss_D: 0.3725 Loss_G: 5.0983\n",
            "[0/25][11/782] Loss_D: 0.5648 Loss_G: 2.9095\n",
            "[0/25][12/782] Loss_D: 1.1040 Loss_G: 8.0325\n",
            "[0/25][13/782] Loss_D: 0.7484 Loss_G: 6.1895\n",
            "[0/25][14/782] Loss_D: 0.1610 Loss_G: 3.5891\n",
            "[0/25][15/782] Loss_D: 0.5891 Loss_G: 6.1586\n",
            "[0/25][16/782] Loss_D: 0.4395 Loss_G: 4.4962\n",
            "[0/25][17/782] Loss_D: 0.3508 Loss_G: 4.4119\n",
            "[0/25][18/782] Loss_D: 0.4131 Loss_G: 6.5251\n",
            "[0/25][19/782] Loss_D: 0.3560 Loss_G: 4.1484\n",
            "[0/25][20/782] Loss_D: 0.3766 Loss_G: 6.2311\n",
            "[0/25][21/782] Loss_D: 0.1742 Loss_G: 5.6354\n",
            "[0/25][22/782] Loss_D: 0.3184 Loss_G: 5.1783\n",
            "[0/25][23/782] Loss_D: 0.3523 Loss_G: 6.1836\n",
            "[0/25][24/782] Loss_D: 0.1845 Loss_G: 5.2968\n",
            "[0/25][25/782] Loss_D: 0.3739 Loss_G: 7.5019\n",
            "[0/25][26/782] Loss_D: 0.1401 Loss_G: 6.0917\n",
            "[0/25][27/782] Loss_D: 0.3198 Loss_G: 4.2056\n",
            "[0/25][28/782] Loss_D: 0.8095 Loss_G: 13.6221\n",
            "[0/25][29/782] Loss_D: 3.0654 Loss_G: 7.1322\n",
            "[0/25][30/782] Loss_D: 0.0846 Loss_G: 3.4054\n",
            "[0/25][31/782] Loss_D: 0.4601 Loss_G: 5.7155\n",
            "[0/25][32/782] Loss_D: 0.1599 Loss_G: 6.4829\n",
            "[0/25][33/782] Loss_D: 0.1496 Loss_G: 5.7129\n",
            "[0/25][34/782] Loss_D: 0.1531 Loss_G: 5.4626\n",
            "[0/25][35/782] Loss_D: 0.3238 Loss_G: 6.6838\n",
            "[0/25][36/782] Loss_D: 0.4218 Loss_G: 4.7508\n",
            "[0/25][37/782] Loss_D: 0.5319 Loss_G: 7.9468\n",
            "[0/25][38/782] Loss_D: 0.3083 Loss_G: 6.4670\n",
            "[0/25][39/782] Loss_D: 0.1913 Loss_G: 5.0472\n",
            "[0/25][40/782] Loss_D: 0.5181 Loss_G: 8.4490\n",
            "[0/25][41/782] Loss_D: 0.6464 Loss_G: 4.1629\n",
            "[0/25][42/782] Loss_D: 1.1705 Loss_G: 12.2742\n",
            "[0/25][43/782] Loss_D: 0.8625 Loss_G: 9.2951\n",
            "[0/25][44/782] Loss_D: 0.0776 Loss_G: 3.7954\n",
            "[0/25][45/782] Loss_D: 2.0938 Loss_G: 12.5062\n",
            "[0/25][46/782] Loss_D: 0.7950 Loss_G: 11.4484\n",
            "[0/25][47/782] Loss_D: 0.6988 Loss_G: 7.1603\n",
            "[0/25][48/782] Loss_D: 0.1551 Loss_G: 3.6586\n",
            "[0/25][49/782] Loss_D: 0.7820 Loss_G: 10.1135\n",
            "[0/25][50/782] Loss_D: 0.4338 Loss_G: 9.6092\n",
            "[0/25][51/782] Loss_D: 0.2747 Loss_G: 6.9624\n",
            "[0/25][52/782] Loss_D: 0.0696 Loss_G: 3.9726\n",
            "[0/25][53/782] Loss_D: 0.7259 Loss_G: 8.8917\n",
            "[0/25][54/782] Loss_D: 0.2290 Loss_G: 8.3220\n",
            "[0/25][55/782] Loss_D: 0.1476 Loss_G: 6.7069\n",
            "[0/25][56/782] Loss_D: 0.2719 Loss_G: 3.4334\n",
            "[0/25][57/782] Loss_D: 0.6857 Loss_G: 8.5648\n",
            "[0/25][58/782] Loss_D: 0.6015 Loss_G: 6.8871\n",
            "[0/25][59/782] Loss_D: 0.1957 Loss_G: 4.0272\n",
            "[0/25][60/782] Loss_D: 0.5892 Loss_G: 11.3760\n",
            "[0/25][61/782] Loss_D: 0.6071 Loss_G: 8.9837\n",
            "[0/25][62/782] Loss_D: 0.1231 Loss_G: 5.2778\n",
            "[0/25][63/782] Loss_D: 0.4130 Loss_G: 7.9981\n",
            "[0/25][64/782] Loss_D: 0.2098 Loss_G: 7.3539\n",
            "[0/25][65/782] Loss_D: 0.4741 Loss_G: 3.8185\n",
            "[0/25][66/782] Loss_D: 0.3989 Loss_G: 7.1348\n",
            "[0/25][67/782] Loss_D: 0.0820 Loss_G: 7.3693\n",
            "[0/25][68/782] Loss_D: 0.0470 Loss_G: 6.2109\n",
            "[0/25][69/782] Loss_D: 0.0686 Loss_G: 5.3181\n",
            "[0/25][70/782] Loss_D: 0.1413 Loss_G: 5.6665\n",
            "[0/25][71/782] Loss_D: 0.1066 Loss_G: 5.8195\n",
            "[0/25][72/782] Loss_D: 0.1919 Loss_G: 6.1143\n",
            "[0/25][73/782] Loss_D: 0.3375 Loss_G: 5.7773\n",
            "[0/25][74/782] Loss_D: 0.6205 Loss_G: 4.6221\n",
            "[0/25][75/782] Loss_D: 0.5534 Loss_G: 10.0735\n",
            "[0/25][76/782] Loss_D: 0.4924 Loss_G: 8.9419\n",
            "[0/25][77/782] Loss_D: 0.0572 Loss_G: 6.6662\n",
            "[0/25][78/782] Loss_D: 0.0750 Loss_G: 4.6194\n",
            "[0/25][79/782] Loss_D: 0.4709 Loss_G: 7.9771\n",
            "[0/25][80/782] Loss_D: 0.4560 Loss_G: 6.7138\n",
            "[0/25][81/782] Loss_D: 0.4192 Loss_G: 4.3450\n",
            "[0/25][82/782] Loss_D: 0.4554 Loss_G: 5.9593\n",
            "[0/25][83/782] Loss_D: 0.2310 Loss_G: 6.5531\n",
            "[0/25][84/782] Loss_D: 0.2778 Loss_G: 5.0894\n",
            "[0/25][85/782] Loss_D: 0.1743 Loss_G: 4.7286\n",
            "[0/25][86/782] Loss_D: 0.3104 Loss_G: 4.8207\n",
            "[0/25][87/782] Loss_D: 0.4399 Loss_G: 5.0214\n",
            "[0/25][88/782] Loss_D: 0.1945 Loss_G: 4.7056\n",
            "[0/25][89/782] Loss_D: 0.2544 Loss_G: 4.1433\n",
            "[0/25][90/782] Loss_D: 0.2402 Loss_G: 5.3658\n",
            "[0/25][91/782] Loss_D: 0.2184 Loss_G: 4.9924\n",
            "[0/25][92/782] Loss_D: 0.1779 Loss_G: 5.1447\n",
            "[0/25][93/782] Loss_D: 0.2406 Loss_G: 4.8231\n",
            "[0/25][94/782] Loss_D: 0.3672 Loss_G: 8.9044\n",
            "[0/25][95/782] Loss_D: 0.5105 Loss_G: 5.1464\n",
            "[0/25][96/782] Loss_D: 1.2581 Loss_G: 12.9421\n",
            "[0/25][97/782] Loss_D: 0.9783 Loss_G: 8.9908\n",
            "[0/25][98/782] Loss_D: 0.3570 Loss_G: 5.3444\n",
            "[0/25][99/782] Loss_D: 1.2262 Loss_G: 13.0808\n",
            "[0/25][100/782] Loss_D: 5.8271 Loss_G: 4.1221\n",
            "[0/25][101/782] Loss_D: 1.8596 Loss_G: 5.4665\n",
            "[0/25][102/782] Loss_D: 1.1559 Loss_G: 3.8182\n",
            "[0/25][103/782] Loss_D: 0.6937 Loss_G: 6.1439\n",
            "[0/25][104/782] Loss_D: 0.4961 Loss_G: 4.8710\n",
            "[0/25][105/782] Loss_D: 0.6579 Loss_G: 5.5421\n",
            "[0/25][106/782] Loss_D: 0.6237 Loss_G: 2.8980\n",
            "[0/25][107/782] Loss_D: 0.5736 Loss_G: 6.2130\n",
            "[0/25][108/782] Loss_D: 0.2631 Loss_G: 5.6067\n",
            "[0/25][109/782] Loss_D: 0.1164 Loss_G: 4.4666\n",
            "[0/25][110/782] Loss_D: 0.1554 Loss_G: 3.8387\n",
            "[0/25][111/782] Loss_D: 0.1395 Loss_G: 3.8748\n",
            "[0/25][112/782] Loss_D: 0.1858 Loss_G: 3.8811\n",
            "[0/25][113/782] Loss_D: 0.1928 Loss_G: 4.4451\n",
            "[0/25][114/782] Loss_D: 0.1666 Loss_G: 4.3757\n",
            "[0/25][115/782] Loss_D: 0.2007 Loss_G: 3.3936\n",
            "[0/25][116/782] Loss_D: 0.3029 Loss_G: 5.1382\n",
            "[0/25][117/782] Loss_D: 0.2563 Loss_G: 3.7108\n",
            "[0/25][118/782] Loss_D: 0.2039 Loss_G: 4.2179\n",
            "[0/25][119/782] Loss_D: 0.2231 Loss_G: 4.3696\n",
            "[0/25][120/782] Loss_D: 0.3099 Loss_G: 3.2608\n",
            "[0/25][121/782] Loss_D: 0.3838 Loss_G: 6.0639\n",
            "[0/25][122/782] Loss_D: 0.5361 Loss_G: 2.5477\n",
            "[0/25][123/782] Loss_D: 0.5144 Loss_G: 6.5231\n",
            "[0/25][124/782] Loss_D: 0.0996 Loss_G: 6.7544\n",
            "[0/25][125/782] Loss_D: 0.1977 Loss_G: 5.3187\n",
            "[0/25][126/782] Loss_D: 0.0698 Loss_G: 3.7187\n",
            "[0/25][127/782] Loss_D: 0.1675 Loss_G: 4.0966\n",
            "[0/25][128/782] Loss_D: 0.2199 Loss_G: 4.7607\n",
            "[0/25][129/782] Loss_D: 0.5871 Loss_G: 1.5004\n",
            "[0/25][130/782] Loss_D: 0.8087 Loss_G: 9.0585\n",
            "[0/25][131/782] Loss_D: 0.8687 Loss_G: 4.7872\n",
            "[0/25][132/782] Loss_D: 0.1155 Loss_G: 3.7895\n",
            "[0/25][133/782] Loss_D: 0.3124 Loss_G: 5.3123\n",
            "[0/25][134/782] Loss_D: 0.1495 Loss_G: 4.9595\n",
            "[0/25][135/782] Loss_D: 0.1771 Loss_G: 4.3185\n",
            "[0/25][136/782] Loss_D: 0.3515 Loss_G: 4.3492\n",
            "[0/25][137/782] Loss_D: 0.2009 Loss_G: 4.6020\n",
            "[0/25][138/782] Loss_D: 0.4309 Loss_G: 4.0167\n",
            "[0/25][139/782] Loss_D: 0.4311 Loss_G: 4.9655\n",
            "[0/25][140/782] Loss_D: 0.3108 Loss_G: 4.3860\n",
            "[0/25][141/782] Loss_D: 0.2873 Loss_G: 4.5493\n",
            "[0/25][142/782] Loss_D: 0.1695 Loss_G: 6.5776\n",
            "[0/25][143/782] Loss_D: 0.3023 Loss_G: 3.0672\n",
            "[0/25][144/782] Loss_D: 0.4745 Loss_G: 9.4461\n",
            "[0/25][145/782] Loss_D: 0.3319 Loss_G: 7.4545\n",
            "[0/25][146/782] Loss_D: 0.2118 Loss_G: 3.1599\n",
            "[0/25][147/782] Loss_D: 0.5277 Loss_G: 8.6422\n",
            "[0/25][148/782] Loss_D: 0.3539 Loss_G: 7.3361\n",
            "[0/25][149/782] Loss_D: 0.3452 Loss_G: 3.8088\n",
            "[0/25][150/782] Loss_D: 0.3010 Loss_G: 5.1570\n",
            "[0/25][151/782] Loss_D: 0.5388 Loss_G: 7.5013\n",
            "[0/25][152/782] Loss_D: 0.4224 Loss_G: 5.2123\n",
            "[0/25][153/782] Loss_D: 0.7683 Loss_G: 8.5845\n",
            "[0/25][154/782] Loss_D: 1.1192 Loss_G: 3.4119\n",
            "[0/25][155/782] Loss_D: 1.5924 Loss_G: 11.8052\n",
            "[0/25][156/782] Loss_D: 0.8418 Loss_G: 8.2573\n",
            "[0/25][157/782] Loss_D: 0.5761 Loss_G: 3.4965\n",
            "[0/25][158/782] Loss_D: 2.2266 Loss_G: 11.9754\n",
            "[0/25][159/782] Loss_D: 3.2716 Loss_G: 7.3942\n",
            "[0/25][160/782] Loss_D: 0.6636 Loss_G: 2.4870\n",
            "[0/25][161/782] Loss_D: 2.2480 Loss_G: 7.2904\n",
            "[0/25][162/782] Loss_D: 0.8839 Loss_G: 5.2426\n",
            "[0/25][163/782] Loss_D: 0.4822 Loss_G: 3.7819\n",
            "[0/25][164/782] Loss_D: 0.6534 Loss_G: 4.5622\n",
            "[0/25][165/782] Loss_D: 0.3460 Loss_G: 4.8431\n",
            "[0/25][166/782] Loss_D: 0.5580 Loss_G: 4.1363\n",
            "[0/25][167/782] Loss_D: 0.4746 Loss_G: 5.2704\n",
            "[0/25][168/782] Loss_D: 0.5321 Loss_G: 4.1312\n",
            "[0/25][169/782] Loss_D: 0.3402 Loss_G: 4.7057\n",
            "[0/25][170/782] Loss_D: 0.3856 Loss_G: 6.1128\n",
            "[0/25][171/782] Loss_D: 0.3130 Loss_G: 5.2701\n",
            "[0/25][172/782] Loss_D: 0.3925 Loss_G: 5.6570\n",
            "[0/25][173/782] Loss_D: 0.2726 Loss_G: 6.2380\n",
            "[0/25][174/782] Loss_D: 0.5224 Loss_G: 3.1342\n",
            "[0/25][175/782] Loss_D: 1.3749 Loss_G: 10.5187\n",
            "[0/25][176/782] Loss_D: 2.9373 Loss_G: 4.8848\n",
            "[0/25][177/782] Loss_D: 0.3512 Loss_G: 5.2039\n",
            "[0/25][178/782] Loss_D: 0.3236 Loss_G: 5.6830\n",
            "[0/25][179/782] Loss_D: 0.4144 Loss_G: 4.0424\n",
            "[0/25][180/782] Loss_D: 0.5920 Loss_G: 6.9585\n",
            "[0/25][181/782] Loss_D: 0.6739 Loss_G: 3.7557\n",
            "[0/25][182/782] Loss_D: 0.6486 Loss_G: 4.0799\n",
            "[0/25][183/782] Loss_D: 0.3815 Loss_G: 5.4952\n",
            "[0/25][184/782] Loss_D: 0.4723 Loss_G: 3.3866\n",
            "[0/25][185/782] Loss_D: 0.7439 Loss_G: 7.0035\n",
            "[0/25][186/782] Loss_D: 1.8550 Loss_G: 1.3242\n",
            "[0/25][187/782] Loss_D: 1.6409 Loss_G: 8.9138\n",
            "[0/25][188/782] Loss_D: 2.3835 Loss_G: 5.7518\n",
            "[0/25][189/782] Loss_D: 0.4061 Loss_G: 2.8790\n",
            "[0/25][190/782] Loss_D: 0.6095 Loss_G: 4.4914\n",
            "[0/25][191/782] Loss_D: 0.2784 Loss_G: 5.2381\n",
            "[0/25][192/782] Loss_D: 0.2215 Loss_G: 4.3230\n",
            "[0/25][193/782] Loss_D: 0.3565 Loss_G: 3.8972\n",
            "[0/25][194/782] Loss_D: 0.2456 Loss_G: 4.3325\n",
            "[0/25][195/782] Loss_D: 0.5439 Loss_G: 3.8808\n",
            "[0/25][196/782] Loss_D: 0.5715 Loss_G: 3.1014\n",
            "[0/25][197/782] Loss_D: 0.5506 Loss_G: 5.7233\n",
            "[0/25][198/782] Loss_D: 0.3363 Loss_G: 4.5533\n",
            "[0/25][199/782] Loss_D: 0.2990 Loss_G: 3.6307\n",
            "[0/25][200/782] Loss_D: 0.4822 Loss_G: 6.7842\n",
            "[0/25][201/782] Loss_D: 0.3841 Loss_G: 4.8970\n",
            "[0/25][202/782] Loss_D: 0.5217 Loss_G: 3.7353\n",
            "[0/25][203/782] Loss_D: 0.8078 Loss_G: 9.2302\n",
            "[0/25][204/782] Loss_D: 1.8731 Loss_G: 3.2297\n",
            "[0/25][205/782] Loss_D: 1.2157 Loss_G: 7.7783\n",
            "[0/25][206/782] Loss_D: 0.1949 Loss_G: 6.4780\n",
            "[0/25][207/782] Loss_D: 0.2968 Loss_G: 3.8629\n",
            "[0/25][208/782] Loss_D: 1.4523 Loss_G: 10.8590\n",
            "[0/25][209/782] Loss_D: 5.0007 Loss_G: 4.0497\n",
            "[0/25][210/782] Loss_D: 0.6683 Loss_G: 2.4098\n",
            "[0/25][211/782] Loss_D: 0.9378 Loss_G: 5.6961\n",
            "[0/25][212/782] Loss_D: 0.5997 Loss_G: 4.6899\n",
            "[0/25][213/782] Loss_D: 0.5450 Loss_G: 2.5412\n",
            "[0/25][214/782] Loss_D: 0.7417 Loss_G: 4.8628\n",
            "[0/25][215/782] Loss_D: 0.2145 Loss_G: 5.0983\n",
            "[0/25][216/782] Loss_D: 0.4897 Loss_G: 3.0753\n",
            "[0/25][217/782] Loss_D: 0.9062 Loss_G: 3.3968\n",
            "[0/25][218/782] Loss_D: 0.5104 Loss_G: 4.8256\n",
            "[0/25][219/782] Loss_D: 0.5980 Loss_G: 3.2761\n",
            "[0/25][220/782] Loss_D: 0.7079 Loss_G: 4.3955\n",
            "[0/25][221/782] Loss_D: 0.5253 Loss_G: 4.6083\n",
            "[0/25][222/782] Loss_D: 0.5874 Loss_G: 4.7175\n",
            "[0/25][223/782] Loss_D: 0.4930 Loss_G: 4.1389\n",
            "[0/25][224/782] Loss_D: 0.8131 Loss_G: 4.7795\n",
            "[0/25][225/782] Loss_D: 0.9899 Loss_G: 2.5031\n",
            "[0/25][226/782] Loss_D: 1.2056 Loss_G: 5.9939\n",
            "[0/25][227/782] Loss_D: 0.8958 Loss_G: 3.4401\n",
            "[0/25][228/782] Loss_D: 0.4315 Loss_G: 2.4059\n",
            "[0/25][229/782] Loss_D: 0.5801 Loss_G: 4.1342\n",
            "[0/25][230/782] Loss_D: 0.1564 Loss_G: 4.9368\n",
            "[0/25][231/782] Loss_D: 0.3829 Loss_G: 3.1780\n",
            "[0/25][232/782] Loss_D: 0.2798 Loss_G: 3.2040\n",
            "[0/25][233/782] Loss_D: 0.6271 Loss_G: 4.6086\n",
            "[0/25][234/782] Loss_D: 0.4842 Loss_G: 3.0010\n",
            "[0/25][235/782] Loss_D: 0.6370 Loss_G: 4.5008\n",
            "[0/25][236/782] Loss_D: 0.6589 Loss_G: 2.7531\n",
            "[0/25][237/782] Loss_D: 0.6962 Loss_G: 5.4626\n",
            "[0/25][238/782] Loss_D: 0.3056 Loss_G: 5.2425\n",
            "[0/25][239/782] Loss_D: 0.4894 Loss_G: 2.0325\n",
            "[0/25][240/782] Loss_D: 1.0348 Loss_G: 7.9014\n",
            "[0/25][241/782] Loss_D: 0.9124 Loss_G: 6.0572\n",
            "[0/25][242/782] Loss_D: 0.4397 Loss_G: 1.7924\n",
            "[0/25][243/782] Loss_D: 1.0024 Loss_G: 6.7222\n",
            "[0/25][244/782] Loss_D: 1.1461 Loss_G: 2.5161\n",
            "[0/25][245/782] Loss_D: 0.6126 Loss_G: 5.1900\n",
            "[0/25][246/782] Loss_D: 0.3695 Loss_G: 4.6905\n",
            "[0/25][247/782] Loss_D: 0.4876 Loss_G: 2.7380\n",
            "[0/25][248/782] Loss_D: 0.3470 Loss_G: 4.8504\n",
            "[0/25][249/782] Loss_D: 0.3180 Loss_G: 3.9497\n",
            "[0/25][250/782] Loss_D: 0.2627 Loss_G: 4.8859\n",
            "[0/25][251/782] Loss_D: 0.2821 Loss_G: 3.9396\n",
            "[0/25][252/782] Loss_D: 0.5213 Loss_G: 6.1934\n",
            "[0/25][253/782] Loss_D: 0.3338 Loss_G: 4.6567\n",
            "[0/25][254/782] Loss_D: 0.4318 Loss_G: 2.2361\n",
            "[0/25][255/782] Loss_D: 1.8280 Loss_G: 9.2999\n",
            "[0/25][256/782] Loss_D: 2.9141 Loss_G: 5.4514\n",
            "[0/25][257/782] Loss_D: 0.7250 Loss_G: 1.2720\n",
            "[0/25][258/782] Loss_D: 1.0468 Loss_G: 5.3884\n",
            "[0/25][259/782] Loss_D: 0.1640 Loss_G: 6.5990\n",
            "[0/25][260/782] Loss_D: 0.2260 Loss_G: 5.2191\n",
            "[0/25][261/782] Loss_D: 0.1445 Loss_G: 4.1396\n",
            "[0/25][262/782] Loss_D: 0.2702 Loss_G: 3.8544\n",
            "[0/25][263/782] Loss_D: 0.2431 Loss_G: 3.6713\n",
            "[0/25][264/782] Loss_D: 0.2813 Loss_G: 4.2425\n",
            "[0/25][265/782] Loss_D: 0.1429 Loss_G: 4.4757\n",
            "[0/25][266/782] Loss_D: 0.2332 Loss_G: 3.8355\n",
            "[0/25][267/782] Loss_D: 0.3852 Loss_G: 3.3386\n",
            "[0/25][268/782] Loss_D: 0.5290 Loss_G: 4.8522\n",
            "[0/25][269/782] Loss_D: 0.2688 Loss_G: 5.0559\n",
            "[0/25][270/782] Loss_D: 0.5300 Loss_G: 2.9549\n",
            "[0/25][271/782] Loss_D: 1.4116 Loss_G: 9.1434\n",
            "[0/25][272/782] Loss_D: 1.9852 Loss_G: 5.7167\n",
            "[0/25][273/782] Loss_D: 0.4210 Loss_G: 1.7193\n",
            "[0/25][274/782] Loss_D: 1.0079 Loss_G: 4.8948\n",
            "[0/25][275/782] Loss_D: 0.2961 Loss_G: 4.9218\n",
            "[0/25][276/782] Loss_D: 0.2551 Loss_G: 3.8232\n",
            "[0/25][277/782] Loss_D: 0.4346 Loss_G: 3.2996\n",
            "[0/25][278/782] Loss_D: 0.3059 Loss_G: 3.8215\n",
            "[0/25][279/782] Loss_D: 0.4108 Loss_G: 3.5388\n",
            "[0/25][280/782] Loss_D: 0.4305 Loss_G: 4.3485\n",
            "[0/25][281/782] Loss_D: 0.5408 Loss_G: 3.2019\n",
            "[0/25][282/782] Loss_D: 0.2910 Loss_G: 4.4033\n",
            "[0/25][283/782] Loss_D: 0.2938 Loss_G: 4.7733\n",
            "[0/25][284/782] Loss_D: 0.2180 Loss_G: 4.6173\n",
            "[0/25][285/782] Loss_D: 0.4411 Loss_G: 4.9085\n",
            "[0/25][286/782] Loss_D: 0.4235 Loss_G: 4.1934\n",
            "[0/25][287/782] Loss_D: 0.3081 Loss_G: 5.3870\n",
            "[0/25][288/782] Loss_D: 0.1571 Loss_G: 5.0081\n",
            "[0/25][289/782] Loss_D: 0.2780 Loss_G: 3.5867\n",
            "[0/25][290/782] Loss_D: 0.1843 Loss_G: 3.7220\n",
            "[0/25][291/782] Loss_D: 0.3735 Loss_G: 3.9706\n",
            "[0/25][292/782] Loss_D: 0.2527 Loss_G: 4.4711\n",
            "[0/25][293/782] Loss_D: 0.5258 Loss_G: 2.9962\n",
            "[0/25][294/782] Loss_D: 0.3682 Loss_G: 3.9282\n",
            "[0/25][295/782] Loss_D: 0.2062 Loss_G: 4.2999\n",
            "[0/25][296/782] Loss_D: 0.2043 Loss_G: 3.8690\n",
            "[0/25][297/782] Loss_D: 0.2907 Loss_G: 4.0699\n",
            "[0/25][298/782] Loss_D: 0.2343 Loss_G: 3.9251\n",
            "[0/25][299/782] Loss_D: 0.5138 Loss_G: 4.4552\n",
            "[0/25][300/782] Loss_D: 0.6553 Loss_G: 2.9069\n",
            "[0/25][301/782] Loss_D: 0.4557 Loss_G: 5.1192\n",
            "[0/25][302/782] Loss_D: 0.1756 Loss_G: 4.9122\n",
            "[0/25][303/782] Loss_D: 0.4756 Loss_G: 2.7254\n",
            "[0/25][304/782] Loss_D: 0.5397 Loss_G: 5.8006\n",
            "[0/25][305/782] Loss_D: 0.2842 Loss_G: 4.8440\n",
            "[0/25][306/782] Loss_D: 0.4029 Loss_G: 3.7953\n",
            "[0/25][307/782] Loss_D: 0.7219 Loss_G: 5.3226\n",
            "[0/25][308/782] Loss_D: 0.7894 Loss_G: 2.2544\n",
            "[0/25][309/782] Loss_D: 0.8899 Loss_G: 7.6549\n",
            "[0/25][310/782] Loss_D: 0.3847 Loss_G: 6.7627\n",
            "[0/25][311/782] Loss_D: 0.1490 Loss_G: 4.3147\n",
            "[0/25][312/782] Loss_D: 0.2099 Loss_G: 3.9466\n",
            "[0/25][313/782] Loss_D: 0.3817 Loss_G: 5.0608\n",
            "[0/25][314/782] Loss_D: 0.4906 Loss_G: 3.2489\n",
            "[0/25][315/782] Loss_D: 0.5512 Loss_G: 5.9975\n",
            "[0/25][316/782] Loss_D: 0.4634 Loss_G: 4.5544\n",
            "[0/25][317/782] Loss_D: 0.1475 Loss_G: 3.8770\n",
            "[0/25][318/782] Loss_D: 0.4425 Loss_G: 6.6864\n",
            "[0/25][319/782] Loss_D: 0.5933 Loss_G: 3.3929\n",
            "[0/25][320/782] Loss_D: 0.4035 Loss_G: 6.6976\n",
            "[0/25][321/782] Loss_D: 0.2770 Loss_G: 5.2971\n",
            "[0/25][322/782] Loss_D: 0.2711 Loss_G: 4.6057\n",
            "[0/25][323/782] Loss_D: 0.3740 Loss_G: 6.3773\n",
            "[0/25][324/782] Loss_D: 0.3333 Loss_G: 4.4115\n",
            "[0/25][325/782] Loss_D: 0.4651 Loss_G: 5.1576\n",
            "[0/25][326/782] Loss_D: 0.5400 Loss_G: 4.0321\n",
            "[0/25][327/782] Loss_D: 0.4571 Loss_G: 7.5589\n",
            "[0/25][328/782] Loss_D: 0.3630 Loss_G: 4.9343\n",
            "[0/25][329/782] Loss_D: 0.2184 Loss_G: 3.3787\n",
            "[0/25][330/782] Loss_D: 0.5813 Loss_G: 7.9232\n",
            "[0/25][331/782] Loss_D: 0.4620 Loss_G: 6.1741\n",
            "[0/25][332/782] Loss_D: 0.6012 Loss_G: 1.9761\n",
            "[0/25][333/782] Loss_D: 1.1373 Loss_G: 6.9456\n",
            "[0/25][334/782] Loss_D: 0.3213 Loss_G: 5.6171\n",
            "[0/25][335/782] Loss_D: 0.3999 Loss_G: 2.5319\n",
            "[0/25][336/782] Loss_D: 1.4826 Loss_G: 8.2057\n",
            "[0/25][337/782] Loss_D: 1.6866 Loss_G: 4.6441\n",
            "[0/25][338/782] Loss_D: 0.5034 Loss_G: 2.3559\n",
            "[0/25][339/782] Loss_D: 0.6093 Loss_G: 5.5962\n",
            "[0/25][340/782] Loss_D: 0.2437 Loss_G: 5.1950\n",
            "[0/25][341/782] Loss_D: 0.1689 Loss_G: 4.0665\n",
            "[0/25][342/782] Loss_D: 0.5874 Loss_G: 2.8492\n",
            "[0/25][343/782] Loss_D: 0.5814 Loss_G: 7.3413\n",
            "[0/25][344/782] Loss_D: 0.5377 Loss_G: 5.6149\n",
            "[0/25][345/782] Loss_D: 0.2542 Loss_G: 3.2147\n",
            "[0/25][346/782] Loss_D: 0.9231 Loss_G: 7.8017\n",
            "[0/25][347/782] Loss_D: 0.7470 Loss_G: 4.6100\n",
            "[0/25][348/782] Loss_D: 0.4038 Loss_G: 2.7214\n",
            "[0/25][349/782] Loss_D: 1.3284 Loss_G: 10.1289\n",
            "[0/25][350/782] Loss_D: 0.8904 Loss_G: 6.3896\n",
            "[0/25][351/782] Loss_D: 0.5355 Loss_G: 1.0692\n",
            "[0/25][352/782] Loss_D: 3.9215 Loss_G: 12.2766\n",
            "[0/25][353/782] Loss_D: 3.4848 Loss_G: 7.2011\n",
            "[0/25][354/782] Loss_D: 1.0304 Loss_G: 1.3987\n",
            "[0/25][355/782] Loss_D: 1.6577 Loss_G: 4.0707\n",
            "[0/25][356/782] Loss_D: 0.7593 Loss_G: 3.7389\n",
            "[0/25][357/782] Loss_D: 0.5047 Loss_G: 2.9434\n",
            "[0/25][358/782] Loss_D: 0.6854 Loss_G: 2.6760\n",
            "[0/25][359/782] Loss_D: 0.5079 Loss_G: 3.1572\n",
            "[0/25][360/782] Loss_D: 0.4514 Loss_G: 3.6794\n",
            "[0/25][361/782] Loss_D: 0.3276 Loss_G: 3.7354\n",
            "[0/25][362/782] Loss_D: 0.3184 Loss_G: 2.9062\n",
            "[0/25][363/782] Loss_D: 0.2778 Loss_G: 3.5716\n",
            "[0/25][364/782] Loss_D: 0.1596 Loss_G: 3.9924\n",
            "[0/25][365/782] Loss_D: 0.1971 Loss_G: 3.6173\n",
            "[0/25][366/782] Loss_D: 0.2452 Loss_G: 3.3738\n",
            "[0/25][367/782] Loss_D: 0.3462 Loss_G: 3.1877\n",
            "[0/25][368/782] Loss_D: 0.2610 Loss_G: 3.6643\n",
            "[0/25][369/782] Loss_D: 0.2441 Loss_G: 3.6752\n",
            "[0/25][370/782] Loss_D: 0.1230 Loss_G: 4.0974\n",
            "[0/25][371/782] Loss_D: 0.1424 Loss_G: 4.0284\n",
            "[0/25][372/782] Loss_D: 0.1501 Loss_G: 4.0915\n",
            "[0/25][373/782] Loss_D: 0.1594 Loss_G: 4.0816\n",
            "[0/25][374/782] Loss_D: 0.2124 Loss_G: 4.0408\n",
            "[0/25][375/782] Loss_D: 0.1916 Loss_G: 3.6434\n",
            "[0/25][376/782] Loss_D: 0.2229 Loss_G: 4.2865\n",
            "[0/25][377/782] Loss_D: 0.2711 Loss_G: 4.4270\n",
            "[0/25][378/782] Loss_D: 0.2193 Loss_G: 4.1142\n",
            "[0/25][379/782] Loss_D: 0.3485 Loss_G: 4.6149\n",
            "[0/25][380/782] Loss_D: 0.3333 Loss_G: 3.0277\n",
            "[0/25][381/782] Loss_D: 0.5847 Loss_G: 8.2895\n",
            "[0/25][382/782] Loss_D: 0.5002 Loss_G: 6.3208\n",
            "[0/25][383/782] Loss_D: 0.4106 Loss_G: 2.1253\n",
            "[0/25][384/782] Loss_D: 0.9052 Loss_G: 6.8281\n",
            "[0/25][385/782] Loss_D: 0.1967 Loss_G: 6.8117\n",
            "[0/25][386/782] Loss_D: 0.0766 Loss_G: 5.2117\n",
            "[0/25][387/782] Loss_D: 0.2063 Loss_G: 3.0127\n",
            "[0/25][388/782] Loss_D: 0.3815 Loss_G: 5.6039\n",
            "[0/25][389/782] Loss_D: 0.2065 Loss_G: 5.0908\n",
            "[0/25][390/782] Loss_D: 0.3678 Loss_G: 2.7488\n",
            "[0/25][391/782] Loss_D: 0.4640 Loss_G: 4.5435\n",
            "[0/25][392/782] Loss_D: 0.3313 Loss_G: 3.9524\n",
            "[0/25][393/782] Loss_D: 0.2483 Loss_G: 3.6503\n",
            "[0/25][394/782] Loss_D: 0.2744 Loss_G: 4.9115\n",
            "[0/25][395/782] Loss_D: 0.3587 Loss_G: 3.2912\n",
            "[0/25][396/782] Loss_D: 0.4724 Loss_G: 5.3436\n",
            "[0/25][397/782] Loss_D: 0.1913 Loss_G: 5.3190\n",
            "[0/25][398/782] Loss_D: 0.3548 Loss_G: 2.9880\n",
            "[0/25][399/782] Loss_D: 0.7199 Loss_G: 6.4134\n",
            "[0/25][400/782] Loss_D: 0.4927 Loss_G: 3.5515\n",
            "[0/25][401/782] Loss_D: 0.2517 Loss_G: 4.8525\n",
            "[0/25][402/782] Loss_D: 0.2098 Loss_G: 6.4707\n",
            "[0/25][403/782] Loss_D: 0.1552 Loss_G: 5.7019\n",
            "[0/25][404/782] Loss_D: 0.4886 Loss_G: 2.5795\n",
            "[0/25][405/782] Loss_D: 0.8497 Loss_G: 8.8626\n",
            "[0/25][406/782] Loss_D: 1.1417 Loss_G: 3.9811\n",
            "[0/25][407/782] Loss_D: 0.4210 Loss_G: 3.8135\n",
            "[0/25][408/782] Loss_D: 0.3280 Loss_G: 5.8140\n",
            "[0/25][409/782] Loss_D: 0.4234 Loss_G: 3.9268\n",
            "[0/25][410/782] Loss_D: 0.3581 Loss_G: 3.5275\n",
            "[0/25][411/782] Loss_D: 0.4141 Loss_G: 5.8134\n",
            "[0/25][412/782] Loss_D: 0.3900 Loss_G: 4.2376\n",
            "[0/25][413/782] Loss_D: 0.2560 Loss_G: 4.4567\n",
            "[0/25][414/782] Loss_D: 0.4302 Loss_G: 3.7717\n",
            "[0/25][415/782] Loss_D: 0.3260 Loss_G: 5.0234\n",
            "[0/25][416/782] Loss_D: 0.2794 Loss_G: 3.8738\n",
            "[0/25][417/782] Loss_D: 0.5179 Loss_G: 4.2626\n",
            "[0/25][418/782] Loss_D: 0.3792 Loss_G: 4.3284\n",
            "[0/25][419/782] Loss_D: 0.4811 Loss_G: 2.5227\n",
            "[0/25][420/782] Loss_D: 0.6832 Loss_G: 5.1489\n",
            "[0/25][421/782] Loss_D: 0.8693 Loss_G: 1.2225\n",
            "[0/25][422/782] Loss_D: 1.3227 Loss_G: 7.8443\n",
            "[0/25][423/782] Loss_D: 1.1207 Loss_G: 4.6599\n",
            "[0/25][424/782] Loss_D: 0.1454 Loss_G: 2.7377\n",
            "[0/25][425/782] Loss_D: 0.4160 Loss_G: 3.7824\n",
            "[0/25][426/782] Loss_D: 0.5823 Loss_G: 2.6970\n",
            "[0/25][427/782] Loss_D: 0.5066 Loss_G: 4.0318\n",
            "[0/25][428/782] Loss_D: 0.6111 Loss_G: 2.9309\n",
            "[0/25][429/782] Loss_D: 1.0346 Loss_G: 4.9705\n",
            "[0/25][430/782] Loss_D: 1.1016 Loss_G: 0.8872\n",
            "[0/25][431/782] Loss_D: 2.5055 Loss_G: 9.6282\n",
            "[0/25][432/782] Loss_D: 2.6782 Loss_G: 4.0458\n",
            "[0/25][433/782] Loss_D: 0.5514 Loss_G: 1.3006\n",
            "[0/25][434/782] Loss_D: 2.3676 Loss_G: 4.7820\n",
            "[0/25][435/782] Loss_D: 1.0596 Loss_G: 3.2337\n",
            "[0/25][436/782] Loss_D: 0.8997 Loss_G: 2.2251\n",
            "[0/25][437/782] Loss_D: 0.8025 Loss_G: 4.0545\n",
            "[0/25][438/782] Loss_D: 0.5273 Loss_G: 3.5310\n",
            "[0/25][439/782] Loss_D: 1.1446 Loss_G: 1.1698\n",
            "[0/25][440/782] Loss_D: 1.2543 Loss_G: 3.6094\n",
            "[0/25][441/782] Loss_D: 0.4563 Loss_G: 3.7937\n",
            "[0/25][442/782] Loss_D: 0.3573 Loss_G: 2.9635\n",
            "[0/25][443/782] Loss_D: 0.3701 Loss_G: 2.6781\n",
            "[0/25][444/782] Loss_D: 0.4811 Loss_G: 4.1771\n",
            "[0/25][445/782] Loss_D: 0.3897 Loss_G: 3.5114\n",
            "[0/25][446/782] Loss_D: 0.2324 Loss_G: 3.2376\n",
            "[0/25][447/782] Loss_D: 0.3975 Loss_G: 3.3665\n",
            "[0/25][448/782] Loss_D: 0.5052 Loss_G: 2.8789\n",
            "[0/25][449/782] Loss_D: 0.3746 Loss_G: 2.8508\n",
            "[0/25][450/782] Loss_D: 0.5836 Loss_G: 3.7000\n",
            "[0/25][451/782] Loss_D: 0.6479 Loss_G: 2.9022\n",
            "[0/25][452/782] Loss_D: 0.2799 Loss_G: 5.1840\n",
            "[0/25][453/782] Loss_D: 0.3071 Loss_G: 3.4177\n",
            "[0/25][454/782] Loss_D: 0.2721 Loss_G: 5.1901\n",
            "[0/25][455/782] Loss_D: 0.2958 Loss_G: 4.0407\n",
            "[0/25][456/782] Loss_D: 0.5323 Loss_G: 6.9864\n",
            "[0/25][457/782] Loss_D: 1.3931 Loss_G: 1.3879\n",
            "[0/25][458/782] Loss_D: 1.5548 Loss_G: 10.4719\n",
            "[0/25][459/782] Loss_D: 1.7530 Loss_G: 6.0895\n",
            "[0/25][460/782] Loss_D: 0.2698 Loss_G: 2.3577\n",
            "[0/25][461/782] Loss_D: 1.1795 Loss_G: 7.3893\n",
            "[0/25][462/782] Loss_D: 0.9260 Loss_G: 5.0789\n",
            "[0/25][463/782] Loss_D: 0.6503 Loss_G: 1.4460\n",
            "[0/25][464/782] Loss_D: 1.2548 Loss_G: 6.2923\n",
            "[0/25][465/782] Loss_D: 0.6313 Loss_G: 4.1021\n",
            "[0/25][466/782] Loss_D: 0.3805 Loss_G: 2.1851\n",
            "[0/25][467/782] Loss_D: 0.3709 Loss_G: 4.3156\n",
            "[0/25][468/782] Loss_D: 0.7378 Loss_G: 6.7724\n",
            "[0/25][469/782] Loss_D: 1.0284 Loss_G: 3.4006\n",
            "[0/25][470/782] Loss_D: 0.6649 Loss_G: 4.3312\n",
            "[0/25][471/782] Loss_D: 0.3893 Loss_G: 6.1098\n",
            "[0/25][472/782] Loss_D: 0.4728 Loss_G: 4.0437\n",
            "[0/25][473/782] Loss_D: 0.9898 Loss_G: 6.0629\n",
            "[0/25][474/782] Loss_D: 0.8412 Loss_G: 3.3952\n",
            "[0/25][475/782] Loss_D: 0.8874 Loss_G: 3.8002\n",
            "[0/25][476/782] Loss_D: 0.4714 Loss_G: 3.8774\n",
            "[0/25][477/782] Loss_D: 0.4732 Loss_G: 3.6704\n",
            "[0/25][478/782] Loss_D: 0.3970 Loss_G: 3.6411\n",
            "[0/25][479/782] Loss_D: 0.4792 Loss_G: 2.2172\n",
            "[0/25][480/782] Loss_D: 0.5159 Loss_G: 5.1550\n",
            "[0/25][481/782] Loss_D: 0.4848 Loss_G: 2.7195\n",
            "[0/25][482/782] Loss_D: 0.5531 Loss_G: 4.5021\n",
            "[0/25][483/782] Loss_D: 0.5412 Loss_G: 2.4585\n",
            "[0/25][484/782] Loss_D: 0.7460 Loss_G: 5.8505\n",
            "[0/25][485/782] Loss_D: 1.1263 Loss_G: 1.1209\n",
            "[0/25][486/782] Loss_D: 1.3082 Loss_G: 8.0187\n",
            "[0/25][487/782] Loss_D: 1.0630 Loss_G: 5.4955\n",
            "[0/25][488/782] Loss_D: 0.7921 Loss_G: 1.5538\n",
            "[0/25][489/782] Loss_D: 0.8389 Loss_G: 4.0528\n",
            "[0/25][490/782] Loss_D: 0.2131 Loss_G: 4.6638\n",
            "[0/25][491/782] Loss_D: 0.5239 Loss_G: 2.5564\n",
            "[0/25][492/782] Loss_D: 0.8474 Loss_G: 3.6722\n",
            "[0/25][493/782] Loss_D: 0.6694 Loss_G: 2.5616\n",
            "[0/25][494/782] Loss_D: 0.8418 Loss_G: 2.7828\n",
            "[0/25][495/782] Loss_D: 0.4644 Loss_G: 2.9277\n",
            "[0/25][496/782] Loss_D: 0.5062 Loss_G: 3.7990\n",
            "[0/25][497/782] Loss_D: 0.6718 Loss_G: 2.0889\n",
            "[0/25][498/782] Loss_D: 0.5063 Loss_G: 3.7380\n",
            "[0/25][499/782] Loss_D: 0.2489 Loss_G: 3.9008\n",
            "[0/25][500/782] Loss_D: 0.4117 Loss_G: 2.2363\n",
            "[0/25][501/782] Loss_D: 0.7751 Loss_G: 6.1426\n",
            "[0/25][502/782] Loss_D: 1.9526 Loss_G: 1.1854\n",
            "[0/25][503/782] Loss_D: 0.9382 Loss_G: 5.0092\n",
            "[0/25][504/782] Loss_D: 0.3371 Loss_G: 4.0961\n",
            "[0/25][505/782] Loss_D: 0.3306 Loss_G: 2.8767\n",
            "[0/25][506/782] Loss_D: 0.4252 Loss_G: 3.7233\n",
            "[0/25][507/782] Loss_D: 0.1806 Loss_G: 3.8991\n",
            "[0/25][508/782] Loss_D: 0.2103 Loss_G: 3.3568\n",
            "[0/25][509/782] Loss_D: 0.2565 Loss_G: 3.3593\n",
            "[0/25][510/782] Loss_D: 0.3389 Loss_G: 3.9662\n",
            "[0/25][511/782] Loss_D: 0.3932 Loss_G: 3.1892\n",
            "[0/25][512/782] Loss_D: 0.3210 Loss_G: 3.3816\n",
            "[0/25][513/782] Loss_D: 0.4388 Loss_G: 3.7730\n",
            "[0/25][514/782] Loss_D: 0.3141 Loss_G: 4.0917\n",
            "[0/25][515/782] Loss_D: 0.4436 Loss_G: 2.7732\n",
            "[0/25][516/782] Loss_D: 0.5604 Loss_G: 6.6232\n",
            "[0/25][517/782] Loss_D: 0.7604 Loss_G: 3.2970\n",
            "[0/25][518/782] Loss_D: 0.3051 Loss_G: 4.4816\n",
            "[0/25][519/782] Loss_D: 0.2251 Loss_G: 4.9491\n",
            "[0/25][520/782] Loss_D: 0.1322 Loss_G: 4.9794\n",
            "[0/25][521/782] Loss_D: 0.4080 Loss_G: 3.2456\n",
            "[0/25][522/782] Loss_D: 0.3519 Loss_G: 5.1847\n",
            "[0/25][523/782] Loss_D: 0.2499 Loss_G: 5.0336\n",
            "[0/25][524/782] Loss_D: 0.1380 Loss_G: 4.5977\n",
            "[0/25][525/782] Loss_D: 0.2889 Loss_G: 4.8754\n",
            "[0/25][526/782] Loss_D: 0.1953 Loss_G: 4.6822\n",
            "[0/25][527/782] Loss_D: 0.2217 Loss_G: 3.8690\n",
            "[0/25][528/782] Loss_D: 0.4047 Loss_G: 6.6640\n",
            "[0/25][529/782] Loss_D: 0.7084 Loss_G: 3.6103\n",
            "[0/25][530/782] Loss_D: 0.2725 Loss_G: 5.3117\n",
            "[0/25][531/782] Loss_D: 0.0854 Loss_G: 5.6217\n",
            "[0/25][532/782] Loss_D: 0.2541 Loss_G: 3.6954\n",
            "[0/25][533/782] Loss_D: 0.4245 Loss_G: 4.8990\n",
            "[0/25][534/782] Loss_D: 0.3701 Loss_G: 3.6747\n",
            "[0/25][535/782] Loss_D: 0.2505 Loss_G: 4.2622\n",
            "[0/25][536/782] Loss_D: 0.8399 Loss_G: 3.7283\n",
            "[0/25][537/782] Loss_D: 0.5535 Loss_G: 4.7834\n",
            "[0/25][538/782] Loss_D: 0.6795 Loss_G: 4.0688\n",
            "[0/25][539/782] Loss_D: 0.5573 Loss_G: 3.7765\n",
            "[0/25][540/782] Loss_D: 0.9904 Loss_G: 4.8392\n",
            "[0/25][541/782] Loss_D: 0.4076 Loss_G: 3.5138\n",
            "[0/25][542/782] Loss_D: 0.6922 Loss_G: 6.1162\n",
            "[0/25][543/782] Loss_D: 0.5029 Loss_G: 3.8964\n",
            "[0/25][544/782] Loss_D: 0.3024 Loss_G: 4.2175\n",
            "[0/25][545/782] Loss_D: 0.2770 Loss_G: 4.5578\n",
            "[0/25][546/782] Loss_D: 0.2823 Loss_G: 4.4894\n",
            "[0/25][547/782] Loss_D: 0.4147 Loss_G: 3.4244\n",
            "[0/25][548/782] Loss_D: 0.2606 Loss_G: 4.7363\n",
            "[0/25][549/782] Loss_D: 0.3337 Loss_G: 4.5102\n",
            "[0/25][550/782] Loss_D: 0.3849 Loss_G: 5.7365\n",
            "[0/25][551/782] Loss_D: 0.4171 Loss_G: 3.4502\n",
            "[0/25][552/782] Loss_D: 0.4074 Loss_G: 6.4454\n",
            "[0/25][553/782] Loss_D: 0.2372 Loss_G: 5.5388\n",
            "[0/25][554/782] Loss_D: 0.1746 Loss_G: 4.7396\n",
            "[0/25][555/782] Loss_D: 0.1966 Loss_G: 4.5636\n",
            "[0/25][556/782] Loss_D: 0.1248 Loss_G: 5.0338\n",
            "[0/25][557/782] Loss_D: 0.2480 Loss_G: 4.7039\n",
            "[0/25][558/782] Loss_D: 0.5164 Loss_G: 5.1576\n",
            "[0/25][559/782] Loss_D: 0.8175 Loss_G: 0.5354\n",
            "[0/25][560/782] Loss_D: 2.6660 Loss_G: 10.6069\n",
            "[0/25][561/782] Loss_D: 4.9326 Loss_G: 1.7997\n",
            "[0/25][562/782] Loss_D: 0.8604 Loss_G: 4.2304\n",
            "[0/25][563/782] Loss_D: 1.1181 Loss_G: 2.1472\n",
            "[0/25][564/782] Loss_D: 1.0376 Loss_G: 5.0201\n",
            "[0/25][565/782] Loss_D: 0.9621 Loss_G: 2.3945\n",
            "[0/25][566/782] Loss_D: 0.8231 Loss_G: 3.1068\n",
            "[0/25][567/782] Loss_D: 0.5424 Loss_G: 3.6469\n",
            "[0/25][568/782] Loss_D: 0.7452 Loss_G: 2.2109\n",
            "[0/25][569/782] Loss_D: 0.7601 Loss_G: 3.8280\n",
            "[0/25][570/782] Loss_D: 0.5532 Loss_G: 3.2547\n",
            "[0/25][571/782] Loss_D: 0.5521 Loss_G: 3.0722\n",
            "[0/25][572/782] Loss_D: 0.4490 Loss_G: 3.2768\n",
            "[0/25][573/782] Loss_D: 0.5707 Loss_G: 2.5356\n",
            "[0/25][574/782] Loss_D: 0.7173 Loss_G: 5.5717\n",
            "[0/25][575/782] Loss_D: 0.6052 Loss_G: 3.5322\n",
            "[0/25][576/782] Loss_D: 0.4411 Loss_G: 2.9271\n",
            "[0/25][577/782] Loss_D: 0.5801 Loss_G: 4.8912\n",
            "[0/25][578/782] Loss_D: 0.5587 Loss_G: 3.1082\n",
            "[0/25][579/782] Loss_D: 0.4362 Loss_G: 2.4912\n",
            "[0/25][580/782] Loss_D: 0.6593 Loss_G: 4.6801\n",
            "[0/25][581/782] Loss_D: 0.5758 Loss_G: 3.2046\n",
            "[0/25][582/782] Loss_D: 0.7051 Loss_G: 3.1035\n",
            "[0/25][583/782] Loss_D: 1.0799 Loss_G: 3.9144\n",
            "[0/25][584/782] Loss_D: 0.5960 Loss_G: 3.2429\n",
            "[0/25][585/782] Loss_D: 0.8927 Loss_G: 4.8636\n",
            "[0/25][586/782] Loss_D: 0.9350 Loss_G: 1.8066\n",
            "[0/25][587/782] Loss_D: 1.4238 Loss_G: 8.7324\n",
            "[0/25][588/782] Loss_D: 1.9040 Loss_G: 3.2109\n",
            "[0/25][589/782] Loss_D: 0.3887 Loss_G: 2.0806\n",
            "[0/25][590/782] Loss_D: 1.0496 Loss_G: 6.5590\n",
            "[0/25][591/782] Loss_D: 1.0697 Loss_G: 2.5418\n",
            "[0/25][592/782] Loss_D: 0.6526 Loss_G: 4.8373\n",
            "[0/25][593/782] Loss_D: 0.3316 Loss_G: 3.9705\n",
            "[0/25][594/782] Loss_D: 0.3888 Loss_G: 2.6554\n",
            "[0/25][595/782] Loss_D: 0.3683 Loss_G: 3.2352\n",
            "[0/25][596/782] Loss_D: 0.6773 Loss_G: 2.5165\n",
            "[0/25][597/782] Loss_D: 0.6077 Loss_G: 3.6989\n",
            "[0/25][598/782] Loss_D: 0.7211 Loss_G: 2.4380\n",
            "[0/25][599/782] Loss_D: 0.8530 Loss_G: 3.4073\n",
            "[0/25][600/782] Loss_D: 0.2871 Loss_G: 3.7660\n",
            "[0/25][601/782] Loss_D: 0.4386 Loss_G: 2.8868\n",
            "[0/25][602/782] Loss_D: 0.3191 Loss_G: 3.1610\n",
            "[0/25][603/782] Loss_D: 0.4298 Loss_G: 2.8419\n",
            "[0/25][604/782] Loss_D: 0.5219 Loss_G: 3.8111\n",
            "[0/25][605/782] Loss_D: 0.4174 Loss_G: 4.1370\n",
            "[0/25][606/782] Loss_D: 0.4258 Loss_G: 2.5901\n",
            "[0/25][607/782] Loss_D: 0.4091 Loss_G: 3.3986\n",
            "[0/25][608/782] Loss_D: 0.3648 Loss_G: 3.3243\n",
            "[0/25][609/782] Loss_D: 0.4517 Loss_G: 3.9939\n",
            "[0/25][610/782] Loss_D: 0.4099 Loss_G: 3.2955\n",
            "[0/25][611/782] Loss_D: 0.4945 Loss_G: 2.3741\n",
            "[0/25][612/782] Loss_D: 0.7321 Loss_G: 6.0707\n",
            "[0/25][613/782] Loss_D: 0.8523 Loss_G: 3.3432\n",
            "[0/25][614/782] Loss_D: 0.4246 Loss_G: 3.7786\n",
            "[0/25][615/782] Loss_D: 0.6045 Loss_G: 3.2876\n",
            "[0/25][616/782] Loss_D: 0.3743 Loss_G: 5.0714\n",
            "[0/25][617/782] Loss_D: 0.2517 Loss_G: 4.4650\n",
            "[0/25][618/782] Loss_D: 0.4153 Loss_G: 3.1284\n",
            "[0/25][619/782] Loss_D: 0.7753 Loss_G: 6.6395\n",
            "[0/25][620/782] Loss_D: 1.8309 Loss_G: 0.6868\n",
            "[0/25][621/782] Loss_D: 2.0196 Loss_G: 8.2655\n",
            "[0/25][622/782] Loss_D: 1.0114 Loss_G: 4.9160\n",
            "[0/25][623/782] Loss_D: 0.5945 Loss_G: 2.1380\n",
            "[0/25][624/782] Loss_D: 1.2401 Loss_G: 5.9859\n",
            "[0/25][625/782] Loss_D: 1.0002 Loss_G: 3.2434\n",
            "[0/25][626/782] Loss_D: 0.7521 Loss_G: 3.3639\n",
            "[0/25][627/782] Loss_D: 0.6564 Loss_G: 4.4857\n",
            "[0/25][628/782] Loss_D: 0.4606 Loss_G: 3.3508\n",
            "[0/25][629/782] Loss_D: 0.6463 Loss_G: 3.8485\n",
            "[0/25][630/782] Loss_D: 0.5072 Loss_G: 3.9887\n",
            "[0/25][631/782] Loss_D: 0.5065 Loss_G: 3.6497\n",
            "[0/25][632/782] Loss_D: 0.5327 Loss_G: 3.1138\n",
            "[0/25][633/782] Loss_D: 0.5116 Loss_G: 5.6515\n",
            "[0/25][634/782] Loss_D: 0.5005 Loss_G: 3.3432\n",
            "[0/25][635/782] Loss_D: 0.3586 Loss_G: 3.9381\n",
            "[0/25][636/782] Loss_D: 0.3930 Loss_G: 4.2781\n",
            "[0/25][637/782] Loss_D: 0.7223 Loss_G: 1.7647\n",
            "[0/25][638/782] Loss_D: 1.0446 Loss_G: 6.8963\n",
            "[0/25][639/782] Loss_D: 1.0350 Loss_G: 3.6324\n",
            "[0/25][640/782] Loss_D: 0.6346 Loss_G: 3.0901\n",
            "[0/25][641/782] Loss_D: 0.7523 Loss_G: 6.0265\n",
            "[0/25][642/782] Loss_D: 1.0293 Loss_G: 2.9585\n",
            "[0/25][643/782] Loss_D: 0.5091 Loss_G: 3.6602\n",
            "[0/25][644/782] Loss_D: 0.2464 Loss_G: 3.9797\n",
            "[0/25][645/782] Loss_D: 0.1941 Loss_G: 3.6467\n",
            "[0/25][646/782] Loss_D: 0.3838 Loss_G: 3.8348\n",
            "[0/25][647/782] Loss_D: 0.3770 Loss_G: 3.0392\n",
            "[0/25][648/782] Loss_D: 0.4034 Loss_G: 3.3726\n",
            "[0/25][649/782] Loss_D: 0.1850 Loss_G: 4.2564\n",
            "[0/25][650/782] Loss_D: 0.3029 Loss_G: 3.6714\n",
            "[0/25][651/782] Loss_D: 0.2743 Loss_G: 3.8932\n",
            "[0/25][652/782] Loss_D: 0.4987 Loss_G: 2.3592\n",
            "[0/25][653/782] Loss_D: 0.7854 Loss_G: 6.8833\n",
            "[0/25][654/782] Loss_D: 2.3313 Loss_G: 0.1828\n",
            "[0/25][655/782] Loss_D: 2.9990 Loss_G: 6.9151\n",
            "[0/25][656/782] Loss_D: 2.3306 Loss_G: 2.3934\n",
            "[0/25][657/782] Loss_D: 0.8763 Loss_G: 1.0505\n",
            "[0/25][658/782] Loss_D: 1.2654 Loss_G: 4.5495\n",
            "[0/25][659/782] Loss_D: 0.9742 Loss_G: 3.1515\n",
            "[0/25][660/782] Loss_D: 0.7099 Loss_G: 1.7359\n",
            "[0/25][661/782] Loss_D: 1.1565 Loss_G: 4.3328\n",
            "[0/25][662/782] Loss_D: 1.1270 Loss_G: 2.5604\n",
            "[0/25][663/782] Loss_D: 0.5670 Loss_G: 2.8186\n",
            "[0/25][664/782] Loss_D: 0.7833 Loss_G: 3.1647\n",
            "[0/25][665/782] Loss_D: 0.2244 Loss_G: 3.9051\n",
            "[0/25][666/782] Loss_D: 0.4431 Loss_G: 3.5090\n",
            "[0/25][667/782] Loss_D: 0.4854 Loss_G: 2.5579\n",
            "[0/25][668/782] Loss_D: 0.9319 Loss_G: 3.1879\n",
            "[0/25][669/782] Loss_D: 0.5318 Loss_G: 3.1473\n",
            "[0/25][670/782] Loss_D: 0.5785 Loss_G: 3.1386\n",
            "[0/25][671/782] Loss_D: 0.9359 Loss_G: 5.2206\n",
            "[0/25][672/782] Loss_D: 1.0643 Loss_G: 2.3791\n",
            "[0/25][673/782] Loss_D: 0.7291 Loss_G: 3.4023\n",
            "[0/25][674/782] Loss_D: 0.4853 Loss_G: 3.2591\n",
            "[0/25][675/782] Loss_D: 0.2935 Loss_G: 3.8590\n",
            "[0/25][676/782] Loss_D: 0.2525 Loss_G: 3.7110\n",
            "[0/25][677/782] Loss_D: 0.7916 Loss_G: 5.5187\n",
            "[0/25][678/782] Loss_D: 1.0596 Loss_G: 2.9988\n",
            "[0/25][679/782] Loss_D: 0.6529 Loss_G: 2.5194\n",
            "[0/25][680/782] Loss_D: 0.6528 Loss_G: 4.8742\n",
            "[0/25][681/782] Loss_D: 0.6010 Loss_G: 2.4694\n",
            "[0/25][682/782] Loss_D: 0.8637 Loss_G: 5.9927\n",
            "[0/25][683/782] Loss_D: 1.1846 Loss_G: 1.8381\n",
            "[0/25][684/782] Loss_D: 1.4426 Loss_G: 5.2454\n",
            "[0/25][685/782] Loss_D: 0.7159 Loss_G: 3.1200\n",
            "[0/25][686/782] Loss_D: 0.6101 Loss_G: 3.6985\n",
            "[0/25][687/782] Loss_D: 0.5593 Loss_G: 5.0013\n",
            "[0/25][688/782] Loss_D: 0.7035 Loss_G: 2.8984\n",
            "[0/25][689/782] Loss_D: 1.1830 Loss_G: 5.6702\n",
            "[0/25][690/782] Loss_D: 0.4260 Loss_G: 4.9665\n",
            "[0/25][691/782] Loss_D: 0.4368 Loss_G: 2.1918\n",
            "[0/25][692/782] Loss_D: 0.8468 Loss_G: 5.1505\n",
            "[0/25][693/782] Loss_D: 0.3271 Loss_G: 3.3618\n",
            "[0/25][694/782] Loss_D: 0.5744 Loss_G: 3.3597\n",
            "[0/25][695/782] Loss_D: 0.3690 Loss_G: 4.7578\n",
            "[0/25][696/782] Loss_D: 0.4784 Loss_G: 3.5363\n",
            "[0/25][697/782] Loss_D: 0.5685 Loss_G: 4.9404\n",
            "[0/25][698/782] Loss_D: 0.4064 Loss_G: 3.9496\n",
            "[0/25][699/782] Loss_D: 0.3145 Loss_G: 4.7193\n",
            "[0/25][700/782] Loss_D: 0.5064 Loss_G: 4.7407\n",
            "[0/25][701/782] Loss_D: 0.3105 Loss_G: 4.2817\n",
            "[0/25][702/782] Loss_D: 0.3280 Loss_G: 4.7910\n",
            "[0/25][703/782] Loss_D: 0.5946 Loss_G: 4.0653\n",
            "[0/25][704/782] Loss_D: 0.3932 Loss_G: 4.5528\n",
            "[0/25][705/782] Loss_D: 0.4723 Loss_G: 5.6224\n",
            "[0/25][706/782] Loss_D: 0.6114 Loss_G: 3.4107\n",
            "[0/25][707/782] Loss_D: 0.8925 Loss_G: 7.8942\n",
            "[0/25][708/782] Loss_D: 0.1189 Loss_G: 8.3199\n",
            "[0/25][709/782] Loss_D: 0.4303 Loss_G: 4.9312\n",
            "[0/25][710/782] Loss_D: 0.4345 Loss_G: 3.6627\n",
            "[0/25][711/782] Loss_D: 0.4771 Loss_G: 4.8885\n",
            "[0/25][712/782] Loss_D: 0.8519 Loss_G: 4.4265\n",
            "[0/25][713/782] Loss_D: 0.7353 Loss_G: 3.0307\n",
            "[0/25][714/782] Loss_D: 1.0055 Loss_G: 4.1336\n",
            "[0/25][715/782] Loss_D: 0.9919 Loss_G: 6.1422\n",
            "[0/25][716/782] Loss_D: 1.3456 Loss_G: 2.2187\n",
            "[0/25][717/782] Loss_D: 1.1893 Loss_G: 5.3205\n",
            "[0/25][718/782] Loss_D: 1.0651 Loss_G: 3.4425\n",
            "[0/25][719/782] Loss_D: 1.0409 Loss_G: 6.9836\n",
            "[0/25][720/782] Loss_D: 1.3170 Loss_G: 3.2906\n",
            "[0/25][721/782] Loss_D: 0.9442 Loss_G: 4.7203\n",
            "[0/25][722/782] Loss_D: 1.0527 Loss_G: 3.4666\n",
            "[0/25][723/782] Loss_D: 1.2222 Loss_G: 4.9518\n",
            "[0/25][724/782] Loss_D: 1.1203 Loss_G: 2.4651\n",
            "[0/25][725/782] Loss_D: 0.9360 Loss_G: 4.4689\n",
            "[0/25][726/782] Loss_D: 0.6103 Loss_G: 4.6851\n",
            "[0/25][727/782] Loss_D: 0.3593 Loss_G: 3.5653\n",
            "[0/25][728/782] Loss_D: 0.6286 Loss_G: 4.4679\n",
            "[0/25][729/782] Loss_D: 0.6558 Loss_G: 3.3781\n",
            "[0/25][730/782] Loss_D: 1.0310 Loss_G: 4.8776\n",
            "[0/25][731/782] Loss_D: 1.1251 Loss_G: 1.1733\n",
            "[0/25][732/782] Loss_D: 2.2215 Loss_G: 7.8591\n",
            "[0/25][733/782] Loss_D: 3.3821 Loss_G: 1.8279\n",
            "[0/25][734/782] Loss_D: 1.1656 Loss_G: 4.1069\n",
            "[0/25][735/782] Loss_D: 1.0170 Loss_G: 2.1598\n",
            "[0/25][736/782] Loss_D: 1.0556 Loss_G: 3.9132\n",
            "[0/25][737/782] Loss_D: 1.4060 Loss_G: 0.9617\n",
            "[0/25][738/782] Loss_D: 1.1136 Loss_G: 4.0902\n",
            "[0/25][739/782] Loss_D: 0.9053 Loss_G: 2.6355\n",
            "[0/25][740/782] Loss_D: 0.5544 Loss_G: 2.2233\n",
            "[0/25][741/782] Loss_D: 0.5900 Loss_G: 3.3005\n",
            "[0/25][742/782] Loss_D: 0.5370 Loss_G: 2.7059\n",
            "[0/25][743/782] Loss_D: 0.4793 Loss_G: 2.3379\n",
            "[0/25][744/782] Loss_D: 0.5033 Loss_G: 3.6546\n",
            "[0/25][745/782] Loss_D: 0.3413 Loss_G: 3.1070\n",
            "[0/25][746/782] Loss_D: 0.3442 Loss_G: 3.1781\n",
            "[0/25][747/782] Loss_D: 0.3728 Loss_G: 3.0097\n",
            "[0/25][748/782] Loss_D: 0.2703 Loss_G: 3.1706\n",
            "[0/25][749/782] Loss_D: 0.6105 Loss_G: 3.7844\n",
            "[0/25][750/782] Loss_D: 0.6853 Loss_G: 2.7336\n",
            "[0/25][751/782] Loss_D: 0.6248 Loss_G: 3.2614\n",
            "[0/25][752/782] Loss_D: 0.3118 Loss_G: 3.7816\n",
            "[0/25][753/782] Loss_D: 0.5824 Loss_G: 2.3141\n",
            "[0/25][754/782] Loss_D: 0.6608 Loss_G: 4.9406\n",
            "[0/25][755/782] Loss_D: 0.5097 Loss_G: 3.2352\n",
            "[0/25][756/782] Loss_D: 0.4511 Loss_G: 4.7908\n",
            "[0/25][757/782] Loss_D: 0.2584 Loss_G: 4.1079\n",
            "[0/25][758/782] Loss_D: 0.3439 Loss_G: 2.9553\n",
            "[0/25][759/782] Loss_D: 0.3863 Loss_G: 5.1486\n",
            "[0/25][760/782] Loss_D: 0.3818 Loss_G: 3.2639\n",
            "[0/25][761/782] Loss_D: 0.2895 Loss_G: 3.6948\n",
            "[0/25][762/782] Loss_D: 0.2302 Loss_G: 4.5660\n",
            "[0/25][763/782] Loss_D: 0.2508 Loss_G: 3.3240\n",
            "[0/25][764/782] Loss_D: 0.4023 Loss_G: 4.2329\n",
            "[0/25][765/782] Loss_D: 0.2277 Loss_G: 4.1638\n",
            "[0/25][766/782] Loss_D: 0.4931 Loss_G: 2.7750\n",
            "[0/25][767/782] Loss_D: 0.8940 Loss_G: 7.6978\n",
            "[0/25][768/782] Loss_D: 2.3847 Loss_G: 1.6246\n",
            "[0/25][769/782] Loss_D: 1.3460 Loss_G: 6.1948\n",
            "[0/25][770/782] Loss_D: 1.0858 Loss_G: 2.8451\n",
            "[0/25][771/782] Loss_D: 0.7260 Loss_G: 5.5792\n",
            "[0/25][772/782] Loss_D: 0.4604 Loss_G: 4.0955\n",
            "[0/25][773/782] Loss_D: 0.5754 Loss_G: 5.3890\n",
            "[0/25][774/782] Loss_D: 0.9403 Loss_G: 2.7553\n",
            "[0/25][775/782] Loss_D: 1.1165 Loss_G: 5.1340\n",
            "[0/25][776/782] Loss_D: 0.5549 Loss_G: 4.5021\n",
            "[0/25][777/782] Loss_D: 0.6266 Loss_G: 2.8931\n",
            "[0/25][778/782] Loss_D: 0.7943 Loss_G: 3.6967\n",
            "[0/25][779/782] Loss_D: 0.4130 Loss_G: 4.1151\n",
            "[0/25][780/782] Loss_D: 0.5045 Loss_G: 3.6687\n",
            "[0/25][781/782] Loss_D: 0.6878 Loss_G: 4.8919\n",
            "[1/25][0/782] Loss_D: 0.8527 Loss_G: 2.5092\n",
            "[1/25][1/782] Loss_D: 1.0262 Loss_G: 5.9419\n",
            "[1/25][2/782] Loss_D: 0.8473 Loss_G: 3.3164\n",
            "[1/25][3/782] Loss_D: 0.6141 Loss_G: 3.4927\n",
            "[1/25][4/782] Loss_D: 0.5741 Loss_G: 3.4359\n",
            "[1/25][5/782] Loss_D: 0.6378 Loss_G: 4.0752\n",
            "[1/25][6/782] Loss_D: 0.6859 Loss_G: 3.9392\n",
            "[1/25][7/782] Loss_D: 0.6611 Loss_G: 3.3340\n",
            "[1/25][8/782] Loss_D: 0.6253 Loss_G: 4.6059\n",
            "[1/25][9/782] Loss_D: 0.6552 Loss_G: 3.0512\n",
            "[1/25][10/782] Loss_D: 0.7273 Loss_G: 4.0815\n",
            "[1/25][11/782] Loss_D: 0.7576 Loss_G: 3.4995\n",
            "[1/25][12/782] Loss_D: 0.6597 Loss_G: 2.5316\n",
            "[1/25][13/782] Loss_D: 0.6167 Loss_G: 5.2451\n",
            "[1/25][14/782] Loss_D: 0.6758 Loss_G: 2.8718\n",
            "[1/25][15/782] Loss_D: 0.5886 Loss_G: 3.5992\n",
            "[1/25][16/782] Loss_D: 0.4026 Loss_G: 3.1253\n",
            "[1/25][17/782] Loss_D: 0.3271 Loss_G: 3.5069\n",
            "[1/25][18/782] Loss_D: 0.2872 Loss_G: 4.0236\n",
            "[1/25][19/782] Loss_D: 0.2823 Loss_G: 4.0089\n",
            "[1/25][20/782] Loss_D: 0.4851 Loss_G: 2.6126\n",
            "[1/25][21/782] Loss_D: 0.3175 Loss_G: 3.7356\n",
            "[1/25][22/782] Loss_D: 0.3137 Loss_G: 3.2478\n",
            "[1/25][23/782] Loss_D: 0.3803 Loss_G: 4.6539\n",
            "[1/25][24/782] Loss_D: 0.4304 Loss_G: 2.9758\n",
            "[1/25][25/782] Loss_D: 0.3416 Loss_G: 3.0596\n",
            "[1/25][26/782] Loss_D: 0.4028 Loss_G: 3.6534\n",
            "[1/25][27/782] Loss_D: 0.2200 Loss_G: 4.2894\n",
            "[1/25][28/782] Loss_D: 0.4919 Loss_G: 2.6605\n",
            "[1/25][29/782] Loss_D: 0.5264 Loss_G: 2.4382\n",
            "[1/25][30/782] Loss_D: 0.7284 Loss_G: 5.5567\n",
            "[1/25][31/782] Loss_D: 0.6754 Loss_G: 3.4064\n",
            "[1/25][32/782] Loss_D: 0.3269 Loss_G: 2.8350\n",
            "[1/25][33/782] Loss_D: 0.4204 Loss_G: 4.2277\n",
            "[1/25][34/782] Loss_D: 0.3347 Loss_G: 3.9297\n",
            "[1/25][35/782] Loss_D: 0.3002 Loss_G: 3.3124\n",
            "[1/25][36/782] Loss_D: 0.3184 Loss_G: 3.6639\n",
            "[1/25][37/782] Loss_D: 0.2648 Loss_G: 4.0958\n",
            "[1/25][38/782] Loss_D: 0.1914 Loss_G: 3.9466\n",
            "[1/25][39/782] Loss_D: 0.3223 Loss_G: 3.4961\n",
            "[1/25][40/782] Loss_D: 0.3261 Loss_G: 2.4939\n",
            "[1/25][41/782] Loss_D: 0.3953 Loss_G: 5.1195\n",
            "[1/25][42/782] Loss_D: 0.7223 Loss_G: 2.1351\n",
            "[1/25][43/782] Loss_D: 0.4988 Loss_G: 4.4166\n",
            "[1/25][44/782] Loss_D: 0.2351 Loss_G: 4.7193\n",
            "[1/25][45/782] Loss_D: 0.5838 Loss_G: 1.6705\n",
            "[1/25][46/782] Loss_D: 0.8931 Loss_G: 8.0365\n",
            "[1/25][47/782] Loss_D: 0.8723 Loss_G: 2.3649\n",
            "[1/25][48/782] Loss_D: 1.0094 Loss_G: 6.1907\n",
            "[1/25][49/782] Loss_D: 0.7032 Loss_G: 3.6865\n",
            "[1/25][50/782] Loss_D: 0.5489 Loss_G: 4.3801\n",
            "[1/25][51/782] Loss_D: 0.2549 Loss_G: 4.9256\n",
            "[1/25][52/782] Loss_D: 0.6501 Loss_G: 3.4593\n",
            "[1/25][53/782] Loss_D: 0.4021 Loss_G: 4.1925\n",
            "[1/25][54/782] Loss_D: 0.6053 Loss_G: 3.6777\n",
            "[1/25][55/782] Loss_D: 1.1654 Loss_G: 1.8159\n",
            "[1/25][56/782] Loss_D: 0.9207 Loss_G: 5.1561\n",
            "[1/25][57/782] Loss_D: 0.4321 Loss_G: 4.1243\n",
            "[1/25][58/782] Loss_D: 0.3670 Loss_G: 2.8542\n",
            "[1/25][59/782] Loss_D: 0.3175 Loss_G: 4.1165\n",
            "[1/25][60/782] Loss_D: 0.1948 Loss_G: 3.9130\n",
            "[1/25][61/782] Loss_D: 0.2262 Loss_G: 3.0524\n",
            "[1/25][62/782] Loss_D: 0.4795 Loss_G: 4.5993\n",
            "[1/25][63/782] Loss_D: 0.4742 Loss_G: 3.2266\n",
            "[1/25][64/782] Loss_D: 0.7225 Loss_G: 4.2465\n",
            "[1/25][65/782] Loss_D: 0.6136 Loss_G: 2.6456\n",
            "[1/25][66/782] Loss_D: 0.7502 Loss_G: 6.7658\n",
            "[1/25][67/782] Loss_D: 1.4099 Loss_G: 1.8338\n",
            "[1/25][68/782] Loss_D: 2.2267 Loss_G: 6.3572\n",
            "[1/25][69/782] Loss_D: 1.5011 Loss_G: 3.1943\n",
            "[1/25][70/782] Loss_D: 0.2876 Loss_G: 2.6464\n",
            "[1/25][71/782] Loss_D: 0.6858 Loss_G: 4.7490\n",
            "[1/25][72/782] Loss_D: 0.6216 Loss_G: 3.1205\n",
            "[1/25][73/782] Loss_D: 0.5035 Loss_G: 2.5069\n",
            "[1/25][74/782] Loss_D: 0.6451 Loss_G: 4.4099\n",
            "[1/25][75/782] Loss_D: 0.5373 Loss_G: 2.9549\n",
            "[1/25][76/782] Loss_D: 0.6534 Loss_G: 3.0560\n",
            "[1/25][77/782] Loss_D: 0.5877 Loss_G: 2.7863\n",
            "[1/25][78/782] Loss_D: 0.6127 Loss_G: 3.5345\n",
            "[1/25][79/782] Loss_D: 0.4126 Loss_G: 3.3717\n",
            "[1/25][80/782] Loss_D: 0.5802 Loss_G: 3.4274\n",
            "[1/25][81/782] Loss_D: 0.3362 Loss_G: 3.5041\n",
            "[1/25][82/782] Loss_D: 0.7228 Loss_G: 3.4748\n",
            "[1/25][83/782] Loss_D: 0.7008 Loss_G: 2.2756\n",
            "[1/25][84/782] Loss_D: 0.6819 Loss_G: 4.4629\n",
            "[1/25][85/782] Loss_D: 1.2809 Loss_G: 0.8776\n",
            "[1/25][86/782] Loss_D: 1.5501 Loss_G: 6.2172\n",
            "[1/25][87/782] Loss_D: 1.8553 Loss_G: 1.0781\n",
            "[1/25][88/782] Loss_D: 1.0376 Loss_G: 5.2316\n",
            "[1/25][89/782] Loss_D: 0.6888 Loss_G: 3.5828\n",
            "[1/25][90/782] Loss_D: 0.5430 Loss_G: 1.9902\n",
            "[1/25][91/782] Loss_D: 0.5779 Loss_G: 3.8675\n",
            "[1/25][92/782] Loss_D: 0.4140 Loss_G: 3.7161\n",
            "[1/25][93/782] Loss_D: 0.5339 Loss_G: 2.8120\n",
            "[1/25][94/782] Loss_D: 0.7085 Loss_G: 3.1879\n",
            "[1/25][95/782] Loss_D: 0.7910 Loss_G: 2.2641\n",
            "[1/25][96/782] Loss_D: 0.5682 Loss_G: 3.3624\n",
            "[1/25][97/782] Loss_D: 0.3283 Loss_G: 3.3812\n",
            "[1/25][98/782] Loss_D: 0.3792 Loss_G: 3.2817\n",
            "[1/25][99/782] Loss_D: 0.5638 Loss_G: 2.3078\n",
            "[1/25][100/782] Loss_D: 0.8096 Loss_G: 5.2661\n",
            "[1/25][101/782] Loss_D: 1.3149 Loss_G: 1.1147\n",
            "[1/25][102/782] Loss_D: 1.3423 Loss_G: 4.9639\n",
            "[1/25][103/782] Loss_D: 0.4835 Loss_G: 3.7407\n",
            "[1/25][104/782] Loss_D: 1.0114 Loss_G: 0.6954\n",
            "[1/25][105/782] Loss_D: 2.9549 Loss_G: 8.0707\n",
            "[1/25][106/782] Loss_D: 2.5920 Loss_G: 3.1665\n",
            "[1/25][107/782] Loss_D: 0.7566 Loss_G: 1.8868\n",
            "[1/25][108/782] Loss_D: 1.3123 Loss_G: 6.8144\n",
            "[1/25][109/782] Loss_D: 2.1704 Loss_G: 1.3099\n",
            "[1/25][110/782] Loss_D: 1.4931 Loss_G: 3.2668\n",
            "[1/25][111/782] Loss_D: 0.7763 Loss_G: 4.6295\n",
            "[1/25][112/782] Loss_D: 1.5683 Loss_G: 1.1245\n",
            "[1/25][113/782] Loss_D: 0.8871 Loss_G: 3.2380\n",
            "[1/25][114/782] Loss_D: 0.7268 Loss_G: 2.9333\n",
            "[1/25][115/782] Loss_D: 0.6328 Loss_G: 2.7768\n",
            "[1/25][116/782] Loss_D: 0.6621 Loss_G: 3.7111\n",
            "[1/25][117/782] Loss_D: 0.5910 Loss_G: 2.7618\n",
            "[1/25][118/782] Loss_D: 0.7549 Loss_G: 2.8647\n",
            "[1/25][119/782] Loss_D: 0.7446 Loss_G: 2.7993\n",
            "[1/25][120/782] Loss_D: 0.6005 Loss_G: 3.7356\n",
            "[1/25][121/782] Loss_D: 0.7165 Loss_G: 2.7311\n",
            "[1/25][122/782] Loss_D: 0.5573 Loss_G: 3.4408\n",
            "[1/25][123/782] Loss_D: 0.6286 Loss_G: 3.0265\n",
            "[1/25][124/782] Loss_D: 0.6987 Loss_G: 3.5438\n",
            "[1/25][125/782] Loss_D: 0.5424 Loss_G: 3.5189\n",
            "[1/25][126/782] Loss_D: 0.3185 Loss_G: 3.8506\n",
            "[1/25][127/782] Loss_D: 0.3256 Loss_G: 3.6006\n",
            "[1/25][128/782] Loss_D: 0.4323 Loss_G: 2.6823\n",
            "[1/25][129/782] Loss_D: 0.3440 Loss_G: 3.6860\n",
            "[1/25][130/782] Loss_D: 0.5102 Loss_G: 3.8394\n",
            "[1/25][131/782] Loss_D: 0.6050 Loss_G: 2.5851\n",
            "[1/25][132/782] Loss_D: 0.6478 Loss_G: 3.3314\n",
            "[1/25][133/782] Loss_D: 0.3673 Loss_G: 3.2507\n",
            "[1/25][134/782] Loss_D: 0.3224 Loss_G: 2.9665\n",
            "[1/25][135/782] Loss_D: 0.9746 Loss_G: 3.0599\n",
            "[1/25][136/782] Loss_D: 0.6473 Loss_G: 2.3376\n",
            "[1/25][137/782] Loss_D: 0.7400 Loss_G: 3.9040\n",
            "[1/25][138/782] Loss_D: 0.5751 Loss_G: 2.9254\n",
            "[1/25][139/782] Loss_D: 0.5572 Loss_G: 2.6305\n",
            "[1/25][140/782] Loss_D: 0.5698 Loss_G: 3.1056\n",
            "[1/25][141/782] Loss_D: 0.3981 Loss_G: 3.6252\n",
            "[1/25][142/782] Loss_D: 0.2774 Loss_G: 3.3580\n",
            "[1/25][143/782] Loss_D: 0.6462 Loss_G: 2.7013\n",
            "[1/25][144/782] Loss_D: 0.4851 Loss_G: 2.6210\n",
            "[1/25][145/782] Loss_D: 0.5001 Loss_G: 4.0272\n",
            "[1/25][146/782] Loss_D: 0.5591 Loss_G: 3.0142\n",
            "[1/25][147/782] Loss_D: 0.5422 Loss_G: 3.0515\n",
            "[1/25][148/782] Loss_D: 0.5177 Loss_G: 3.8015\n",
            "[1/25][149/782] Loss_D: 0.3983 Loss_G: 3.5129\n",
            "[1/25][150/782] Loss_D: 0.2692 Loss_G: 3.2443\n",
            "[1/25][151/782] Loss_D: 0.5863 Loss_G: 4.4907\n",
            "[1/25][152/782] Loss_D: 0.5065 Loss_G: 2.5520\n",
            "[1/25][153/782] Loss_D: 0.4119 Loss_G: 3.8542\n",
            "[1/25][154/782] Loss_D: 0.3428 Loss_G: 3.7623\n",
            "[1/25][155/782] Loss_D: 0.3353 Loss_G: 3.6322\n",
            "[1/25][156/782] Loss_D: 0.4011 Loss_G: 3.3296\n",
            "[1/25][157/782] Loss_D: 0.4362 Loss_G: 4.6095\n",
            "[1/25][158/782] Loss_D: 0.6477 Loss_G: 2.2970\n",
            "[1/25][159/782] Loss_D: 0.8329 Loss_G: 5.6412\n",
            "[1/25][160/782] Loss_D: 0.6826 Loss_G: 2.4923\n",
            "[1/25][161/782] Loss_D: 0.7916 Loss_G: 4.9162\n",
            "[1/25][162/782] Loss_D: 0.4043 Loss_G: 5.3086\n",
            "[1/25][163/782] Loss_D: 0.9064 Loss_G: 1.0981\n",
            "[1/25][164/782] Loss_D: 1.3380 Loss_G: 7.1427\n",
            "[1/25][165/782] Loss_D: 0.8156 Loss_G: 4.3691\n",
            "[1/25][166/782] Loss_D: 0.2935 Loss_G: 2.7138\n",
            "[1/25][167/782] Loss_D: 0.2673 Loss_G: 4.3396\n",
            "[1/25][168/782] Loss_D: 0.2508 Loss_G: 4.7232\n",
            "[1/25][169/782] Loss_D: 0.3274 Loss_G: 3.2527\n",
            "[1/25][170/782] Loss_D: 0.3747 Loss_G: 4.6325\n",
            "[1/25][171/782] Loss_D: 0.5386 Loss_G: 2.6756\n",
            "[1/25][172/782] Loss_D: 0.4049 Loss_G: 4.7949\n",
            "[1/25][173/782] Loss_D: 0.4207 Loss_G: 3.1265\n",
            "[1/25][174/782] Loss_D: 0.4817 Loss_G: 5.3271\n",
            "[1/25][175/782] Loss_D: 0.4357 Loss_G: 2.9775\n",
            "[1/25][176/782] Loss_D: 0.6082 Loss_G: 6.0714\n",
            "[1/25][177/782] Loss_D: 0.9087 Loss_G: 1.2900\n",
            "[1/25][178/782] Loss_D: 1.1670 Loss_G: 7.8406\n",
            "[1/25][179/782] Loss_D: 0.7628 Loss_G: 4.1302\n",
            "[1/25][180/782] Loss_D: 0.4564 Loss_G: 1.0578\n",
            "[1/25][181/782] Loss_D: 1.1848 Loss_G: 6.3754\n",
            "[1/25][182/782] Loss_D: 0.7750 Loss_G: 3.3844\n",
            "[1/25][183/782] Loss_D: 0.2782 Loss_G: 2.8749\n",
            "[1/25][184/782] Loss_D: 0.6130 Loss_G: 3.7407\n",
            "[1/25][185/782] Loss_D: 0.7996 Loss_G: 2.8302\n",
            "[1/25][186/782] Loss_D: 0.2898 Loss_G: 4.0404\n",
            "[1/25][187/782] Loss_D: 0.6719 Loss_G: 2.4904\n",
            "[1/25][188/782] Loss_D: 1.1217 Loss_G: 5.5174\n",
            "[1/25][189/782] Loss_D: 0.5687 Loss_G: 3.7822\n",
            "[1/25][190/782] Loss_D: 0.3872 Loss_G: 3.1654\n",
            "[1/25][191/782] Loss_D: 0.3635 Loss_G: 5.0317\n",
            "[1/25][192/782] Loss_D: 0.3505 Loss_G: 3.4660\n",
            "[1/25][193/782] Loss_D: 0.3315 Loss_G: 4.4503\n",
            "[1/25][194/782] Loss_D: 0.4914 Loss_G: 2.7539\n",
            "[1/25][195/782] Loss_D: 0.9941 Loss_G: 7.7418\n",
            "[1/25][196/782] Loss_D: 1.5243 Loss_G: 2.9336\n",
            "[1/25][197/782] Loss_D: 0.8525 Loss_G: 5.0444\n",
            "[1/25][198/782] Loss_D: 0.6416 Loss_G: 3.0573\n",
            "[1/25][199/782] Loss_D: 0.4116 Loss_G: 5.0865\n",
            "[1/25][200/782] Loss_D: 0.1958 Loss_G: 4.8247\n",
            "[1/25][201/782] Loss_D: 0.2608 Loss_G: 3.6753\n",
            "[1/25][202/782] Loss_D: 0.4697 Loss_G: 4.4873\n",
            "[1/25][203/782] Loss_D: 0.4704 Loss_G: 3.4568\n",
            "[1/25][204/782] Loss_D: 0.3807 Loss_G: 3.9281\n",
            "[1/25][205/782] Loss_D: 0.4581 Loss_G: 4.0914\n",
            "[1/25][206/782] Loss_D: 0.2602 Loss_G: 3.9949\n",
            "[1/25][207/782] Loss_D: 0.3481 Loss_G: 3.2657\n",
            "[1/25][208/782] Loss_D: 0.3149 Loss_G: 4.0448\n",
            "[1/25][209/782] Loss_D: 0.1417 Loss_G: 4.5090\n",
            "[1/25][210/782] Loss_D: 0.1271 Loss_G: 4.3970\n",
            "[1/25][211/782] Loss_D: 0.1550 Loss_G: 4.1428\n",
            "[1/25][212/782] Loss_D: 0.1878 Loss_G: 4.2731\n",
            "[1/25][213/782] Loss_D: 0.3217 Loss_G: 3.7035\n",
            "[1/25][214/782] Loss_D: 0.1296 Loss_G: 4.4371\n",
            "[1/25][215/782] Loss_D: 0.2188 Loss_G: 3.9540\n",
            "[1/25][216/782] Loss_D: 0.1302 Loss_G: 4.2555\n",
            "[1/25][217/782] Loss_D: 0.1971 Loss_G: 3.8650\n",
            "[1/25][218/782] Loss_D: 0.4271 Loss_G: 4.9289\n",
            "[1/25][219/782] Loss_D: 0.3397 Loss_G: 3.8303\n",
            "[1/25][220/782] Loss_D: 0.5710 Loss_G: 3.4094\n",
            "[1/25][221/782] Loss_D: 0.3011 Loss_G: 4.1565\n",
            "[1/25][222/782] Loss_D: 0.3464 Loss_G: 5.5543\n",
            "[1/25][223/782] Loss_D: 0.5790 Loss_G: 2.6367\n",
            "[1/25][224/782] Loss_D: 0.5698 Loss_G: 5.9359\n",
            "[1/25][225/782] Loss_D: 0.3639 Loss_G: 4.1298\n",
            "[1/25][226/782] Loss_D: 0.1500 Loss_G: 3.7370\n",
            "[1/25][227/782] Loss_D: 0.2980 Loss_G: 4.4190\n",
            "[1/25][228/782] Loss_D: 0.2242 Loss_G: 4.5771\n",
            "[1/25][229/782] Loss_D: 0.2417 Loss_G: 3.5266\n",
            "[1/25][230/782] Loss_D: 0.3001 Loss_G: 2.8264\n",
            "[1/25][231/782] Loss_D: 0.5490 Loss_G: 5.4072\n",
            "[1/25][232/782] Loss_D: 0.5882 Loss_G: 2.3146\n",
            "[1/25][233/782] Loss_D: 0.7085 Loss_G: 4.5813\n",
            "[1/25][234/782] Loss_D: 0.9613 Loss_G: 1.2754\n",
            "[1/25][235/782] Loss_D: 1.6502 Loss_G: 8.5132\n",
            "[1/25][236/782] Loss_D: 2.0816 Loss_G: 2.7718\n",
            "[1/25][237/782] Loss_D: 0.5070 Loss_G: 3.1363\n",
            "[1/25][238/782] Loss_D: 0.6691 Loss_G: 4.5806\n",
            "[1/25][239/782] Loss_D: 0.4078 Loss_G: 3.3640\n",
            "[1/25][240/782] Loss_D: 0.9080 Loss_G: 2.6804\n",
            "[1/25][241/782] Loss_D: 1.0250 Loss_G: 5.1197\n",
            "[1/25][242/782] Loss_D: 1.3375 Loss_G: 0.9506\n",
            "[1/25][243/782] Loss_D: 1.0791 Loss_G: 6.7125\n",
            "[1/25][244/782] Loss_D: 0.8760 Loss_G: 3.1901\n",
            "[1/25][245/782] Loss_D: 0.2387 Loss_G: 3.3627\n",
            "[1/25][246/782] Loss_D: 0.2993 Loss_G: 4.3343\n",
            "[1/25][247/782] Loss_D: 0.3055 Loss_G: 3.3218\n",
            "[1/25][248/782] Loss_D: 0.5014 Loss_G: 3.7649\n",
            "[1/25][249/782] Loss_D: 0.3789 Loss_G: 3.5671\n",
            "[1/25][250/782] Loss_D: 0.7130 Loss_G: 1.3881\n",
            "[1/25][251/782] Loss_D: 1.9372 Loss_G: 7.9242\n",
            "[1/25][252/782] Loss_D: 2.2291 Loss_G: 3.5130\n",
            "[1/25][253/782] Loss_D: 0.3140 Loss_G: 1.7885\n",
            "[1/25][254/782] Loss_D: 0.4662 Loss_G: 4.1857\n",
            "[1/25][255/782] Loss_D: 0.2175 Loss_G: 4.8250\n",
            "[1/25][256/782] Loss_D: 0.4482 Loss_G: 3.0324\n",
            "[1/25][257/782] Loss_D: 0.3860 Loss_G: 2.9452\n",
            "[1/25][258/782] Loss_D: 0.9138 Loss_G: 6.2749\n",
            "[1/25][259/782] Loss_D: 1.1429 Loss_G: 2.7431\n",
            "[1/25][260/782] Loss_D: 0.2625 Loss_G: 3.7125\n",
            "[1/25][261/782] Loss_D: 0.4316 Loss_G: 5.1711\n",
            "[1/25][262/782] Loss_D: 0.3042 Loss_G: 3.7320\n",
            "[1/25][263/782] Loss_D: 0.3680 Loss_G: 3.6975\n",
            "[1/25][264/782] Loss_D: 0.2784 Loss_G: 4.3693\n",
            "[1/25][265/782] Loss_D: 0.6985 Loss_G: 2.6578\n",
            "[1/25][266/782] Loss_D: 0.9387 Loss_G: 6.1234\n",
            "[1/25][267/782] Loss_D: 1.4995 Loss_G: 1.8309\n",
            "[1/25][268/782] Loss_D: 1.0877 Loss_G: 7.6275\n",
            "[1/25][269/782] Loss_D: 0.9605 Loss_G: 4.5353\n",
            "[1/25][270/782] Loss_D: 0.2303 Loss_G: 3.3114\n",
            "[1/25][271/782] Loss_D: 0.4151 Loss_G: 4.7729\n",
            "[1/25][272/782] Loss_D: 0.3691 Loss_G: 6.0513\n",
            "[1/25][273/782] Loss_D: 0.5407 Loss_G: 3.4145\n",
            "[1/25][274/782] Loss_D: 0.6298 Loss_G: 5.4676\n",
            "[1/25][275/782] Loss_D: 0.8108 Loss_G: 2.5219\n",
            "[1/25][276/782] Loss_D: 0.6981 Loss_G: 4.7764\n",
            "[1/25][277/782] Loss_D: 0.4805 Loss_G: 3.0988\n",
            "[1/25][278/782] Loss_D: 0.3099 Loss_G: 3.9789\n",
            "[1/25][279/782] Loss_D: 0.5092 Loss_G: 6.3135\n",
            "[1/25][280/782] Loss_D: 1.0903 Loss_G: 1.4423\n",
            "[1/25][281/782] Loss_D: 0.8872 Loss_G: 6.0144\n",
            "[1/25][282/782] Loss_D: 0.7556 Loss_G: 2.9809\n",
            "[1/25][283/782] Loss_D: 0.6454 Loss_G: 5.7168\n",
            "[1/25][284/782] Loss_D: 0.3125 Loss_G: 4.7751\n",
            "[1/25][285/782] Loss_D: 0.3510 Loss_G: 3.8219\n",
            "[1/25][286/782] Loss_D: 0.4203 Loss_G: 4.3348\n",
            "[1/25][287/782] Loss_D: 0.6140 Loss_G: 2.4765\n",
            "[1/25][288/782] Loss_D: 0.6134 Loss_G: 6.0157\n",
            "[1/25][289/782] Loss_D: 0.4625 Loss_G: 3.6535\n",
            "[1/25][290/782] Loss_D: 0.2461 Loss_G: 2.7842\n",
            "[1/25][291/782] Loss_D: 0.8203 Loss_G: 6.9146\n",
            "[1/25][292/782] Loss_D: 0.6877 Loss_G: 4.2888\n",
            "[1/25][293/782] Loss_D: 0.2798 Loss_G: 2.6412\n",
            "[1/25][294/782] Loss_D: 0.5844 Loss_G: 6.2535\n",
            "[1/25][295/782] Loss_D: 0.5273 Loss_G: 3.5055\n",
            "[1/25][296/782] Loss_D: 0.5838 Loss_G: 5.4575\n",
            "[1/25][297/782] Loss_D: 0.4058 Loss_G: 4.6667\n",
            "[1/25][298/782] Loss_D: 1.1353 Loss_G: 1.5359\n",
            "[1/25][299/782] Loss_D: 1.4623 Loss_G: 8.8127\n",
            "[1/25][300/782] Loss_D: 2.9647 Loss_G: 0.4031\n",
            "[1/25][301/782] Loss_D: 2.2099 Loss_G: 8.5414\n",
            "[1/25][302/782] Loss_D: 1.8659 Loss_G: 2.6091\n",
            "[1/25][303/782] Loss_D: 0.9048 Loss_G: 2.9507\n",
            "[1/25][304/782] Loss_D: 0.7653 Loss_G: 5.7464\n",
            "[1/25][305/782] Loss_D: 0.9964 Loss_G: 3.3589\n",
            "[1/25][306/782] Loss_D: 0.8817 Loss_G: 4.0340\n",
            "[1/25][307/782] Loss_D: 0.6934 Loss_G: 3.2038\n",
            "[1/25][308/782] Loss_D: 0.8921 Loss_G: 5.0169\n",
            "[1/25][309/782] Loss_D: 0.8201 Loss_G: 2.7431\n",
            "[1/25][310/782] Loss_D: 1.0536 Loss_G: 3.8066\n",
            "[1/25][311/782] Loss_D: 0.9142 Loss_G: 4.0494\n",
            "[1/25][312/782] Loss_D: 0.4321 Loss_G: 4.5294\n",
            "[1/25][313/782] Loss_D: 0.6693 Loss_G: 2.7114\n",
            "[1/25][314/782] Loss_D: 0.7227 Loss_G: 4.5135\n",
            "[1/25][315/782] Loss_D: 0.7507 Loss_G: 2.7055\n",
            "[1/25][316/782] Loss_D: 0.4467 Loss_G: 5.3121\n",
            "[1/25][317/782] Loss_D: 0.5125 Loss_G: 3.2707\n",
            "[1/25][318/782] Loss_D: 0.3560 Loss_G: 3.9338\n",
            "[1/25][319/782] Loss_D: 0.3663 Loss_G: 4.1625\n",
            "[1/25][320/782] Loss_D: 0.3946 Loss_G: 2.9681\n",
            "[1/25][321/782] Loss_D: 0.6123 Loss_G: 4.0992\n",
            "[1/25][322/782] Loss_D: 0.4509 Loss_G: 3.2621\n",
            "[1/25][323/782] Loss_D: 0.4960 Loss_G: 4.9660\n",
            "[1/25][324/782] Loss_D: 0.7543 Loss_G: 2.1066\n",
            "[1/25][325/782] Loss_D: 0.6460 Loss_G: 5.0791\n",
            "[1/25][326/782] Loss_D: 0.3374 Loss_G: 4.4560\n",
            "[1/25][327/782] Loss_D: 0.4441 Loss_G: 2.7408\n",
            "[1/25][328/782] Loss_D: 0.6538 Loss_G: 5.1090\n",
            "[1/25][329/782] Loss_D: 0.3986 Loss_G: 3.7385\n",
            "[1/25][330/782] Loss_D: 0.4484 Loss_G: 5.4220\n",
            "[1/25][331/782] Loss_D: 0.5903 Loss_G: 3.4217\n",
            "[1/25][332/782] Loss_D: 0.3565 Loss_G: 4.1289\n",
            "[1/25][333/782] Loss_D: 0.3652 Loss_G: 3.8154\n",
            "[1/25][334/782] Loss_D: 0.3753 Loss_G: 4.5056\n",
            "[1/25][335/782] Loss_D: 0.1849 Loss_G: 4.5292\n",
            "[1/25][336/782] Loss_D: 0.4693 Loss_G: 5.0406\n",
            "[1/25][337/782] Loss_D: 0.5584 Loss_G: 2.8749\n",
            "[1/25][338/782] Loss_D: 0.6467 Loss_G: 5.4758\n",
            "[1/25][339/782] Loss_D: 0.6287 Loss_G: 2.7463\n",
            "[1/25][340/782] Loss_D: 0.4727 Loss_G: 4.8066\n",
            "[1/25][341/782] Loss_D: 0.4112 Loss_G: 3.2762\n",
            "[1/25][342/782] Loss_D: 0.4679 Loss_G: 3.5244\n",
            "[1/25][343/782] Loss_D: 0.7070 Loss_G: 6.3423\n",
            "[1/25][344/782] Loss_D: 1.6182 Loss_G: 1.6839\n",
            "[1/25][345/782] Loss_D: 1.4416 Loss_G: 6.4234\n",
            "[1/25][346/782] Loss_D: 1.1548 Loss_G: 1.3845\n",
            "[1/25][347/782] Loss_D: 1.4960 Loss_G: 5.7283\n",
            "[1/25][348/782] Loss_D: 1.3606 Loss_G: 2.4665\n",
            "[1/25][349/782] Loss_D: 0.6877 Loss_G: 3.3525\n",
            "[1/25][350/782] Loss_D: 0.4922 Loss_G: 5.5132\n",
            "[1/25][351/782] Loss_D: 0.4745 Loss_G: 3.8041\n",
            "[1/25][352/782] Loss_D: 0.4777 Loss_G: 3.2414\n",
            "[1/25][353/782] Loss_D: 0.6446 Loss_G: 5.0933\n",
            "[1/25][354/782] Loss_D: 0.5325 Loss_G: 3.3345\n",
            "[1/25][355/782] Loss_D: 0.5800 Loss_G: 2.9910\n",
            "[1/25][356/782] Loss_D: 0.7823 Loss_G: 5.8198\n",
            "[1/25][357/782] Loss_D: 0.8433 Loss_G: 3.0307\n",
            "[1/25][358/782] Loss_D: 0.7936 Loss_G: 3.7418\n",
            "[1/25][359/782] Loss_D: 0.4461 Loss_G: 4.2628\n",
            "[1/25][360/782] Loss_D: 0.5600 Loss_G: 3.6957\n",
            "[1/25][361/782] Loss_D: 0.9045 Loss_G: 1.8838\n",
            "[1/25][362/782] Loss_D: 0.9013 Loss_G: 6.8162\n",
            "[1/25][363/782] Loss_D: 0.5539 Loss_G: 3.8425\n",
            "[1/25][364/782] Loss_D: 0.4054 Loss_G: 2.8842\n",
            "[1/25][365/782] Loss_D: 0.7005 Loss_G: 5.8763\n",
            "[1/25][366/782] Loss_D: 0.4794 Loss_G: 3.9753\n",
            "[1/25][367/782] Loss_D: 0.3176 Loss_G: 2.7631\n",
            "[1/25][368/782] Loss_D: 0.4732 Loss_G: 3.6523\n",
            "[1/25][369/782] Loss_D: 0.3194 Loss_G: 3.8638\n",
            "[1/25][370/782] Loss_D: 0.6733 Loss_G: 2.1181\n",
            "[1/25][371/782] Loss_D: 0.6691 Loss_G: 5.0651\n",
            "[1/25][372/782] Loss_D: 0.6725 Loss_G: 2.6153\n",
            "[1/25][373/782] Loss_D: 0.5643 Loss_G: 4.0230\n",
            "[1/25][374/782] Loss_D: 0.1496 Loss_G: 4.7257\n",
            "[1/25][375/782] Loss_D: 0.2192 Loss_G: 3.7543\n",
            "[1/25][376/782] Loss_D: 0.4963 Loss_G: 2.1141\n",
            "[1/25][377/782] Loss_D: 1.1142 Loss_G: 6.5963\n",
            "[1/25][378/782] Loss_D: 0.7369 Loss_G: 3.8113\n",
            "[1/25][379/782] Loss_D: 0.4298 Loss_G: 2.0391\n",
            "[1/25][380/782] Loss_D: 0.7257 Loss_G: 6.2967\n",
            "[1/25][381/782] Loss_D: 1.1538 Loss_G: 2.4919\n",
            "[1/25][382/782] Loss_D: 0.7171 Loss_G: 5.5851\n",
            "[1/25][383/782] Loss_D: 0.5883 Loss_G: 2.9018\n",
            "[1/25][384/782] Loss_D: 0.7892 Loss_G: 6.2524\n",
            "[1/25][385/782] Loss_D: 0.4544 Loss_G: 4.6017\n",
            "[1/25][386/782] Loss_D: 0.4067 Loss_G: 3.0837\n",
            "[1/25][387/782] Loss_D: 0.5186 Loss_G: 5.6055\n",
            "[1/25][388/782] Loss_D: 0.7689 Loss_G: 2.4614\n",
            "[1/25][389/782] Loss_D: 0.4643 Loss_G: 4.6511\n",
            "[1/25][390/782] Loss_D: 0.3403 Loss_G: 4.3760\n",
            "[1/25][391/782] Loss_D: 0.4363 Loss_G: 2.7786\n",
            "[1/25][392/782] Loss_D: 0.4575 Loss_G: 4.4754\n",
            "[1/25][393/782] Loss_D: 0.2137 Loss_G: 4.9715\n",
            "[1/25][394/782] Loss_D: 0.3055 Loss_G: 3.7738\n",
            "[1/25][395/782] Loss_D: 0.3239 Loss_G: 3.5137\n",
            "[1/25][396/782] Loss_D: 0.3049 Loss_G: 3.5088\n",
            "[1/25][397/782] Loss_D: 0.5657 Loss_G: 4.0562\n",
            "[1/25][398/782] Loss_D: 0.4282 Loss_G: 4.5809\n",
            "[1/25][399/782] Loss_D: 0.5023 Loss_G: 2.6446\n",
            "[1/25][400/782] Loss_D: 0.7630 Loss_G: 4.5013\n",
            "[1/25][401/782] Loss_D: 0.6679 Loss_G: 2.3511\n",
            "[1/25][402/782] Loss_D: 0.7485 Loss_G: 4.5852\n",
            "[1/25][403/782] Loss_D: 0.4864 Loss_G: 3.8573\n",
            "[1/25][404/782] Loss_D: 0.4259 Loss_G: 2.4873\n",
            "[1/25][405/782] Loss_D: 0.6300 Loss_G: 3.9393\n",
            "[1/25][406/782] Loss_D: 0.4272 Loss_G: 4.1421\n",
            "[1/25][407/782] Loss_D: 0.2146 Loss_G: 3.8156\n",
            "[1/25][408/782] Loss_D: 0.4545 Loss_G: 3.9926\n",
            "[1/25][409/782] Loss_D: 0.5010 Loss_G: 3.3067\n",
            "[1/25][410/782] Loss_D: 0.5168 Loss_G: 3.9403\n",
            "[1/25][411/782] Loss_D: 0.3615 Loss_G: 4.2295\n",
            "[1/25][412/782] Loss_D: 0.3789 Loss_G: 3.0545\n",
            "[1/25][413/782] Loss_D: 0.3334 Loss_G: 3.9042\n",
            "[1/25][414/782] Loss_D: 0.2989 Loss_G: 3.9983\n",
            "[1/25][415/782] Loss_D: 0.2119 Loss_G: 4.6274\n",
            "[1/25][416/782] Loss_D: 0.2964 Loss_G: 3.2904\n",
            "[1/25][417/782] Loss_D: 0.6177 Loss_G: 1.9002\n",
            "[1/25][418/782] Loss_D: 1.2477 Loss_G: 8.0014\n",
            "[1/25][419/782] Loss_D: 0.8498 Loss_G: 5.5634\n",
            "[1/25][420/782] Loss_D: 0.2767 Loss_G: 2.5056\n",
            "[1/25][421/782] Loss_D: 0.8097 Loss_G: 4.9582\n",
            "[1/25][422/782] Loss_D: 0.5684 Loss_G: 3.4382\n",
            "[1/25][423/782] Loss_D: 0.6519 Loss_G: 5.3319\n",
            "[1/25][424/782] Loss_D: 0.6126 Loss_G: 2.8729\n",
            "[1/25][425/782] Loss_D: 0.5701 Loss_G: 3.1360\n",
            "[1/25][426/782] Loss_D: 0.6633 Loss_G: 5.2175\n",
            "[1/25][427/782] Loss_D: 0.5129 Loss_G: 3.3334\n",
            "[1/25][428/782] Loss_D: 0.5435 Loss_G: 3.9569\n",
            "[1/25][429/782] Loss_D: 0.4639 Loss_G: 3.5910\n",
            "[1/25][430/782] Loss_D: 0.4483 Loss_G: 2.5636\n",
            "[1/25][431/782] Loss_D: 0.6503 Loss_G: 6.5564\n",
            "[1/25][432/782] Loss_D: 0.7815 Loss_G: 1.6503\n",
            "[1/25][433/782] Loss_D: 0.7798 Loss_G: 5.2403\n",
            "[1/25][434/782] Loss_D: 0.2765 Loss_G: 4.5415\n",
            "[1/25][435/782] Loss_D: 0.3251 Loss_G: 2.8176\n",
            "[1/25][436/782] Loss_D: 0.5526 Loss_G: 5.7627\n",
            "[1/25][437/782] Loss_D: 0.4145 Loss_G: 4.0228\n",
            "[1/25][438/782] Loss_D: 0.4591 Loss_G: 3.3496\n",
            "[1/25][439/782] Loss_D: 0.3723 Loss_G: 4.6752\n",
            "[1/25][440/782] Loss_D: 0.3155 Loss_G: 3.9882\n",
            "[1/25][441/782] Loss_D: 0.4676 Loss_G: 4.1752\n",
            "[1/25][442/782] Loss_D: 0.4307 Loss_G: 4.7115\n",
            "[1/25][443/782] Loss_D: 0.3842 Loss_G: 3.2235\n",
            "[1/25][444/782] Loss_D: 0.4357 Loss_G: 5.2929\n",
            "[1/25][445/782] Loss_D: 0.5166 Loss_G: 2.6040\n",
            "[1/25][446/782] Loss_D: 0.6857 Loss_G: 7.6562\n",
            "[1/25][447/782] Loss_D: 0.5995 Loss_G: 4.1798\n",
            "[1/25][448/782] Loss_D: 0.3034 Loss_G: 5.1204\n",
            "[1/25][449/782] Loss_D: 0.2845 Loss_G: 5.5915\n",
            "[1/25][450/782] Loss_D: 0.7871 Loss_G: 1.6508\n",
            "[1/25][451/782] Loss_D: 1.2388 Loss_G: 7.8837\n",
            "[1/25][452/782] Loss_D: 1.4281 Loss_G: 0.9335\n",
            "[1/25][453/782] Loss_D: 2.3807 Loss_G: 8.2490\n",
            "[1/25][454/782] Loss_D: 1.4655 Loss_G: 4.4349\n",
            "[1/25][455/782] Loss_D: 0.8381 Loss_G: 2.0514\n",
            "[1/25][456/782] Loss_D: 1.0002 Loss_G: 8.7184\n",
            "[1/25][457/782] Loss_D: 1.3464 Loss_G: 1.6566\n",
            "[1/25][458/782] Loss_D: 0.9452 Loss_G: 6.1478\n",
            "[1/25][459/782] Loss_D: 0.3439 Loss_G: 5.1249\n",
            "[1/25][460/782] Loss_D: 0.5154 Loss_G: 2.7434\n",
            "[1/25][461/782] Loss_D: 0.8374 Loss_G: 5.6729\n",
            "[1/25][462/782] Loss_D: 0.5128 Loss_G: 3.4630\n",
            "[1/25][463/782] Loss_D: 0.6264 Loss_G: 3.7351\n",
            "[1/25][464/782] Loss_D: 0.6432 Loss_G: 2.8460\n",
            "[1/25][465/782] Loss_D: 0.4751 Loss_G: 4.3923\n",
            "[1/25][466/782] Loss_D: 0.3432 Loss_G: 3.8074\n",
            "[1/25][467/782] Loss_D: 0.3003 Loss_G: 3.3450\n",
            "[1/25][468/782] Loss_D: 0.4660 Loss_G: 4.4703\n",
            "[1/25][469/782] Loss_D: 0.3962 Loss_G: 3.7691\n",
            "[1/25][470/782] Loss_D: 0.3751 Loss_G: 3.3195\n",
            "[1/25][471/782] Loss_D: 0.6261 Loss_G: 4.6395\n",
            "[1/25][472/782] Loss_D: 0.9670 Loss_G: 2.4223\n",
            "[1/25][473/782] Loss_D: 0.9032 Loss_G: 3.8639\n",
            "[1/25][474/782] Loss_D: 0.6766 Loss_G: 4.0124\n",
            "[1/25][475/782] Loss_D: 0.3728 Loss_G: 4.3198\n",
            "[1/25][476/782] Loss_D: 0.4203 Loss_G: 2.8889\n",
            "[1/25][477/782] Loss_D: 0.4848 Loss_G: 6.1229\n",
            "[1/25][478/782] Loss_D: 0.4305 Loss_G: 4.5914\n",
            "[1/25][479/782] Loss_D: 0.3098 Loss_G: 3.3285\n",
            "[1/25][480/782] Loss_D: 0.6255 Loss_G: 5.4070\n",
            "[1/25][481/782] Loss_D: 0.5682 Loss_G: 2.9740\n",
            "[1/25][482/782] Loss_D: 0.6529 Loss_G: 4.6853\n",
            "[1/25][483/782] Loss_D: 0.3638 Loss_G: 4.0572\n",
            "[1/25][484/782] Loss_D: 0.5301 Loss_G: 2.5554\n",
            "[1/25][485/782] Loss_D: 0.5788 Loss_G: 5.1218\n",
            "[1/25][486/782] Loss_D: 0.5968 Loss_G: 3.1574\n",
            "[1/25][487/782] Loss_D: 0.7022 Loss_G: 5.9811\n",
            "[1/25][488/782] Loss_D: 0.6689 Loss_G: 2.8749\n",
            "[1/25][489/782] Loss_D: 0.9565 Loss_G: 5.9989\n",
            "[1/25][490/782] Loss_D: 0.6077 Loss_G: 3.7391\n",
            "[1/25][491/782] Loss_D: 0.3400 Loss_G: 2.3108\n",
            "[1/25][492/782] Loss_D: 0.5853 Loss_G: 5.5699\n",
            "[1/25][493/782] Loss_D: 0.2747 Loss_G: 4.7179\n",
            "[1/25][494/782] Loss_D: 0.3724 Loss_G: 2.8242\n",
            "[1/25][495/782] Loss_D: 0.5334 Loss_G: 5.2559\n",
            "[1/25][496/782] Loss_D: 0.7778 Loss_G: 2.0410\n",
            "[1/25][497/782] Loss_D: 1.1194 Loss_G: 6.6013\n",
            "[1/25][498/782] Loss_D: 0.4810 Loss_G: 4.3058\n",
            "[1/25][499/782] Loss_D: 0.3272 Loss_G: 2.2920\n",
            "[1/25][500/782] Loss_D: 0.5780 Loss_G: 5.2182\n",
            "[1/25][501/782] Loss_D: 0.6170 Loss_G: 4.0529\n",
            "[1/25][502/782] Loss_D: 0.4066 Loss_G: 2.8500\n",
            "[1/25][503/782] Loss_D: 0.3290 Loss_G: 3.7880\n",
            "[1/25][504/782] Loss_D: 0.3670 Loss_G: 4.5819\n",
            "[1/25][505/782] Loss_D: 0.5625 Loss_G: 2.3414\n",
            "[1/25][506/782] Loss_D: 0.4656 Loss_G: 3.8753\n",
            "[1/25][507/782] Loss_D: 0.4231 Loss_G: 3.2096\n",
            "[1/25][508/782] Loss_D: 0.7130 Loss_G: 5.3498\n",
            "[1/25][509/782] Loss_D: 0.4243 Loss_G: 3.8752\n",
            "[1/25][510/782] Loss_D: 0.2887 Loss_G: 2.5073\n",
            "[1/25][511/782] Loss_D: 0.5275 Loss_G: 5.2509\n",
            "[1/25][512/782] Loss_D: 0.2812 Loss_G: 4.3969\n",
            "[1/25][513/782] Loss_D: 0.3495 Loss_G: 2.8360\n",
            "[1/25][514/782] Loss_D: 0.5464 Loss_G: 3.1060\n",
            "[1/25][515/782] Loss_D: 0.5229 Loss_G: 3.9948\n",
            "[1/25][516/782] Loss_D: 0.4683 Loss_G: 2.1197\n",
            "[1/25][517/782] Loss_D: 0.7640 Loss_G: 5.3961\n",
            "[1/25][518/782] Loss_D: 0.5731 Loss_G: 3.6343\n",
            "[1/25][519/782] Loss_D: 0.2538 Loss_G: 3.2715\n",
            "[1/25][520/782] Loss_D: 0.1955 Loss_G: 3.8173\n",
            "[1/25][521/782] Loss_D: 0.3319 Loss_G: 3.7139\n",
            "[1/25][522/782] Loss_D: 0.5004 Loss_G: 3.6140\n",
            "[1/25][523/782] Loss_D: 0.4972 Loss_G: 4.0325\n",
            "[1/25][524/782] Loss_D: 0.3247 Loss_G: 2.9300\n",
            "[1/25][525/782] Loss_D: 0.5840 Loss_G: 5.6551\n",
            "[1/25][526/782] Loss_D: 0.7824 Loss_G: 1.5649\n",
            "[1/25][527/782] Loss_D: 1.0278 Loss_G: 7.8901\n",
            "[1/25][528/782] Loss_D: 0.7341 Loss_G: 5.2194\n",
            "[1/25][529/782] Loss_D: 0.3122 Loss_G: 2.6482\n",
            "[1/25][530/782] Loss_D: 0.9316 Loss_G: 6.7271\n",
            "[1/25][531/782] Loss_D: 1.0646 Loss_G: 2.1608\n",
            "[1/25][532/782] Loss_D: 0.6873 Loss_G: 5.4302\n",
            "[1/25][533/782] Loss_D: 0.6361 Loss_G: 3.2271\n",
            "[1/25][534/782] Loss_D: 0.5136 Loss_G: 3.4244\n",
            "[1/25][535/782] Loss_D: 0.5865 Loss_G: 4.5602\n",
            "[1/25][536/782] Loss_D: 0.3154 Loss_G: 3.4970\n",
            "[1/25][537/782] Loss_D: 0.6938 Loss_G: 3.3713\n",
            "[1/25][538/782] Loss_D: 0.5240 Loss_G: 5.9475\n",
            "[1/25][539/782] Loss_D: 0.6805 Loss_G: 2.1746\n",
            "[1/25][540/782] Loss_D: 0.8678 Loss_G: 6.5987\n",
            "[1/25][541/782] Loss_D: 1.4165 Loss_G: 1.6875\n",
            "[1/25][542/782] Loss_D: 1.0634 Loss_G: 6.7610\n",
            "[1/25][543/782] Loss_D: 1.0492 Loss_G: 1.5887\n",
            "[1/25][544/782] Loss_D: 1.2879 Loss_G: 6.8159\n",
            "[1/25][545/782] Loss_D: 0.6169 Loss_G: 4.7504\n",
            "[1/25][546/782] Loss_D: 0.3674 Loss_G: 2.6489\n",
            "[1/25][547/782] Loss_D: 0.7908 Loss_G: 5.1531\n",
            "[1/25][548/782] Loss_D: 0.6076 Loss_G: 3.4346\n",
            "[1/25][549/782] Loss_D: 0.4518 Loss_G: 2.7273\n",
            "[1/25][550/782] Loss_D: 0.6243 Loss_G: 5.4558\n",
            "[1/25][551/782] Loss_D: 0.7397 Loss_G: 2.8393\n",
            "[1/25][552/782] Loss_D: 0.7333 Loss_G: 4.9150\n",
            "[1/25][553/782] Loss_D: 0.7730 Loss_G: 3.3959\n",
            "[1/25][554/782] Loss_D: 0.7792 Loss_G: 2.5847\n",
            "[1/25][555/782] Loss_D: 1.0910 Loss_G: 8.0439\n",
            "[1/25][556/782] Loss_D: 1.9829 Loss_G: 2.1646\n",
            "[1/25][557/782] Loss_D: 0.7188 Loss_G: 4.9334\n",
            "[1/25][558/782] Loss_D: 0.6299 Loss_G: 3.4942\n",
            "[1/25][559/782] Loss_D: 0.7759 Loss_G: 4.2040\n",
            "[1/25][560/782] Loss_D: 0.5745 Loss_G: 3.1612\n",
            "[1/25][561/782] Loss_D: 0.5415 Loss_G: 3.8109\n",
            "[1/25][562/782] Loss_D: 0.3510 Loss_G: 4.4618\n",
            "[1/25][563/782] Loss_D: 0.4432 Loss_G: 3.6427\n",
            "[1/25][564/782] Loss_D: 0.5490 Loss_G: 4.4624\n",
            "[1/25][565/782] Loss_D: 1.0681 Loss_G: 1.9333\n",
            "[1/25][566/782] Loss_D: 1.1323 Loss_G: 7.3412\n",
            "[1/25][567/782] Loss_D: 1.2055 Loss_G: 3.1427\n",
            "[1/25][568/782] Loss_D: 0.7893 Loss_G: 3.2338\n",
            "[1/25][569/782] Loss_D: 0.3865 Loss_G: 3.7576\n",
            "[1/25][570/782] Loss_D: 0.8010 Loss_G: 3.0479\n",
            "[1/25][571/782] Loss_D: 0.5657 Loss_G: 4.1957\n",
            "[1/25][572/782] Loss_D: 0.1977 Loss_G: 4.3505\n",
            "[1/25][573/782] Loss_D: 0.3364 Loss_G: 2.9203\n",
            "[1/25][574/782] Loss_D: 0.7871 Loss_G: 4.6472\n",
            "[1/25][575/782] Loss_D: 0.6730 Loss_G: 3.4344\n",
            "[1/25][576/782] Loss_D: 0.6649 Loss_G: 4.0443\n",
            "[1/25][577/782] Loss_D: 0.4960 Loss_G: 4.0548\n",
            "[1/25][578/782] Loss_D: 0.5430 Loss_G: 3.2849\n",
            "[1/25][579/782] Loss_D: 0.8824 Loss_G: 2.6198\n",
            "[1/25][580/782] Loss_D: 0.8990 Loss_G: 5.3463\n",
            "[1/25][581/782] Loss_D: 0.9688 Loss_G: 1.6941\n",
            "[1/25][582/782] Loss_D: 0.8495 Loss_G: 4.7463\n",
            "[1/25][583/782] Loss_D: 0.5483 Loss_G: 3.4892\n",
            "[1/25][584/782] Loss_D: 0.5550 Loss_G: 4.0576\n",
            "[1/25][585/782] Loss_D: 0.4514 Loss_G: 3.0217\n",
            "[1/25][586/782] Loss_D: 0.8562 Loss_G: 4.3707\n",
            "[1/25][587/782] Loss_D: 0.6822 Loss_G: 1.7419\n",
            "[1/25][588/782] Loss_D: 1.1873 Loss_G: 6.1455\n",
            "[1/25][589/782] Loss_D: 0.8933 Loss_G: 1.8572\n",
            "[1/25][590/782] Loss_D: 1.1289 Loss_G: 7.0763\n",
            "[1/25][591/782] Loss_D: 1.7966 Loss_G: 0.8538\n",
            "[1/25][592/782] Loss_D: 1.8768 Loss_G: 6.3655\n",
            "[1/25][593/782] Loss_D: 0.9158 Loss_G: 3.9658\n",
            "[1/25][594/782] Loss_D: 0.6132 Loss_G: 2.0866\n",
            "[1/25][595/782] Loss_D: 0.7967 Loss_G: 6.1026\n",
            "[1/25][596/782] Loss_D: 1.0523 Loss_G: 1.0205\n",
            "[1/25][597/782] Loss_D: 1.6275 Loss_G: 6.7713\n",
            "[1/25][598/782] Loss_D: 1.2392 Loss_G: 2.2071\n",
            "[1/25][599/782] Loss_D: 0.6611 Loss_G: 2.5281\n",
            "[1/25][600/782] Loss_D: 1.1641 Loss_G: 5.1548\n",
            "[1/25][601/782] Loss_D: 1.3231 Loss_G: 1.7898\n",
            "[1/25][602/782] Loss_D: 0.7329 Loss_G: 3.6617\n",
            "[1/25][603/782] Loss_D: 0.7121 Loss_G: 3.5536\n",
            "[1/25][604/782] Loss_D: 0.4850 Loss_G: 3.2196\n",
            "[1/25][605/782] Loss_D: 0.7933 Loss_G: 1.9432\n",
            "[1/25][606/782] Loss_D: 0.7528 Loss_G: 4.5433\n",
            "[1/25][607/782] Loss_D: 0.7023 Loss_G: 1.9313\n",
            "[1/25][608/782] Loss_D: 0.9480 Loss_G: 3.8326\n",
            "[1/25][609/782] Loss_D: 0.5502 Loss_G: 3.2572\n",
            "[1/25][610/782] Loss_D: 0.4840 Loss_G: 2.3569\n",
            "[1/25][611/782] Loss_D: 0.7748 Loss_G: 5.1610\n",
            "[1/25][612/782] Loss_D: 0.7760 Loss_G: 3.0184\n",
            "[1/25][613/782] Loss_D: 0.6038 Loss_G: 2.7150\n",
            "[1/25][614/782] Loss_D: 0.3929 Loss_G: 3.5092\n",
            "[1/25][615/782] Loss_D: 0.4257 Loss_G: 3.6447\n",
            "[1/25][616/782] Loss_D: 0.2602 Loss_G: 3.8592\n",
            "[1/25][617/782] Loss_D: 0.5650 Loss_G: 3.3604\n",
            "[1/25][618/782] Loss_D: 0.3589 Loss_G: 3.3040\n",
            "[1/25][619/782] Loss_D: 0.4923 Loss_G: 5.2837\n",
            "[1/25][620/782] Loss_D: 0.6428 Loss_G: 3.1883\n",
            "[1/25][621/782] Loss_D: 0.3947 Loss_G: 3.0680\n",
            "[1/25][622/782] Loss_D: 0.3945 Loss_G: 3.3603\n",
            "[1/25][623/782] Loss_D: 0.4967 Loss_G: 4.7755\n",
            "[1/25][624/782] Loss_D: 0.3399 Loss_G: 4.1863\n",
            "[1/25][625/782] Loss_D: 0.3200 Loss_G: 3.4362\n",
            "[1/25][626/782] Loss_D: 0.5621 Loss_G: 3.8949\n",
            "[1/25][627/782] Loss_D: 0.7049 Loss_G: 3.0658\n",
            "[1/25][628/782] Loss_D: 0.5505 Loss_G: 4.8012\n",
            "[1/25][629/782] Loss_D: 0.8508 Loss_G: 2.2487\n",
            "[1/25][630/782] Loss_D: 0.8934 Loss_G: 5.7522\n",
            "[1/25][631/782] Loss_D: 0.9222 Loss_G: 2.3678\n",
            "[1/25][632/782] Loss_D: 0.9607 Loss_G: 5.3611\n",
            "[1/25][633/782] Loss_D: 0.6976 Loss_G: 2.1589\n",
            "[1/25][634/782] Loss_D: 0.6100 Loss_G: 5.1821\n",
            "[1/25][635/782] Loss_D: 0.4576 Loss_G: 4.1233\n",
            "[1/25][636/782] Loss_D: 0.4408 Loss_G: 2.9452\n",
            "[1/25][637/782] Loss_D: 0.4707 Loss_G: 4.0959\n",
            "[1/25][638/782] Loss_D: 0.3863 Loss_G: 3.7482\n",
            "[1/25][639/782] Loss_D: 0.4439 Loss_G: 3.4459\n",
            "[1/25][640/782] Loss_D: 0.5421 Loss_G: 4.1307\n",
            "[1/25][641/782] Loss_D: 0.4626 Loss_G: 2.8334\n",
            "[1/25][642/782] Loss_D: 0.4532 Loss_G: 4.1867\n",
            "[1/25][643/782] Loss_D: 0.4847 Loss_G: 3.1689\n",
            "[1/25][644/782] Loss_D: 0.5356 Loss_G: 4.5413\n",
            "[1/25][645/782] Loss_D: 0.5423 Loss_G: 2.1393\n",
            "[1/25][646/782] Loss_D: 0.7142 Loss_G: 5.3284\n",
            "[1/25][647/782] Loss_D: 0.4472 Loss_G: 2.4924\n",
            "[1/25][648/782] Loss_D: 0.7678 Loss_G: 4.9037\n",
            "[1/25][649/782] Loss_D: 0.7538 Loss_G: 2.2528\n",
            "[1/25][650/782] Loss_D: 0.5561 Loss_G: 5.3989\n",
            "[1/25][651/782] Loss_D: 0.5993 Loss_G: 3.3293\n",
            "[1/25][652/782] Loss_D: 0.3120 Loss_G: 3.9328\n",
            "[1/25][653/782] Loss_D: 0.3652 Loss_G: 4.1105\n",
            "[1/25][654/782] Loss_D: 0.2881 Loss_G: 3.7853\n",
            "[1/25][655/782] Loss_D: 0.4501 Loss_G: 3.0447\n",
            "[1/25][656/782] Loss_D: 0.4456 Loss_G: 3.1403\n",
            "[1/25][657/782] Loss_D: 0.5272 Loss_G: 4.1956\n",
            "[1/25][658/782] Loss_D: 0.4464 Loss_G: 3.5745\n",
            "[1/25][659/782] Loss_D: 0.3723 Loss_G: 3.6049\n",
            "[1/25][660/782] Loss_D: 0.5357 Loss_G: 3.2559\n",
            "[1/25][661/782] Loss_D: 0.5904 Loss_G: 3.4126\n",
            "[1/25][662/782] Loss_D: 0.3561 Loss_G: 4.7535\n",
            "[1/25][663/782] Loss_D: 0.5261 Loss_G: 3.2686\n",
            "[1/25][664/782] Loss_D: 0.4674 Loss_G: 3.7192\n",
            "[1/25][665/782] Loss_D: 0.7185 Loss_G: 2.8777\n",
            "[1/25][666/782] Loss_D: 0.6422 Loss_G: 4.1949\n",
            "[1/25][667/782] Loss_D: 0.3940 Loss_G: 4.5594\n",
            "[1/25][668/782] Loss_D: 0.4577 Loss_G: 2.8299\n",
            "[1/25][669/782] Loss_D: 0.6070 Loss_G: 5.3186\n",
            "[1/25][670/782] Loss_D: 0.6241 Loss_G: 2.3485\n",
            "[1/25][671/782] Loss_D: 0.9867 Loss_G: 6.9792\n",
            "[1/25][672/782] Loss_D: 1.3203 Loss_G: 0.5998\n",
            "[1/25][673/782] Loss_D: 2.2590 Loss_G: 10.8223\n",
            "[1/25][674/782] Loss_D: 2.4234 Loss_G: 4.8689\n",
            "[1/25][675/782] Loss_D: 0.6179 Loss_G: 1.1369\n",
            "[1/25][676/782] Loss_D: 1.9673 Loss_G: 8.5134\n",
            "[1/25][677/782] Loss_D: 1.5169 Loss_G: 3.7859\n",
            "[1/25][678/782] Loss_D: 0.5468 Loss_G: 2.9365\n",
            "[1/25][679/782] Loss_D: 1.0839 Loss_G: 4.3057\n",
            "[1/25][680/782] Loss_D: 0.7978 Loss_G: 3.2592\n",
            "[1/25][681/782] Loss_D: 0.6066 Loss_G: 3.4916\n",
            "[1/25][682/782] Loss_D: 0.9062 Loss_G: 3.0638\n",
            "[1/25][683/782] Loss_D: 0.5710 Loss_G: 3.9935\n",
            "[1/25][684/782] Loss_D: 0.6038 Loss_G: 2.7325\n",
            "[1/25][685/782] Loss_D: 0.4974 Loss_G: 3.1318\n",
            "[1/25][686/782] Loss_D: 0.4724 Loss_G: 3.6472\n",
            "[1/25][687/782] Loss_D: 0.3592 Loss_G: 3.7510\n",
            "[1/25][688/782] Loss_D: 0.5320 Loss_G: 2.3085\n",
            "[1/25][689/782] Loss_D: 0.7244 Loss_G: 4.5176\n",
            "[1/25][690/782] Loss_D: 0.4078 Loss_G: 3.7762\n",
            "[1/25][691/782] Loss_D: 0.3958 Loss_G: 2.9656\n",
            "[1/25][692/782] Loss_D: 0.5820 Loss_G: 4.3182\n",
            "[1/25][693/782] Loss_D: 0.6624 Loss_G: 2.7815\n",
            "[1/25][694/782] Loss_D: 0.5708 Loss_G: 3.2808\n",
            "[1/25][695/782] Loss_D: 0.5138 Loss_G: 3.9611\n",
            "[1/25][696/782] Loss_D: 0.5230 Loss_G: 3.4991\n",
            "[1/25][697/782] Loss_D: 0.3942 Loss_G: 3.1890\n",
            "[1/25][698/782] Loss_D: 0.6238 Loss_G: 3.8088\n",
            "[1/25][699/782] Loss_D: 0.7038 Loss_G: 2.8106\n",
            "[1/25][700/782] Loss_D: 0.4854 Loss_G: 4.1137\n",
            "[1/25][701/782] Loss_D: 0.6948 Loss_G: 2.6697\n",
            "[1/25][702/782] Loss_D: 0.8698 Loss_G: 4.2947\n",
            "[1/25][703/782] Loss_D: 0.3669 Loss_G: 3.9568\n",
            "[1/25][704/782] Loss_D: 0.8473 Loss_G: 2.1966\n",
            "[1/25][705/782] Loss_D: 0.6471 Loss_G: 4.1446\n",
            "[1/25][706/782] Loss_D: 0.7274 Loss_G: 2.9736\n",
            "[1/25][707/782] Loss_D: 0.8605 Loss_G: 2.9978\n",
            "[1/25][708/782] Loss_D: 0.7395 Loss_G: 4.3416\n",
            "[1/25][709/782] Loss_D: 0.5315 Loss_G: 2.6153\n",
            "[1/25][710/782] Loss_D: 0.7152 Loss_G: 4.6088\n",
            "[1/25][711/782] Loss_D: 0.6553 Loss_G: 3.0479\n",
            "[1/25][712/782] Loss_D: 0.4301 Loss_G: 3.5290\n",
            "[1/25][713/782] Loss_D: 0.5066 Loss_G: 4.4354\n",
            "[1/25][714/782] Loss_D: 0.4822 Loss_G: 2.8379\n",
            "[1/25][715/782] Loss_D: 0.5327 Loss_G: 4.0647\n",
            "[1/25][716/782] Loss_D: 0.6022 Loss_G: 3.2820\n",
            "[1/25][717/782] Loss_D: 0.4754 Loss_G: 2.8227\n",
            "[1/25][718/782] Loss_D: 0.5938 Loss_G: 4.8504\n",
            "[1/25][719/782] Loss_D: 0.4949 Loss_G: 3.5991\n",
            "[1/25][720/782] Loss_D: 0.5193 Loss_G: 2.2808\n",
            "[1/25][721/782] Loss_D: 0.7517 Loss_G: 5.6378\n",
            "[1/25][722/782] Loss_D: 0.5980 Loss_G: 2.6322\n",
            "[1/25][723/782] Loss_D: 0.4984 Loss_G: 4.3642\n",
            "[1/25][724/782] Loss_D: 0.3386 Loss_G: 3.5462\n",
            "[1/25][725/782] Loss_D: 0.6744 Loss_G: 4.8936\n",
            "[1/25][726/782] Loss_D: 0.7188 Loss_G: 2.2564\n",
            "[1/25][727/782] Loss_D: 0.5586 Loss_G: 4.4347\n",
            "[1/25][728/782] Loss_D: 0.4168 Loss_G: 3.0526\n",
            "[1/25][729/782] Loss_D: 0.5594 Loss_G: 3.4110\n",
            "[1/25][730/782] Loss_D: 0.7340 Loss_G: 2.9609\n",
            "[1/25][731/782] Loss_D: 0.6522 Loss_G: 4.1727\n",
            "[1/25][732/782] Loss_D: 0.4354 Loss_G: 2.5510\n",
            "[1/25][733/782] Loss_D: 0.4516 Loss_G: 4.2083\n",
            "[1/25][734/782] Loss_D: 0.3902 Loss_G: 2.8886\n",
            "[1/25][735/782] Loss_D: 0.3146 Loss_G: 3.6673\n",
            "[1/25][736/782] Loss_D: 0.6282 Loss_G: 1.9972\n",
            "[1/25][737/782] Loss_D: 0.4869 Loss_G: 3.9461\n",
            "[1/25][738/782] Loss_D: 0.4225 Loss_G: 4.7138\n",
            "[1/25][739/782] Loss_D: 0.4546 Loss_G: 2.0970\n",
            "[1/25][740/782] Loss_D: 0.5192 Loss_G: 5.6772\n",
            "[1/25][741/782] Loss_D: 0.5926 Loss_G: 2.6376\n",
            "[1/25][742/782] Loss_D: 0.2711 Loss_G: 3.1492\n",
            "[1/25][743/782] Loss_D: 0.3405 Loss_G: 4.5906\n",
            "[1/25][744/782] Loss_D: 0.3237 Loss_G: 4.6548\n",
            "[1/25][745/782] Loss_D: 0.4869 Loss_G: 2.3472\n",
            "[1/25][746/782] Loss_D: 0.6203 Loss_G: 4.1299\n",
            "[1/25][747/782] Loss_D: 0.4819 Loss_G: 2.0406\n",
            "[1/25][748/782] Loss_D: 0.5544 Loss_G: 6.8797\n",
            "[1/25][749/782] Loss_D: 1.4307 Loss_G: 1.6038\n",
            "[1/25][750/782] Loss_D: 0.5767 Loss_G: 3.7454\n",
            "[1/25][751/782] Loss_D: 0.3395 Loss_G: 4.2338\n",
            "[1/25][752/782] Loss_D: 0.2518 Loss_G: 3.5848\n",
            "[1/25][753/782] Loss_D: 0.3547 Loss_G: 2.9451\n",
            "[1/25][754/782] Loss_D: 0.5867 Loss_G: 3.4238\n",
            "[1/25][755/782] Loss_D: 0.3938 Loss_G: 4.1446\n",
            "[1/25][756/782] Loss_D: 0.6126 Loss_G: 1.7817\n",
            "[1/25][757/782] Loss_D: 0.7043 Loss_G: 4.6087\n",
            "[1/25][758/782] Loss_D: 0.8615 Loss_G: 0.5545\n",
            "[1/25][759/782] Loss_D: 1.4417 Loss_G: 6.8815\n",
            "[1/25][760/782] Loss_D: 0.9668 Loss_G: 1.3366\n",
            "[1/25][761/782] Loss_D: 1.2333 Loss_G: 5.6855\n",
            "[1/25][762/782] Loss_D: 1.1167 Loss_G: 2.2098\n",
            "[1/25][763/782] Loss_D: 0.4369 Loss_G: 3.9043\n",
            "[1/25][764/782] Loss_D: 0.8650 Loss_G: 3.3172\n",
            "[1/25][765/782] Loss_D: 0.7218 Loss_G: 4.1002\n",
            "[1/25][766/782] Loss_D: 0.5617 Loss_G: 2.3430\n",
            "[1/25][767/782] Loss_D: 0.6277 Loss_G: 4.8200\n",
            "[1/25][768/782] Loss_D: 0.4410 Loss_G: 3.9744\n",
            "[1/25][769/782] Loss_D: 0.4135 Loss_G: 2.8037\n",
            "[1/25][770/782] Loss_D: 0.5583 Loss_G: 4.3109\n",
            "[1/25][771/782] Loss_D: 0.5428 Loss_G: 2.7640\n",
            "[1/25][772/782] Loss_D: 0.7060 Loss_G: 4.1859\n",
            "[1/25][773/782] Loss_D: 0.3901 Loss_G: 3.4859\n",
            "[1/25][774/782] Loss_D: 0.5002 Loss_G: 2.6079\n",
            "[1/25][775/782] Loss_D: 0.4461 Loss_G: 3.9090\n",
            "[1/25][776/782] Loss_D: 0.4313 Loss_G: 3.9736\n",
            "[1/25][777/782] Loss_D: 0.3059 Loss_G: 3.2742\n",
            "[1/25][778/782] Loss_D: 0.3146 Loss_G: 4.3768\n",
            "[1/25][779/782] Loss_D: 0.3836 Loss_G: 3.3399\n",
            "[1/25][780/782] Loss_D: 0.4545 Loss_G: 3.4656\n",
            "[1/25][781/782] Loss_D: 0.4896 Loss_G: 4.3003\n",
            "[2/25][0/782] Loss_D: 0.4533 Loss_G: 5.8071\n",
            "[2/25][1/782] Loss_D: 0.3535 Loss_G: 4.3882\n",
            "[2/25][2/782] Loss_D: 0.2575 Loss_G: 3.3510\n",
            "[2/25][3/782] Loss_D: 0.4187 Loss_G: 4.1304\n",
            "[2/25][4/782] Loss_D: 0.4836 Loss_G: 4.5697\n",
            "[2/25][5/782] Loss_D: 0.3020 Loss_G: 3.6512\n",
            "[2/25][6/782] Loss_D: 0.5581 Loss_G: 4.5467\n",
            "[2/25][7/782] Loss_D: 0.8950 Loss_G: 2.0486\n",
            "[2/25][8/782] Loss_D: 0.7961 Loss_G: 6.3683\n",
            "[2/25][9/782] Loss_D: 1.7734 Loss_G: 0.8218\n",
            "[2/25][10/782] Loss_D: 1.7547 Loss_G: 5.8444\n",
            "[2/25][11/782] Loss_D: 1.1557 Loss_G: 3.1898\n",
            "[2/25][12/782] Loss_D: 0.5673 Loss_G: 4.6690\n",
            "[2/25][13/782] Loss_D: 0.5437 Loss_G: 2.9418\n",
            "[2/25][14/782] Loss_D: 0.5919 Loss_G: 4.9401\n",
            "[2/25][15/782] Loss_D: 0.9458 Loss_G: 1.7232\n",
            "[2/25][16/782] Loss_D: 1.2073 Loss_G: 5.2194\n",
            "[2/25][17/782] Loss_D: 0.8834 Loss_G: 0.9580\n",
            "[2/25][18/782] Loss_D: 1.5462 Loss_G: 8.2256\n",
            "[2/25][19/782] Loss_D: 1.5204 Loss_G: 2.6650\n",
            "[2/25][20/782] Loss_D: 0.7836 Loss_G: 3.2052\n",
            "[2/25][21/782] Loss_D: 0.6305 Loss_G: 5.3590\n",
            "[2/25][22/782] Loss_D: 0.8325 Loss_G: 2.1194\n",
            "[2/25][23/782] Loss_D: 1.4914 Loss_G: 6.2296\n",
            "[2/25][24/782] Loss_D: 1.5836 Loss_G: 1.4210\n",
            "[2/25][25/782] Loss_D: 1.2627 Loss_G: 5.7086\n",
            "[2/25][26/782] Loss_D: 0.7140 Loss_G: 3.9019\n",
            "[2/25][27/782] Loss_D: 0.6641 Loss_G: 4.1791\n",
            "[2/25][28/782] Loss_D: 1.0908 Loss_G: 3.3179\n",
            "[2/25][29/782] Loss_D: 0.8121 Loss_G: 3.7404\n",
            "[2/25][30/782] Loss_D: 0.8864 Loss_G: 2.0541\n",
            "[2/25][31/782] Loss_D: 0.6148 Loss_G: 4.1248\n",
            "[2/25][32/782] Loss_D: 0.4991 Loss_G: 3.4928\n",
            "[2/25][33/782] Loss_D: 0.4362 Loss_G: 3.1029\n",
            "[2/25][34/782] Loss_D: 0.4296 Loss_G: 2.4425\n",
            "[2/25][35/782] Loss_D: 0.4457 Loss_G: 3.9562\n",
            "[2/25][36/782] Loss_D: 0.3634 Loss_G: 3.7034\n",
            "[2/25][37/782] Loss_D: 0.4642 Loss_G: 2.8185\n",
            "[2/25][38/782] Loss_D: 0.4068 Loss_G: 2.7394\n",
            "[2/25][39/782] Loss_D: 0.4735 Loss_G: 3.7240\n",
            "[2/25][40/782] Loss_D: 0.3571 Loss_G: 3.4772\n",
            "[2/25][41/782] Loss_D: 0.3185 Loss_G: 3.1564\n",
            "[2/25][42/782] Loss_D: 0.4498 Loss_G: 3.5586\n",
            "[2/25][43/782] Loss_D: 0.3379 Loss_G: 3.2987\n",
            "[2/25][44/782] Loss_D: 0.3776 Loss_G: 2.9372\n",
            "[2/25][45/782] Loss_D: 0.3119 Loss_G: 3.8278\n",
            "[2/25][46/782] Loss_D: 0.4505 Loss_G: 3.1906\n",
            "[2/25][47/782] Loss_D: 0.4872 Loss_G: 3.9873\n",
            "[2/25][48/782] Loss_D: 0.6215 Loss_G: 2.8984\n",
            "[2/25][49/782] Loss_D: 0.7774 Loss_G: 2.7591\n",
            "[2/25][50/782] Loss_D: 0.8161 Loss_G: 4.3481\n",
            "[2/25][51/782] Loss_D: 0.6720 Loss_G: 2.0271\n",
            "[2/25][52/782] Loss_D: 1.2132 Loss_G: 6.8498\n",
            "[2/25][53/782] Loss_D: 1.0280 Loss_G: 3.3639\n",
            "[2/25][54/782] Loss_D: 0.4538 Loss_G: 2.6029\n",
            "[2/25][55/782] Loss_D: 0.4474 Loss_G: 4.2967\n",
            "[2/25][56/782] Loss_D: 0.6282 Loss_G: 3.0667\n",
            "[2/25][57/782] Loss_D: 0.5713 Loss_G: 5.0126\n",
            "[2/25][58/782] Loss_D: 0.4147 Loss_G: 3.0350\n",
            "[2/25][59/782] Loss_D: 0.2986 Loss_G: 3.2105\n",
            "[2/25][60/782] Loss_D: 0.4868 Loss_G: 3.9844\n",
            "[2/25][61/782] Loss_D: 0.3689 Loss_G: 3.8600\n",
            "[2/25][62/782] Loss_D: 0.2752 Loss_G: 3.5306\n",
            "[2/25][63/782] Loss_D: 0.4045 Loss_G: 2.8547\n",
            "[2/25][64/782] Loss_D: 1.0098 Loss_G: 6.4144\n",
            "[2/25][65/782] Loss_D: 1.2323 Loss_G: 1.0330\n",
            "[2/25][66/782] Loss_D: 1.4130 Loss_G: 7.6915\n",
            "[2/25][67/782] Loss_D: 1.5143 Loss_G: 3.9359\n",
            "[2/25][68/782] Loss_D: 0.3906 Loss_G: 2.6446\n",
            "[2/25][69/782] Loss_D: 0.8902 Loss_G: 5.3960\n",
            "[2/25][70/782] Loss_D: 1.2935 Loss_G: 2.1179\n",
            "[2/25][71/782] Loss_D: 0.9487 Loss_G: 3.8358\n",
            "[2/25][72/782] Loss_D: 0.4873 Loss_G: 3.9587\n",
            "[2/25][73/782] Loss_D: 0.8796 Loss_G: 1.8231\n",
            "[2/25][74/782] Loss_D: 0.7004 Loss_G: 5.9965\n",
            "[2/25][75/782] Loss_D: 1.6140 Loss_G: 1.1135\n",
            "[2/25][76/782] Loss_D: 1.3725 Loss_G: 5.3625\n",
            "[2/25][77/782] Loss_D: 0.7089 Loss_G: 2.2292\n",
            "[2/25][78/782] Loss_D: 0.5391 Loss_G: 3.3730\n",
            "[2/25][79/782] Loss_D: 0.4723 Loss_G: 4.7491\n",
            "[2/25][80/782] Loss_D: 0.5971 Loss_G: 2.8316\n",
            "[2/25][81/782] Loss_D: 0.4242 Loss_G: 2.9425\n",
            "[2/25][82/782] Loss_D: 0.7247 Loss_G: 3.5682\n",
            "[2/25][83/782] Loss_D: 0.3436 Loss_G: 3.6711\n",
            "[2/25][84/782] Loss_D: 0.4193 Loss_G: 2.3464\n",
            "[2/25][85/782] Loss_D: 0.4756 Loss_G: 3.7258\n",
            "[2/25][86/782] Loss_D: 0.2934 Loss_G: 4.1284\n",
            "[2/25][87/782] Loss_D: 0.3839 Loss_G: 3.0024\n",
            "[2/25][88/782] Loss_D: 0.4658 Loss_G: 3.1629\n",
            "[2/25][89/782] Loss_D: 0.2931 Loss_G: 3.4314\n",
            "[2/25][90/782] Loss_D: 0.3658 Loss_G: 2.8616\n",
            "[2/25][91/782] Loss_D: 0.3561 Loss_G: 3.0652\n",
            "[2/25][92/782] Loss_D: 0.3087 Loss_G: 3.9511\n",
            "[2/25][93/782] Loss_D: 0.5280 Loss_G: 2.5886\n",
            "[2/25][94/782] Loss_D: 0.3371 Loss_G: 3.1570\n",
            "[2/25][95/782] Loss_D: 0.8343 Loss_G: 2.1373\n",
            "[2/25][96/782] Loss_D: 0.7865 Loss_G: 4.6936\n",
            "[2/25][97/782] Loss_D: 0.7255 Loss_G: 2.8417\n",
            "[2/25][98/782] Loss_D: 0.5890 Loss_G: 2.5849\n",
            "[2/25][99/782] Loss_D: 0.3217 Loss_G: 3.6100\n",
            "[2/25][100/782] Loss_D: 0.7474 Loss_G: 3.9091\n",
            "[2/25][101/782] Loss_D: 0.5658 Loss_G: 3.1027\n",
            "[2/25][102/782] Loss_D: 0.5155 Loss_G: 2.9702\n",
            "[2/25][103/782] Loss_D: 0.4284 Loss_G: 3.2554\n",
            "[2/25][104/782] Loss_D: 0.3361 Loss_G: 4.0004\n",
            "[2/25][105/782] Loss_D: 0.5337 Loss_G: 2.3722\n",
            "[2/25][106/782] Loss_D: 0.5152 Loss_G: 4.0513\n",
            "[2/25][107/782] Loss_D: 0.5285 Loss_G: 2.8893\n",
            "[2/25][108/782] Loss_D: 0.2667 Loss_G: 3.4676\n",
            "[2/25][109/782] Loss_D: 0.2156 Loss_G: 4.0331\n",
            "[2/25][110/782] Loss_D: 0.3074 Loss_G: 3.2920\n",
            "[2/25][111/782] Loss_D: 0.3869 Loss_G: 2.7571\n",
            "[2/25][112/782] Loss_D: 0.5357 Loss_G: 4.1935\n",
            "[2/25][113/782] Loss_D: 0.4244 Loss_G: 3.5567\n",
            "[2/25][114/782] Loss_D: 0.4871 Loss_G: 2.3127\n",
            "[2/25][115/782] Loss_D: 0.6104 Loss_G: 3.9216\n",
            "[2/25][116/782] Loss_D: 0.6286 Loss_G: 3.0187\n",
            "[2/25][117/782] Loss_D: 0.5723 Loss_G: 3.7507\n",
            "[2/25][118/782] Loss_D: 0.5046 Loss_G: 2.8905\n",
            "[2/25][119/782] Loss_D: 0.3933 Loss_G: 4.7146\n",
            "[2/25][120/782] Loss_D: 0.3279 Loss_G: 3.6311\n",
            "[2/25][121/782] Loss_D: 0.3910 Loss_G: 2.5334\n",
            "[2/25][122/782] Loss_D: 0.5298 Loss_G: 4.0822\n",
            "[2/25][123/782] Loss_D: 0.5457 Loss_G: 2.9903\n",
            "[2/25][124/782] Loss_D: 0.5072 Loss_G: 3.1408\n",
            "[2/25][125/782] Loss_D: 0.5378 Loss_G: 2.8613\n",
            "[2/25][126/782] Loss_D: 0.5835 Loss_G: 3.2326\n",
            "[2/25][127/782] Loss_D: 0.5911 Loss_G: 2.2207\n",
            "[2/25][128/782] Loss_D: 0.7490 Loss_G: 4.8065\n",
            "[2/25][129/782] Loss_D: 1.1515 Loss_G: 0.0566\n",
            "[2/25][130/782] Loss_D: 3.9676 Loss_G: 7.4150\n",
            "[2/25][131/782] Loss_D: 3.0473 Loss_G: 1.8449\n",
            "[2/25][132/782] Loss_D: 0.8463 Loss_G: 2.2801\n",
            "[2/25][133/782] Loss_D: 0.7107 Loss_G: 5.8418\n",
            "[2/25][134/782] Loss_D: 0.6533 Loss_G: 3.0015\n",
            "[2/25][135/782] Loss_D: 0.4223 Loss_G: 3.0341\n",
            "[2/25][136/782] Loss_D: 0.4415 Loss_G: 3.6951\n",
            "[2/25][137/782] Loss_D: 0.7711 Loss_G: 1.4552\n",
            "[2/25][138/782] Loss_D: 1.1240 Loss_G: 6.0083\n",
            "[2/25][139/782] Loss_D: 0.8717 Loss_G: 1.9924\n",
            "[2/25][140/782] Loss_D: 1.0772 Loss_G: 7.0345\n",
            "[2/25][141/782] Loss_D: 0.8908 Loss_G: 1.9799\n",
            "[2/25][142/782] Loss_D: 1.0692 Loss_G: 4.7058\n",
            "[2/25][143/782] Loss_D: 0.5917 Loss_G: 3.2853\n",
            "[2/25][144/782] Loss_D: 0.6159 Loss_G: 1.9428\n",
            "[2/25][145/782] Loss_D: 0.8918 Loss_G: 5.9468\n",
            "[2/25][146/782] Loss_D: 1.3647 Loss_G: 1.3967\n",
            "[2/25][147/782] Loss_D: 1.0702 Loss_G: 5.0150\n",
            "[2/25][148/782] Loss_D: 0.7928 Loss_G: 2.1691\n",
            "[2/25][149/782] Loss_D: 0.6372 Loss_G: 4.2977\n",
            "[2/25][150/782] Loss_D: 0.7480 Loss_G: 3.3418\n",
            "[2/25][151/782] Loss_D: 0.5820 Loss_G: 2.7123\n",
            "[2/25][152/782] Loss_D: 0.5724 Loss_G: 4.0130\n",
            "[2/25][153/782] Loss_D: 0.4370 Loss_G: 3.8432\n",
            "[2/25][154/782] Loss_D: 0.5186 Loss_G: 3.3500\n",
            "[2/25][155/782] Loss_D: 0.4907 Loss_G: 3.0251\n",
            "[2/25][156/782] Loss_D: 0.5237 Loss_G: 3.3865\n",
            "[2/25][157/782] Loss_D: 0.4162 Loss_G: 3.2084\n",
            "[2/25][158/782] Loss_D: 0.2921 Loss_G: 3.3951\n",
            "[2/25][159/782] Loss_D: 0.5388 Loss_G: 4.3203\n",
            "[2/25][160/782] Loss_D: 0.4199 Loss_G: 4.0469\n",
            "[2/25][161/782] Loss_D: 0.6646 Loss_G: 3.1155\n",
            "[2/25][162/782] Loss_D: 1.0486 Loss_G: 3.9693\n",
            "[2/25][163/782] Loss_D: 1.3110 Loss_G: 2.0536\n",
            "[2/25][164/782] Loss_D: 0.8826 Loss_G: 6.4524\n",
            "[2/25][165/782] Loss_D: 0.4261 Loss_G: 4.7939\n",
            "[2/25][166/782] Loss_D: 0.2032 Loss_G: 3.0285\n",
            "[2/25][167/782] Loss_D: 0.3191 Loss_G: 5.2433\n",
            "[2/25][168/782] Loss_D: 0.2487 Loss_G: 4.3288\n",
            "[2/25][169/782] Loss_D: 0.3027 Loss_G: 3.6110\n",
            "[2/25][170/782] Loss_D: 0.3239 Loss_G: 3.3715\n",
            "[2/25][171/782] Loss_D: 0.4529 Loss_G: 3.6710\n",
            "[2/25][172/782] Loss_D: 0.6011 Loss_G: 3.6982\n",
            "[2/25][173/782] Loss_D: 0.5373 Loss_G: 2.5736\n",
            "[2/25][174/782] Loss_D: 0.5823 Loss_G: 3.0776\n",
            "[2/25][175/782] Loss_D: 0.4573 Loss_G: 4.1687\n",
            "[2/25][176/782] Loss_D: 0.2311 Loss_G: 4.1089\n",
            "[2/25][177/782] Loss_D: 0.1675 Loss_G: 3.8119\n",
            "[2/25][178/782] Loss_D: 0.3416 Loss_G: 3.6156\n",
            "[2/25][179/782] Loss_D: 0.4652 Loss_G: 3.0598\n",
            "[2/25][180/782] Loss_D: 0.4326 Loss_G: 4.1499\n",
            "[2/25][181/782] Loss_D: 0.2704 Loss_G: 4.0441\n",
            "[2/25][182/782] Loss_D: 0.6824 Loss_G: 1.2345\n",
            "[2/25][183/782] Loss_D: 0.7859 Loss_G: 5.8098\n",
            "[2/25][184/782] Loss_D: 0.6437 Loss_G: 2.8043\n",
            "[2/25][185/782] Loss_D: 0.3412 Loss_G: 4.2881\n",
            "[2/25][186/782] Loss_D: 0.2670 Loss_G: 4.6046\n",
            "[2/25][187/782] Loss_D: 0.3986 Loss_G: 2.6644\n",
            "[2/25][188/782] Loss_D: 0.3520 Loss_G: 3.6369\n",
            "[2/25][189/782] Loss_D: 0.9690 Loss_G: 3.0107\n",
            "[2/25][190/782] Loss_D: 0.4983 Loss_G: 3.3317\n",
            "[2/25][191/782] Loss_D: 0.3423 Loss_G: 4.0866\n",
            "[2/25][192/782] Loss_D: 0.4028 Loss_G: 2.7847\n",
            "[2/25][193/782] Loss_D: 0.4015 Loss_G: 3.2652\n",
            "[2/25][194/782] Loss_D: 0.4058 Loss_G: 3.5061\n",
            "[2/25][195/782] Loss_D: 0.3797 Loss_G: 2.9345\n",
            "[2/25][196/782] Loss_D: 0.3088 Loss_G: 3.6960\n",
            "[2/25][197/782] Loss_D: 0.2284 Loss_G: 3.7057\n",
            "[2/25][198/782] Loss_D: 0.3783 Loss_G: 2.7238\n",
            "[2/25][199/782] Loss_D: 0.5475 Loss_G: 3.4222\n",
            "[2/25][200/782] Loss_D: 0.3612 Loss_G: 3.4693\n",
            "[2/25][201/782] Loss_D: 0.2921 Loss_G: 3.4419\n",
            "[2/25][202/782] Loss_D: 0.3570 Loss_G: 3.4623\n",
            "[2/25][203/782] Loss_D: 0.3893 Loss_G: 3.7712\n",
            "[2/25][204/782] Loss_D: 0.2907 Loss_G: 2.9673\n",
            "[2/25][205/782] Loss_D: 0.3740 Loss_G: 3.7261\n",
            "[2/25][206/782] Loss_D: 0.8003 Loss_G: 1.5515\n",
            "[2/25][207/782] Loss_D: 0.7407 Loss_G: 7.5017\n",
            "[2/25][208/782] Loss_D: 0.9138 Loss_G: 2.4350\n",
            "[2/25][209/782] Loss_D: 0.3837 Loss_G: 3.9365\n",
            "[2/25][210/782] Loss_D: 0.2872 Loss_G: 4.7061\n",
            "[2/25][211/782] Loss_D: 0.5333 Loss_G: 2.1258\n",
            "[2/25][212/782] Loss_D: 1.0293 Loss_G: 5.9388\n",
            "[2/25][213/782] Loss_D: 1.1987 Loss_G: 1.9045\n",
            "[2/25][214/782] Loss_D: 0.9410 Loss_G: 5.1286\n",
            "[2/25][215/782] Loss_D: 0.4521 Loss_G: 3.8360\n",
            "[2/25][216/782] Loss_D: 0.4249 Loss_G: 2.9622\n",
            "[2/25][217/782] Loss_D: 0.4962 Loss_G: 3.9742\n",
            "[2/25][218/782] Loss_D: 0.4190 Loss_G: 3.9328\n",
            "[2/25][219/782] Loss_D: 0.8340 Loss_G: 1.8475\n",
            "[2/25][220/782] Loss_D: 0.6246 Loss_G: 6.2941\n",
            "[2/25][221/782] Loss_D: 0.7437 Loss_G: 2.4306\n",
            "[2/25][222/782] Loss_D: 0.5035 Loss_G: 2.8764\n",
            "[2/25][223/782] Loss_D: 0.9203 Loss_G: 6.5835\n",
            "[2/25][224/782] Loss_D: 1.2375 Loss_G: 1.6925\n",
            "[2/25][225/782] Loss_D: 0.9514 Loss_G: 4.2799\n",
            "[2/25][226/782] Loss_D: 0.4807 Loss_G: 3.3534\n",
            "[2/25][227/782] Loss_D: 0.3037 Loss_G: 3.2736\n",
            "[2/25][228/782] Loss_D: 0.5284 Loss_G: 4.3195\n",
            "[2/25][229/782] Loss_D: 0.3893 Loss_G: 3.0245\n",
            "[2/25][230/782] Loss_D: 0.7080 Loss_G: 2.3366\n",
            "[2/25][231/782] Loss_D: 0.6468 Loss_G: 5.3576\n",
            "[2/25][232/782] Loss_D: 0.9851 Loss_G: 2.2346\n",
            "[2/25][233/782] Loss_D: 0.6554 Loss_G: 4.5875\n",
            "[2/25][234/782] Loss_D: 0.5269 Loss_G: 2.4122\n",
            "[2/25][235/782] Loss_D: 0.5882 Loss_G: 3.3772\n",
            "[2/25][236/782] Loss_D: 0.2409 Loss_G: 4.0264\n",
            "[2/25][237/782] Loss_D: 0.3393 Loss_G: 3.5668\n",
            "[2/25][238/782] Loss_D: 0.4607 Loss_G: 3.4313\n",
            "[2/25][239/782] Loss_D: 0.2419 Loss_G: 4.0157\n",
            "[2/25][240/782] Loss_D: 0.3848 Loss_G: 2.6633\n",
            "[2/25][241/782] Loss_D: 0.6206 Loss_G: 4.7685\n",
            "[2/25][242/782] Loss_D: 0.5834 Loss_G: 2.8197\n",
            "[2/25][243/782] Loss_D: 0.9448 Loss_G: 5.0911\n",
            "[2/25][244/782] Loss_D: 0.8981 Loss_G: 1.7356\n",
            "[2/25][245/782] Loss_D: 1.0254 Loss_G: 6.6689\n",
            "[2/25][246/782] Loss_D: 0.9693 Loss_G: 2.2964\n",
            "[2/25][247/782] Loss_D: 0.5834 Loss_G: 4.6268\n",
            "[2/25][248/782] Loss_D: 0.6283 Loss_G: 1.8845\n",
            "[2/25][249/782] Loss_D: 0.6549 Loss_G: 4.9278\n",
            "[2/25][250/782] Loss_D: 0.3158 Loss_G: 4.1632\n",
            "[2/25][251/782] Loss_D: 0.5169 Loss_G: 1.5423\n",
            "[2/25][252/782] Loss_D: 1.3695 Loss_G: 8.1213\n",
            "[2/25][253/782] Loss_D: 2.7984 Loss_G: 0.2711\n",
            "[2/25][254/782] Loss_D: 2.7514 Loss_G: 7.9580\n",
            "[2/25][255/782] Loss_D: 2.7857 Loss_G: 1.8208\n",
            "[2/25][256/782] Loss_D: 0.6057 Loss_G: 2.8103\n",
            "[2/25][257/782] Loss_D: 0.4554 Loss_G: 4.4366\n",
            "[2/25][258/782] Loss_D: 0.3556 Loss_G: 3.6267\n",
            "[2/25][259/782] Loss_D: 0.5474 Loss_G: 2.8278\n",
            "[2/25][260/782] Loss_D: 0.4701 Loss_G: 3.8717\n",
            "[2/25][261/782] Loss_D: 0.7804 Loss_G: 2.1908\n",
            "[2/25][262/782] Loss_D: 0.9297 Loss_G: 2.8195\n",
            "[2/25][263/782] Loss_D: 0.7492 Loss_G: 2.1852\n",
            "[2/25][264/782] Loss_D: 0.5962 Loss_G: 3.7633\n",
            "[2/25][265/782] Loss_D: 0.4638 Loss_G: 3.5993\n",
            "[2/25][266/782] Loss_D: 0.7170 Loss_G: 1.7837\n",
            "[2/25][267/782] Loss_D: 0.9405 Loss_G: 3.7800\n",
            "[2/25][268/782] Loss_D: 0.4872 Loss_G: 2.8298\n",
            "[2/25][269/782] Loss_D: 0.6448 Loss_G: 3.2357\n",
            "[2/25][270/782] Loss_D: 0.4619 Loss_G: 3.0402\n",
            "[2/25][271/782] Loss_D: 0.5010 Loss_G: 3.0941\n",
            "[2/25][272/782] Loss_D: 0.4271 Loss_G: 3.2364\n",
            "[2/25][273/782] Loss_D: 0.4306 Loss_G: 2.5893\n",
            "[2/25][274/782] Loss_D: 0.5570 Loss_G: 4.1874\n",
            "[2/25][275/782] Loss_D: 0.5610 Loss_G: 3.1756\n",
            "[2/25][276/782] Loss_D: 0.5494 Loss_G: 1.8702\n",
            "[2/25][277/782] Loss_D: 0.8170 Loss_G: 4.7051\n",
            "[2/25][278/782] Loss_D: 0.8416 Loss_G: 2.9042\n",
            "[2/25][279/782] Loss_D: 0.5452 Loss_G: 4.1133\n",
            "[2/25][280/782] Loss_D: 0.5816 Loss_G: 2.9542\n",
            "[2/25][281/782] Loss_D: 0.8360 Loss_G: 3.8661\n",
            "[2/25][282/782] Loss_D: 0.5726 Loss_G: 3.4328\n",
            "[2/25][283/782] Loss_D: 0.4364 Loss_G: 2.7876\n",
            "[2/25][284/782] Loss_D: 0.6043 Loss_G: 5.4384\n",
            "[2/25][285/782] Loss_D: 0.5921 Loss_G: 3.2541\n",
            "[2/25][286/782] Loss_D: 0.6118 Loss_G: 3.5996\n",
            "[2/25][287/782] Loss_D: 0.8264 Loss_G: 6.6450\n",
            "[2/25][288/782] Loss_D: 1.8273 Loss_G: 0.9294\n",
            "[2/25][289/782] Loss_D: 1.6004 Loss_G: 7.0788\n",
            "[2/25][290/782] Loss_D: 2.3182 Loss_G: 0.8617\n",
            "[2/25][291/782] Loss_D: 1.4834 Loss_G: 4.1130\n",
            "[2/25][292/782] Loss_D: 0.4523 Loss_G: 4.4701\n",
            "[2/25][293/782] Loss_D: 0.6339 Loss_G: 2.5660\n",
            "[2/25][294/782] Loss_D: 0.9261 Loss_G: 4.3788\n",
            "[2/25][295/782] Loss_D: 1.0903 Loss_G: 2.3170\n",
            "[2/25][296/782] Loss_D: 1.3002 Loss_G: 4.4950\n",
            "[2/25][297/782] Loss_D: 1.5343 Loss_G: 1.6073\n",
            "[2/25][298/782] Loss_D: 0.9150 Loss_G: 6.2280\n",
            "[2/25][299/782] Loss_D: 0.8834 Loss_G: 3.2988\n",
            "[2/25][300/782] Loss_D: 0.7425 Loss_G: 4.0755\n",
            "[2/25][301/782] Loss_D: 0.4278 Loss_G: 4.6383\n",
            "[2/25][302/782] Loss_D: 0.6209 Loss_G: 2.4946\n",
            "[2/25][303/782] Loss_D: 0.8391 Loss_G: 4.7852\n",
            "[2/25][304/782] Loss_D: 0.7338 Loss_G: 1.9685\n",
            "[2/25][305/782] Loss_D: 0.9591 Loss_G: 5.8762\n",
            "[2/25][306/782] Loss_D: 1.0118 Loss_G: 1.9469\n",
            "[2/25][307/782] Loss_D: 0.7739 Loss_G: 4.4469\n",
            "[2/25][308/782] Loss_D: 0.5532 Loss_G: 3.1053\n",
            "[2/25][309/782] Loss_D: 0.6541 Loss_G: 3.2866\n",
            "[2/25][310/782] Loss_D: 0.4950 Loss_G: 3.5514\n",
            "[2/25][311/782] Loss_D: 0.5853 Loss_G: 2.6521\n",
            "[2/25][312/782] Loss_D: 0.5437 Loss_G: 3.3492\n",
            "[2/25][313/782] Loss_D: 0.5696 Loss_G: 3.4541\n",
            "[2/25][314/782] Loss_D: 0.5101 Loss_G: 3.4394\n",
            "[2/25][315/782] Loss_D: 0.4370 Loss_G: 2.8714\n",
            "[2/25][316/782] Loss_D: 0.7561 Loss_G: 4.2498\n",
            "[2/25][317/782] Loss_D: 0.6888 Loss_G: 2.6327\n",
            "[2/25][318/782] Loss_D: 0.4450 Loss_G: 3.6492\n",
            "[2/25][319/782] Loss_D: 0.9369 Loss_G: 1.2570\n",
            "[2/25][320/782] Loss_D: 1.1552 Loss_G: 5.4710\n",
            "[2/25][321/782] Loss_D: 1.2906 Loss_G: 1.3537\n",
            "[2/25][322/782] Loss_D: 0.8191 Loss_G: 4.0075\n",
            "[2/25][323/782] Loss_D: 0.5255 Loss_G: 2.8000\n",
            "[2/25][324/782] Loss_D: 0.4257 Loss_G: 3.1132\n",
            "[2/25][325/782] Loss_D: 0.3909 Loss_G: 3.3319\n",
            "[2/25][326/782] Loss_D: 0.4107 Loss_G: 2.6777\n",
            "[2/25][327/782] Loss_D: 0.6932 Loss_G: 3.2439\n",
            "[2/25][328/782] Loss_D: 0.5571 Loss_G: 2.6135\n",
            "[2/25][329/782] Loss_D: 0.5778 Loss_G: 2.9263\n",
            "[2/25][330/782] Loss_D: 0.3955 Loss_G: 3.6042\n",
            "[2/25][331/782] Loss_D: 0.3198 Loss_G: 2.9131\n",
            "[2/25][332/782] Loss_D: 0.3412 Loss_G: 2.7189\n",
            "[2/25][333/782] Loss_D: 0.4560 Loss_G: 3.3511\n",
            "[2/25][334/782] Loss_D: 0.5338 Loss_G: 2.1764\n",
            "[2/25][335/782] Loss_D: 0.5456 Loss_G: 2.5165\n",
            "[2/25][336/782] Loss_D: 0.5481 Loss_G: 3.0535\n",
            "[2/25][337/782] Loss_D: 0.5159 Loss_G: 2.5968\n",
            "[2/25][338/782] Loss_D: 0.5179 Loss_G: 2.7460\n",
            "[2/25][339/782] Loss_D: 0.5079 Loss_G: 3.3143\n",
            "[2/25][340/782] Loss_D: 0.3684 Loss_G: 2.5777\n",
            "[2/25][341/782] Loss_D: 0.4518 Loss_G: 3.2858\n",
            "[2/25][342/782] Loss_D: 0.6089 Loss_G: 1.6866\n",
            "[2/25][343/782] Loss_D: 0.6955 Loss_G: 4.3896\n",
            "[2/25][344/782] Loss_D: 0.7786 Loss_G: 1.6941\n",
            "[2/25][345/782] Loss_D: 0.6790 Loss_G: 4.9690\n",
            "[2/25][346/782] Loss_D: 0.7827 Loss_G: 1.4875\n",
            "[2/25][347/782] Loss_D: 0.7007 Loss_G: 5.1954\n",
            "[2/25][348/782] Loss_D: 0.4252 Loss_G: 2.3296\n",
            "[2/25][349/782] Loss_D: 0.6226 Loss_G: 4.8525\n",
            "[2/25][350/782] Loss_D: 1.2105 Loss_G: 0.9459\n",
            "[2/25][351/782] Loss_D: 1.0447 Loss_G: 4.3256\n",
            "[2/25][352/782] Loss_D: 0.5731 Loss_G: 3.8634\n",
            "[2/25][353/782] Loss_D: 0.6682 Loss_G: 1.9381\n",
            "[2/25][354/782] Loss_D: 0.6564 Loss_G: 2.4983\n",
            "[2/25][355/782] Loss_D: 0.6917 Loss_G: 4.3620\n",
            "[2/25][356/782] Loss_D: 0.6378 Loss_G: 2.2679\n",
            "[2/25][357/782] Loss_D: 0.7232 Loss_G: 3.8450\n",
            "[2/25][358/782] Loss_D: 0.3691 Loss_G: 3.5019\n",
            "[2/25][359/782] Loss_D: 0.3031 Loss_G: 2.8296\n",
            "[2/25][360/782] Loss_D: 0.3957 Loss_G: 3.1449\n",
            "[2/25][361/782] Loss_D: 0.3726 Loss_G: 3.0765\n",
            "[2/25][362/782] Loss_D: 0.6848 Loss_G: 2.4753\n",
            "[2/25][363/782] Loss_D: 0.9492 Loss_G: 4.8739\n",
            "[2/25][364/782] Loss_D: 1.0290 Loss_G: 1.7656\n",
            "[2/25][365/782] Loss_D: 0.6819 Loss_G: 3.7154\n",
            "[2/25][366/782] Loss_D: 0.3522 Loss_G: 3.5473\n",
            "[2/25][367/782] Loss_D: 0.8348 Loss_G: 1.3065\n",
            "[2/25][368/782] Loss_D: 1.0938 Loss_G: 5.9724\n",
            "[2/25][369/782] Loss_D: 1.5408 Loss_G: 0.9977\n",
            "[2/25][370/782] Loss_D: 1.0604 Loss_G: 5.2024\n",
            "[2/25][371/782] Loss_D: 1.1888 Loss_G: 1.4618\n",
            "[2/25][372/782] Loss_D: 1.0879 Loss_G: 4.6663\n",
            "[2/25][373/782] Loss_D: 0.9780 Loss_G: 1.5511\n",
            "[2/25][374/782] Loss_D: 1.0028 Loss_G: 4.0155\n",
            "[2/25][375/782] Loss_D: 0.5163 Loss_G: 3.1409\n",
            "[2/25][376/782] Loss_D: 0.6561 Loss_G: 1.6691\n",
            "[2/25][377/782] Loss_D: 0.8445 Loss_G: 4.8653\n",
            "[2/25][378/782] Loss_D: 0.9801 Loss_G: 1.4085\n",
            "[2/25][379/782] Loss_D: 0.8321 Loss_G: 3.4848\n",
            "[2/25][380/782] Loss_D: 0.5020 Loss_G: 2.6608\n",
            "[2/25][381/782] Loss_D: 0.6122 Loss_G: 3.4821\n",
            "[2/25][382/782] Loss_D: 0.3893 Loss_G: 3.9937\n",
            "[2/25][383/782] Loss_D: 0.3743 Loss_G: 3.1466\n",
            "[2/25][384/782] Loss_D: 0.6101 Loss_G: 1.6736\n",
            "[2/25][385/782] Loss_D: 0.5483 Loss_G: 3.4227\n",
            "[2/25][386/782] Loss_D: 0.5190 Loss_G: 2.7688\n",
            "[2/25][387/782] Loss_D: 0.6324 Loss_G: 3.6815\n",
            "[2/25][388/782] Loss_D: 0.6298 Loss_G: 1.7740\n",
            "[2/25][389/782] Loss_D: 0.9371 Loss_G: 5.3632\n",
            "[2/25][390/782] Loss_D: 1.2742 Loss_G: 1.6856\n",
            "[2/25][391/782] Loss_D: 0.9333 Loss_G: 4.5603\n",
            "[2/25][392/782] Loss_D: 0.7237 Loss_G: 1.7311\n",
            "[2/25][393/782] Loss_D: 1.0287 Loss_G: 5.0004\n",
            "[2/25][394/782] Loss_D: 0.4835 Loss_G: 3.3817\n",
            "[2/25][395/782] Loss_D: 0.5790 Loss_G: 1.5730\n",
            "[2/25][396/782] Loss_D: 0.8870 Loss_G: 5.2997\n",
            "[2/25][397/782] Loss_D: 1.4840 Loss_G: 0.9861\n",
            "[2/25][398/782] Loss_D: 1.4722 Loss_G: 4.6332\n",
            "[2/25][399/782] Loss_D: 0.7533 Loss_G: 2.3194\n",
            "[2/25][400/782] Loss_D: 0.4830 Loss_G: 3.4067\n",
            "[2/25][401/782] Loss_D: 0.4821 Loss_G: 2.6404\n",
            "[2/25][402/782] Loss_D: 0.5449 Loss_G: 2.9215\n",
            "[2/25][403/782] Loss_D: 0.5777 Loss_G: 3.9900\n",
            "[2/25][404/782] Loss_D: 0.9997 Loss_G: 1.1174\n",
            "[2/25][405/782] Loss_D: 1.4953 Loss_G: 4.3816\n",
            "[2/25][406/782] Loss_D: 1.0282 Loss_G: 2.0440\n",
            "[2/25][407/782] Loss_D: 0.6515 Loss_G: 3.0928\n",
            "[2/25][408/782] Loss_D: 0.4911 Loss_G: 2.8566\n",
            "[2/25][409/782] Loss_D: 0.6682 Loss_G: 3.5543\n",
            "[2/25][410/782] Loss_D: 0.7349 Loss_G: 1.8679\n",
            "[2/25][411/782] Loss_D: 0.5462 Loss_G: 2.7210\n",
            "[2/25][412/782] Loss_D: 0.6061 Loss_G: 3.5264\n",
            "[2/25][413/782] Loss_D: 1.1182 Loss_G: 0.8793\n",
            "[2/25][414/782] Loss_D: 0.8274 Loss_G: 4.0307\n",
            "[2/25][415/782] Loss_D: 0.5487 Loss_G: 2.5363\n",
            "[2/25][416/782] Loss_D: 0.5732 Loss_G: 1.8630\n",
            "[2/25][417/782] Loss_D: 0.4911 Loss_G: 4.3724\n",
            "[2/25][418/782] Loss_D: 0.5818 Loss_G: 2.1912\n",
            "[2/25][419/782] Loss_D: 0.6111 Loss_G: 3.3479\n",
            "[2/25][420/782] Loss_D: 0.6982 Loss_G: 2.0203\n",
            "[2/25][421/782] Loss_D: 0.7167 Loss_G: 3.0576\n",
            "[2/25][422/782] Loss_D: 0.4399 Loss_G: 2.7196\n",
            "[2/25][423/782] Loss_D: 0.6198 Loss_G: 2.7858\n",
            "[2/25][424/782] Loss_D: 0.4508 Loss_G: 3.6087\n",
            "[2/25][425/782] Loss_D: 0.7197 Loss_G: 1.4408\n",
            "[2/25][426/782] Loss_D: 0.6984 Loss_G: 3.6037\n",
            "[2/25][427/782] Loss_D: 0.5026 Loss_G: 2.3831\n",
            "[2/25][428/782] Loss_D: 0.6033 Loss_G: 2.8282\n",
            "[2/25][429/782] Loss_D: 0.3714 Loss_G: 2.8466\n",
            "[2/25][430/782] Loss_D: 0.4507 Loss_G: 2.3310\n",
            "[2/25][431/782] Loss_D: 0.7656 Loss_G: 3.7297\n",
            "[2/25][432/782] Loss_D: 0.6881 Loss_G: 1.7415\n",
            "[2/25][433/782] Loss_D: 0.6039 Loss_G: 3.2546\n",
            "[2/25][434/782] Loss_D: 0.6413 Loss_G: 2.9793\n",
            "[2/25][435/782] Loss_D: 0.5965 Loss_G: 2.3941\n",
            "[2/25][436/782] Loss_D: 0.4741 Loss_G: 3.0499\n",
            "[2/25][437/782] Loss_D: 0.3751 Loss_G: 3.7322\n",
            "[2/25][438/782] Loss_D: 0.4537 Loss_G: 2.8077\n",
            "[2/25][439/782] Loss_D: 0.4544 Loss_G: 3.4106\n",
            "[2/25][440/782] Loss_D: 0.3960 Loss_G: 3.1829\n",
            "[2/25][441/782] Loss_D: 0.3977 Loss_G: 2.7109\n",
            "[2/25][442/782] Loss_D: 0.4929 Loss_G: 3.7415\n",
            "[2/25][443/782] Loss_D: 0.3939 Loss_G: 3.0337\n",
            "[2/25][444/782] Loss_D: 0.4713 Loss_G: 3.1945\n",
            "[2/25][445/782] Loss_D: 0.2846 Loss_G: 2.9548\n",
            "[2/25][446/782] Loss_D: 0.4128 Loss_G: 4.7689\n",
            "[2/25][447/782] Loss_D: 0.7059 Loss_G: 2.1324\n",
            "[2/25][448/782] Loss_D: 0.5991 Loss_G: 4.2560\n",
            "[2/25][449/782] Loss_D: 0.7641 Loss_G: 1.6374\n",
            "[2/25][450/782] Loss_D: 0.8354 Loss_G: 6.2507\n",
            "[2/25][451/782] Loss_D: 0.7654 Loss_G: 3.1077\n",
            "[2/25][452/782] Loss_D: 0.3582 Loss_G: 3.2326\n",
            "[2/25][453/782] Loss_D: 0.5904 Loss_G: 3.8572\n",
            "[2/25][454/782] Loss_D: 0.7986 Loss_G: 0.9839\n",
            "[2/25][455/782] Loss_D: 1.5760 Loss_G: 7.7971\n",
            "[2/25][456/782] Loss_D: 2.6325 Loss_G: 0.1692\n",
            "[2/25][457/782] Loss_D: 2.6802 Loss_G: 5.9671\n",
            "[2/25][458/782] Loss_D: 2.9458 Loss_G: 1.4449\n",
            "[2/25][459/782] Loss_D: 1.0773 Loss_G: 3.5523\n",
            "[2/25][460/782] Loss_D: 1.0534 Loss_G: 3.7590\n",
            "[2/25][461/782] Loss_D: 1.0273 Loss_G: 1.4868\n",
            "[2/25][462/782] Loss_D: 1.5252 Loss_G: 5.9850\n",
            "[2/25][463/782] Loss_D: 1.9194 Loss_G: 0.8574\n",
            "[2/25][464/782] Loss_D: 1.5465 Loss_G: 5.1703\n",
            "[2/25][465/782] Loss_D: 0.7753 Loss_G: 2.7401\n",
            "[2/25][466/782] Loss_D: 0.7026 Loss_G: 3.3941\n",
            "[2/25][467/782] Loss_D: 0.6720 Loss_G: 3.1042\n",
            "[2/25][468/782] Loss_D: 0.7103 Loss_G: 2.3019\n",
            "[2/25][469/782] Loss_D: 0.9098 Loss_G: 3.7484\n",
            "[2/25][470/782] Loss_D: 0.9930 Loss_G: 1.3807\n",
            "[2/25][471/782] Loss_D: 0.9652 Loss_G: 3.4837\n",
            "[2/25][472/782] Loss_D: 0.5456 Loss_G: 2.7150\n",
            "[2/25][473/782] Loss_D: 0.7943 Loss_G: 4.1073\n",
            "[2/25][474/782] Loss_D: 1.0288 Loss_G: 1.8104\n",
            "[2/25][475/782] Loss_D: 0.8244 Loss_G: 3.0921\n",
            "[2/25][476/782] Loss_D: 0.4997 Loss_G: 2.9463\n",
            "[2/25][477/782] Loss_D: 0.3917 Loss_G: 2.3997\n",
            "[2/25][478/782] Loss_D: 0.6142 Loss_G: 3.9028\n",
            "[2/25][479/782] Loss_D: 0.5019 Loss_G: 2.8331\n",
            "[2/25][480/782] Loss_D: 0.4624 Loss_G: 1.9227\n",
            "[2/25][481/782] Loss_D: 0.6940 Loss_G: 3.5179\n",
            "[2/25][482/782] Loss_D: 0.4317 Loss_G: 3.1448\n",
            "[2/25][483/782] Loss_D: 0.6509 Loss_G: 2.5424\n",
            "[2/25][484/782] Loss_D: 0.9164 Loss_G: 1.2567\n",
            "[2/25][485/782] Loss_D: 1.1758 Loss_G: 4.8147\n",
            "[2/25][486/782] Loss_D: 1.1582 Loss_G: 1.4118\n",
            "[2/25][487/782] Loss_D: 0.8991 Loss_G: 3.3192\n",
            "[2/25][488/782] Loss_D: 0.5742 Loss_G: 4.1734\n",
            "[2/25][489/782] Loss_D: 1.2061 Loss_G: 0.8879\n",
            "[2/25][490/782] Loss_D: 1.3999 Loss_G: 4.1201\n",
            "[2/25][491/782] Loss_D: 1.0413 Loss_G: 1.1777\n",
            "[2/25][492/782] Loss_D: 0.9019 Loss_G: 4.2305\n",
            "[2/25][493/782] Loss_D: 0.4362 Loss_G: 3.5126\n",
            "[2/25][494/782] Loss_D: 0.4351 Loss_G: 2.1280\n",
            "[2/25][495/782] Loss_D: 0.6865 Loss_G: 2.5864\n",
            "[2/25][496/782] Loss_D: 0.5915 Loss_G: 2.3688\n",
            "[2/25][497/782] Loss_D: 0.4147 Loss_G: 3.0455\n",
            "[2/25][498/782] Loss_D: 0.5613 Loss_G: 2.7999\n",
            "[2/25][499/782] Loss_D: 0.4941 Loss_G: 2.9066\n",
            "[2/25][500/782] Loss_D: 0.5355 Loss_G: 3.2172\n",
            "[2/25][501/782] Loss_D: 1.1026 Loss_G: 0.6045\n",
            "[2/25][502/782] Loss_D: 1.7324 Loss_G: 5.5893\n",
            "[2/25][503/782] Loss_D: 1.2088 Loss_G: 2.4487\n",
            "[2/25][504/782] Loss_D: 0.5592 Loss_G: 1.9096\n",
            "[2/25][505/782] Loss_D: 0.6114 Loss_G: 3.6902\n",
            "[2/25][506/782] Loss_D: 0.6302 Loss_G: 2.4675\n",
            "[2/25][507/782] Loss_D: 0.4145 Loss_G: 2.7538\n",
            "[2/25][508/782] Loss_D: 0.5830 Loss_G: 2.9131\n",
            "[2/25][509/782] Loss_D: 0.6254 Loss_G: 2.0235\n",
            "[2/25][510/782] Loss_D: 0.6032 Loss_G: 3.4352\n",
            "[2/25][511/782] Loss_D: 0.6010 Loss_G: 2.4195\n",
            "[2/25][512/782] Loss_D: 0.5627 Loss_G: 2.1422\n",
            "[2/25][513/782] Loss_D: 0.5815 Loss_G: 3.3613\n",
            "[2/25][514/782] Loss_D: 0.7247 Loss_G: 1.9098\n",
            "[2/25][515/782] Loss_D: 0.7404 Loss_G: 3.9941\n",
            "[2/25][516/782] Loss_D: 0.8929 Loss_G: 2.0625\n",
            "[2/25][517/782] Loss_D: 0.4722 Loss_G: 3.0441\n",
            "[2/25][518/782] Loss_D: 0.4268 Loss_G: 3.2010\n",
            "[2/25][519/782] Loss_D: 0.3271 Loss_G: 3.2199\n",
            "[2/25][520/782] Loss_D: 0.3043 Loss_G: 3.0542\n",
            "[2/25][521/782] Loss_D: 0.3837 Loss_G: 3.0804\n",
            "[2/25][522/782] Loss_D: 0.4318 Loss_G: 2.8533\n",
            "[2/25][523/782] Loss_D: 0.5435 Loss_G: 2.4235\n",
            "[2/25][524/782] Loss_D: 0.3763 Loss_G: 3.5206\n",
            "[2/25][525/782] Loss_D: 0.3928 Loss_G: 3.0388\n",
            "[2/25][526/782] Loss_D: 0.2608 Loss_G: 3.3287\n",
            "[2/25][527/782] Loss_D: 0.3359 Loss_G: 3.3915\n",
            "[2/25][528/782] Loss_D: 0.4940 Loss_G: 2.6884\n",
            "[2/25][529/782] Loss_D: 0.6249 Loss_G: 4.4585\n",
            "[2/25][530/782] Loss_D: 0.9783 Loss_G: 1.7771\n",
            "[2/25][531/782] Loss_D: 0.8623 Loss_G: 3.8093\n",
            "[2/25][532/782] Loss_D: 0.3476 Loss_G: 3.8205\n",
            "[2/25][533/782] Loss_D: 0.4167 Loss_G: 2.4162\n",
            "[2/25][534/782] Loss_D: 0.5202 Loss_G: 3.7469\n",
            "[2/25][535/782] Loss_D: 0.4852 Loss_G: 3.0139\n",
            "[2/25][536/782] Loss_D: 0.3619 Loss_G: 2.9869\n",
            "[2/25][537/782] Loss_D: 0.5197 Loss_G: 2.1170\n",
            "[2/25][538/782] Loss_D: 0.5289 Loss_G: 4.0479\n",
            "[2/25][539/782] Loss_D: 0.3897 Loss_G: 3.3682\n",
            "[2/25][540/782] Loss_D: 0.3989 Loss_G: 2.7633\n",
            "[2/25][541/782] Loss_D: 0.4358 Loss_G: 2.9153\n",
            "[2/25][542/782] Loss_D: 0.2683 Loss_G: 3.4011\n",
            "[2/25][543/782] Loss_D: 0.4802 Loss_G: 2.6425\n",
            "[2/25][544/782] Loss_D: 0.3379 Loss_G: 2.7269\n",
            "[2/25][545/782] Loss_D: 0.6273 Loss_G: 3.1963\n",
            "[2/25][546/782] Loss_D: 0.4320 Loss_G: 2.9724\n",
            "[2/25][547/782] Loss_D: 0.5147 Loss_G: 3.3366\n",
            "[2/25][548/782] Loss_D: 0.3803 Loss_G: 3.1411\n",
            "[2/25][549/782] Loss_D: 0.2397 Loss_G: 3.3845\n",
            "[2/25][550/782] Loss_D: 0.4303 Loss_G: 3.0644\n",
            "[2/25][551/782] Loss_D: 0.4533 Loss_G: 2.9760\n",
            "[2/25][552/782] Loss_D: 0.7024 Loss_G: 2.6339\n",
            "[2/25][553/782] Loss_D: 0.7399 Loss_G: 2.9107\n",
            "[2/25][554/782] Loss_D: 0.6052 Loss_G: 2.8569\n",
            "[2/25][555/782] Loss_D: 0.4771 Loss_G: 3.2738\n",
            "[2/25][556/782] Loss_D: 0.2223 Loss_G: 3.5245\n",
            "[2/25][557/782] Loss_D: 0.5097 Loss_G: 2.1068\n",
            "[2/25][558/782] Loss_D: 0.7087 Loss_G: 5.8884\n",
            "[2/25][559/782] Loss_D: 0.9810 Loss_G: 2.2752\n",
            "[2/25][560/782] Loss_D: 0.6493 Loss_G: 3.3271\n",
            "[2/25][561/782] Loss_D: 0.4758 Loss_G: 3.4786\n",
            "[2/25][562/782] Loss_D: 0.4853 Loss_G: 3.3610\n",
            "[2/25][563/782] Loss_D: 0.4035 Loss_G: 2.2805\n",
            "[2/25][564/782] Loss_D: 0.4958 Loss_G: 4.6951\n",
            "[2/25][565/782] Loss_D: 0.3611 Loss_G: 3.0842\n",
            "[2/25][566/782] Loss_D: 0.2983 Loss_G: 2.4926\n",
            "[2/25][567/782] Loss_D: 0.5108 Loss_G: 5.0959\n",
            "[2/25][568/782] Loss_D: 0.8396 Loss_G: 1.1311\n",
            "[2/25][569/782] Loss_D: 0.6683 Loss_G: 4.9958\n",
            "[2/25][570/782] Loss_D: 0.4872 Loss_G: 2.8564\n",
            "[2/25][571/782] Loss_D: 0.6508 Loss_G: 2.5123\n",
            "[2/25][572/782] Loss_D: 0.4462 Loss_G: 3.6978\n",
            "[2/25][573/782] Loss_D: 0.7513 Loss_G: 0.9675\n",
            "[2/25][574/782] Loss_D: 1.3589 Loss_G: 6.0726\n",
            "[2/25][575/782] Loss_D: 1.4849 Loss_G: 0.4259\n",
            "[2/25][576/782] Loss_D: 1.8480 Loss_G: 6.9367\n",
            "[2/25][577/782] Loss_D: 1.5436 Loss_G: 1.7923\n",
            "[2/25][578/782] Loss_D: 0.8230 Loss_G: 4.1830\n",
            "[2/25][579/782] Loss_D: 0.4395 Loss_G: 3.9151\n",
            "[2/25][580/782] Loss_D: 0.4557 Loss_G: 1.8995\n",
            "[2/25][581/782] Loss_D: 1.0645 Loss_G: 7.0440\n",
            "[2/25][582/782] Loss_D: 2.2757 Loss_G: 0.3999\n",
            "[2/25][583/782] Loss_D: 2.2331 Loss_G: 5.9315\n",
            "[2/25][584/782] Loss_D: 1.0271 Loss_G: 1.0490\n",
            "[2/25][585/782] Loss_D: 1.1148 Loss_G: 6.4177\n",
            "[2/25][586/782] Loss_D: 1.0310 Loss_G: 2.1792\n",
            "[2/25][587/782] Loss_D: 0.6961 Loss_G: 3.3081\n",
            "[2/25][588/782] Loss_D: 0.7117 Loss_G: 3.2232\n",
            "[2/25][589/782] Loss_D: 0.4707 Loss_G: 2.6872\n",
            "[2/25][590/782] Loss_D: 0.5890 Loss_G: 3.2938\n",
            "[2/25][591/782] Loss_D: 0.2642 Loss_G: 3.7988\n",
            "[2/25][592/782] Loss_D: 0.4558 Loss_G: 2.1774\n",
            "[2/25][593/782] Loss_D: 0.4417 Loss_G: 3.0169\n",
            "[2/25][594/782] Loss_D: 0.4969 Loss_G: 2.7869\n",
            "[2/25][595/782] Loss_D: 0.4645 Loss_G: 3.4584\n",
            "[2/25][596/782] Loss_D: 0.4498 Loss_G: 2.6472\n",
            "[2/25][597/782] Loss_D: 0.5078 Loss_G: 3.2825\n",
            "[2/25][598/782] Loss_D: 0.6777 Loss_G: 1.8046\n",
            "[2/25][599/782] Loss_D: 0.6050 Loss_G: 4.0238\n",
            "[2/25][600/782] Loss_D: 0.4308 Loss_G: 3.4184\n",
            "[2/25][601/782] Loss_D: 0.4112 Loss_G: 2.3355\n",
            "[2/25][602/782] Loss_D: 0.8006 Loss_G: 4.0195\n",
            "[2/25][603/782] Loss_D: 0.2690 Loss_G: 4.0905\n",
            "[2/25][604/782] Loss_D: 0.4582 Loss_G: 1.7759\n",
            "[2/25][605/782] Loss_D: 0.7580 Loss_G: 4.4008\n",
            "[2/25][606/782] Loss_D: 0.9748 Loss_G: 1.5178\n",
            "[2/25][607/782] Loss_D: 0.9361 Loss_G: 4.6887\n",
            "[2/25][608/782] Loss_D: 0.9992 Loss_G: 1.9136\n",
            "[2/25][609/782] Loss_D: 0.8471 Loss_G: 3.8846\n",
            "[2/25][610/782] Loss_D: 0.5228 Loss_G: 3.0732\n",
            "[2/25][611/782] Loss_D: 0.6632 Loss_G: 3.4255\n",
            "[2/25][612/782] Loss_D: 0.7845 Loss_G: 2.9940\n",
            "[2/25][613/782] Loss_D: 0.5171 Loss_G: 3.4457\n",
            "[2/25][614/782] Loss_D: 0.6898 Loss_G: 2.9639\n",
            "[2/25][615/782] Loss_D: 0.3403 Loss_G: 3.5475\n",
            "[2/25][616/782] Loss_D: 0.4758 Loss_G: 3.6654\n",
            "[2/25][617/782] Loss_D: 0.4278 Loss_G: 3.3112\n",
            "[2/25][618/782] Loss_D: 0.3528 Loss_G: 3.2442\n",
            "[2/25][619/782] Loss_D: 0.5955 Loss_G: 4.4860\n",
            "[2/25][620/782] Loss_D: 0.7009 Loss_G: 1.9671\n",
            "[2/25][621/782] Loss_D: 0.8789 Loss_G: 5.1003\n",
            "[2/25][622/782] Loss_D: 0.7002 Loss_G: 2.5013\n",
            "[2/25][623/782] Loss_D: 0.5615 Loss_G: 3.9407\n",
            "[2/25][624/782] Loss_D: 0.6305 Loss_G: 2.1842\n",
            "[2/25][625/782] Loss_D: 0.6252 Loss_G: 4.2386\n",
            "[2/25][626/782] Loss_D: 0.7011 Loss_G: 2.0547\n",
            "[2/25][627/782] Loss_D: 0.5753 Loss_G: 3.5467\n",
            "[2/25][628/782] Loss_D: 0.3861 Loss_G: 2.9991\n",
            "[2/25][629/782] Loss_D: 0.3938 Loss_G: 4.1121\n",
            "[2/25][630/782] Loss_D: 0.4514 Loss_G: 2.0832\n",
            "[2/25][631/782] Loss_D: 0.5340 Loss_G: 4.2872\n",
            "[2/25][632/782] Loss_D: 0.4794 Loss_G: 2.6292\n",
            "[2/25][633/782] Loss_D: 0.3798 Loss_G: 3.3833\n",
            "[2/25][634/782] Loss_D: 0.3607 Loss_G: 2.9823\n",
            "[2/25][635/782] Loss_D: 0.4512 Loss_G: 2.0236\n",
            "[2/25][636/782] Loss_D: 0.6621 Loss_G: 4.5578\n",
            "[2/25][637/782] Loss_D: 0.6692 Loss_G: 1.4232\n",
            "[2/25][638/782] Loss_D: 0.7642 Loss_G: 4.4457\n",
            "[2/25][639/782] Loss_D: 0.5370 Loss_G: 2.1887\n",
            "[2/25][640/782] Loss_D: 0.3641 Loss_G: 4.2404\n",
            "[2/25][641/782] Loss_D: 0.4978 Loss_G: 2.9372\n",
            "[2/25][642/782] Loss_D: 0.4015 Loss_G: 3.2525\n",
            "[2/25][643/782] Loss_D: 0.3035 Loss_G: 3.3866\n",
            "[2/25][644/782] Loss_D: 0.5505 Loss_G: 1.6481\n",
            "[2/25][645/782] Loss_D: 0.9177 Loss_G: 5.8800\n",
            "[2/25][646/782] Loss_D: 0.8031 Loss_G: 2.9368\n",
            "[2/25][647/782] Loss_D: 0.2142 Loss_G: 2.5147\n",
            "[2/25][648/782] Loss_D: 0.6795 Loss_G: 5.3636\n",
            "[2/25][649/782] Loss_D: 0.9216 Loss_G: 2.3159\n",
            "[2/25][650/782] Loss_D: 0.6683 Loss_G: 4.2333\n",
            "[2/25][651/782] Loss_D: 0.4235 Loss_G: 2.3353\n",
            "[2/25][652/782] Loss_D: 0.6754 Loss_G: 4.5471\n",
            "[2/25][653/782] Loss_D: 0.7695 Loss_G: 2.2137\n",
            "[2/25][654/782] Loss_D: 0.4939 Loss_G: 4.4161\n",
            "[2/25][655/782] Loss_D: 0.3655 Loss_G: 3.2480\n",
            "[2/25][656/782] Loss_D: 0.5257 Loss_G: 3.1972\n",
            "[2/25][657/782] Loss_D: 0.3505 Loss_G: 3.2392\n",
            "[2/25][658/782] Loss_D: 0.4540 Loss_G: 2.9861\n",
            "[2/25][659/782] Loss_D: 0.5148 Loss_G: 3.4828\n",
            "[2/25][660/782] Loss_D: 0.6198 Loss_G: 2.4500\n",
            "[2/25][661/782] Loss_D: 0.5674 Loss_G: 4.0355\n",
            "[2/25][662/782] Loss_D: 0.5919 Loss_G: 1.8750\n",
            "[2/25][663/782] Loss_D: 0.6773 Loss_G: 4.8096\n",
            "[2/25][664/782] Loss_D: 0.5798 Loss_G: 2.7550\n",
            "[2/25][665/782] Loss_D: 0.4878 Loss_G: 3.6456\n",
            "[2/25][666/782] Loss_D: 0.4185 Loss_G: 2.3990\n",
            "[2/25][667/782] Loss_D: 0.3885 Loss_G: 4.0490\n",
            "[2/25][668/782] Loss_D: 0.1990 Loss_G: 3.9657\n",
            "[2/25][669/782] Loss_D: 0.4598 Loss_G: 2.4245\n",
            "[2/25][670/782] Loss_D: 0.5706 Loss_G: 2.9661\n",
            "[2/25][671/782] Loss_D: 0.3680 Loss_G: 3.5492\n",
            "[2/25][672/782] Loss_D: 0.3822 Loss_G: 3.5303\n",
            "[2/25][673/782] Loss_D: 0.4280 Loss_G: 1.9718\n",
            "[2/25][674/782] Loss_D: 0.5311 Loss_G: 4.9241\n",
            "[2/25][675/782] Loss_D: 0.7357 Loss_G: 1.4847\n",
            "[2/25][676/782] Loss_D: 0.9076 Loss_G: 5.1882\n",
            "[2/25][677/782] Loss_D: 0.9427 Loss_G: 0.5993\n",
            "[2/25][678/782] Loss_D: 1.7067 Loss_G: 8.6098\n",
            "[2/25][679/782] Loss_D: 3.1278 Loss_G: 0.8053\n",
            "[2/25][680/782] Loss_D: 1.5595 Loss_G: 5.5672\n",
            "[2/25][681/782] Loss_D: 1.0394 Loss_G: 1.2435\n",
            "[2/25][682/782] Loss_D: 1.0343 Loss_G: 4.5467\n",
            "[2/25][683/782] Loss_D: 0.7540 Loss_G: 2.1250\n",
            "[2/25][684/782] Loss_D: 0.4391 Loss_G: 3.0492\n",
            "[2/25][685/782] Loss_D: 0.5560 Loss_G: 3.3635\n",
            "[2/25][686/782] Loss_D: 0.5307 Loss_G: 3.2412\n",
            "[2/25][687/782] Loss_D: 0.7443 Loss_G: 2.7708\n",
            "[2/25][688/782] Loss_D: 0.6362 Loss_G: 2.0654\n",
            "[2/25][689/782] Loss_D: 0.8200 Loss_G: 4.8318\n",
            "[2/25][690/782] Loss_D: 1.1094 Loss_G: 0.5884\n",
            "[2/25][691/782] Loss_D: 1.5639 Loss_G: 5.9021\n",
            "[2/25][692/782] Loss_D: 0.9848 Loss_G: 2.1896\n",
            "[2/25][693/782] Loss_D: 0.6205 Loss_G: 4.5228\n",
            "[2/25][694/782] Loss_D: 0.4494 Loss_G: 3.2974\n",
            "[2/25][695/782] Loss_D: 0.5045 Loss_G: 2.1062\n",
            "[2/25][696/782] Loss_D: 0.9817 Loss_G: 5.8608\n",
            "[2/25][697/782] Loss_D: 1.5456 Loss_G: 2.1523\n",
            "[2/25][698/782] Loss_D: 0.6189 Loss_G: 3.4338\n",
            "[2/25][699/782] Loss_D: 0.3172 Loss_G: 5.0522\n",
            "[2/25][700/782] Loss_D: 0.3762 Loss_G: 3.2173\n",
            "[2/25][701/782] Loss_D: 0.4262 Loss_G: 3.2883\n",
            "[2/25][702/782] Loss_D: 0.6319 Loss_G: 3.6280\n",
            "[2/25][703/782] Loss_D: 1.6405 Loss_G: 0.2350\n",
            "[2/25][704/782] Loss_D: 2.2266 Loss_G: 6.5887\n",
            "[2/25][705/782] Loss_D: 1.0950 Loss_G: 1.8896\n",
            "[2/25][706/782] Loss_D: 0.7461 Loss_G: 4.3679\n",
            "[2/25][707/782] Loss_D: 0.8278 Loss_G: 1.5525\n",
            "[2/25][708/782] Loss_D: 1.0039 Loss_G: 5.0998\n",
            "[2/25][709/782] Loss_D: 0.6596 Loss_G: 1.7164\n",
            "[2/25][710/782] Loss_D: 0.8151 Loss_G: 2.9608\n",
            "[2/25][711/782] Loss_D: 0.4805 Loss_G: 3.6591\n",
            "[2/25][712/782] Loss_D: 0.8109 Loss_G: 1.2766\n",
            "[2/25][713/782] Loss_D: 1.1522 Loss_G: 4.7751\n",
            "[2/25][714/782] Loss_D: 1.3909 Loss_G: 0.9416\n",
            "[2/25][715/782] Loss_D: 1.1339 Loss_G: 3.6366\n",
            "[2/25][716/782] Loss_D: 0.3750 Loss_G: 3.0187\n",
            "[2/25][717/782] Loss_D: 0.7208 Loss_G: 1.4236\n",
            "[2/25][718/782] Loss_D: 0.6189 Loss_G: 4.9521\n",
            "[2/25][719/782] Loss_D: 0.7570 Loss_G: 1.8140\n",
            "[2/25][720/782] Loss_D: 1.0869 Loss_G: 4.3352\n",
            "[2/25][721/782] Loss_D: 0.5585 Loss_G: 2.8769\n",
            "[2/25][722/782] Loss_D: 0.7998 Loss_G: 3.1449\n",
            "[2/25][723/782] Loss_D: 0.4437 Loss_G: 3.1711\n",
            "[2/25][724/782] Loss_D: 0.6085 Loss_G: 2.8434\n",
            "[2/25][725/782] Loss_D: 0.5077 Loss_G: 2.7051\n",
            "[2/25][726/782] Loss_D: 0.6271 Loss_G: 3.3742\n",
            "[2/25][727/782] Loss_D: 0.8528 Loss_G: 1.3641\n",
            "[2/25][728/782] Loss_D: 1.1511 Loss_G: 4.8562\n",
            "[2/25][729/782] Loss_D: 0.8800 Loss_G: 2.1536\n",
            "[2/25][730/782] Loss_D: 0.7012 Loss_G: 3.7464\n",
            "[2/25][731/782] Loss_D: 0.4979 Loss_G: 2.8218\n",
            "[2/25][732/782] Loss_D: 0.4785 Loss_G: 2.3918\n",
            "[2/25][733/782] Loss_D: 0.5312 Loss_G: 3.8393\n",
            "[2/25][734/782] Loss_D: 0.6278 Loss_G: 2.2658\n",
            "[2/25][735/782] Loss_D: 0.3650 Loss_G: 3.1767\n",
            "[2/25][736/782] Loss_D: 0.2225 Loss_G: 3.6079\n",
            "[2/25][737/782] Loss_D: 0.2947 Loss_G: 3.5929\n",
            "[2/25][738/782] Loss_D: 0.3477 Loss_G: 3.1519\n",
            "[2/25][739/782] Loss_D: 0.4872 Loss_G: 2.0396\n",
            "[2/25][740/782] Loss_D: 0.5090 Loss_G: 3.0303\n",
            "[2/25][741/782] Loss_D: 0.4776 Loss_G: 3.2687\n",
            "[2/25][742/782] Loss_D: 0.5160 Loss_G: 2.4628\n",
            "[2/25][743/782] Loss_D: 0.5616 Loss_G: 3.8564\n",
            "[2/25][744/782] Loss_D: 0.4408 Loss_G: 2.8298\n",
            "[2/25][745/782] Loss_D: 0.4504 Loss_G: 2.4706\n",
            "[2/25][746/782] Loss_D: 0.6655 Loss_G: 4.7923\n",
            "[2/25][747/782] Loss_D: 0.7642 Loss_G: 2.0664\n",
            "[2/25][748/782] Loss_D: 0.5101 Loss_G: 4.2199\n",
            "[2/25][749/782] Loss_D: 0.4186 Loss_G: 3.0906\n",
            "[2/25][750/782] Loss_D: 0.4073 Loss_G: 3.3153\n",
            "[2/25][751/782] Loss_D: 0.1903 Loss_G: 3.9879\n",
            "[2/25][752/782] Loss_D: 0.3420 Loss_G: 3.8897\n",
            "[2/25][753/782] Loss_D: 0.5838 Loss_G: 1.7892\n",
            "[2/25][754/782] Loss_D: 0.5411 Loss_G: 4.2760\n",
            "[2/25][755/782] Loss_D: 0.4419 Loss_G: 3.2427\n",
            "[2/25][756/782] Loss_D: 0.2596 Loss_G: 2.6073\n",
            "[2/25][757/782] Loss_D: 0.4675 Loss_G: 3.7689\n",
            "[2/25][758/782] Loss_D: 0.4757 Loss_G: 2.4156\n",
            "[2/25][759/782] Loss_D: 0.3647 Loss_G: 3.2820\n",
            "[2/25][760/782] Loss_D: 0.2996 Loss_G: 2.9288\n",
            "[2/25][761/782] Loss_D: 0.3763 Loss_G: 3.3744\n",
            "[2/25][762/782] Loss_D: 0.3513 Loss_G: 3.1536\n",
            "[2/25][763/782] Loss_D: 0.2851 Loss_G: 3.1995\n",
            "[2/25][764/782] Loss_D: 0.2931 Loss_G: 3.5681\n",
            "[2/25][765/782] Loss_D: 0.2519 Loss_G: 3.3059\n",
            "[2/25][766/782] Loss_D: 0.2753 Loss_G: 3.1534\n",
            "[2/25][767/782] Loss_D: 0.2229 Loss_G: 3.5164\n",
            "[2/25][768/782] Loss_D: 0.3576 Loss_G: 3.1454\n",
            "[2/25][769/782] Loss_D: 0.4407 Loss_G: 2.9129\n",
            "[2/25][770/782] Loss_D: 0.6146 Loss_G: 2.7824\n",
            "[2/25][771/782] Loss_D: 0.3489 Loss_G: 4.3963\n",
            "[2/25][772/782] Loss_D: 0.3252 Loss_G: 3.1123\n",
            "[2/25][773/782] Loss_D: 0.4014 Loss_G: 4.1348\n",
            "[2/25][774/782] Loss_D: 0.6146 Loss_G: 2.7395\n",
            "[2/25][775/782] Loss_D: 0.5996 Loss_G: 3.7978\n",
            "[2/25][776/782] Loss_D: 0.4430 Loss_G: 2.3830\n",
            "[2/25][777/782] Loss_D: 0.4354 Loss_G: 3.9329\n",
            "[2/25][778/782] Loss_D: 0.3036 Loss_G: 3.4369\n",
            "[2/25][779/782] Loss_D: 0.1787 Loss_G: 3.2899\n",
            "[2/25][780/782] Loss_D: 0.3499 Loss_G: 2.8845\n",
            "[2/25][781/782] Loss_D: 0.3929 Loss_G: 2.8871\n",
            "[3/25][0/782] Loss_D: 0.6291 Loss_G: 5.7799\n",
            "[3/25][1/782] Loss_D: 1.1426 Loss_G: 1.8582\n",
            "[3/25][2/782] Loss_D: 0.9751 Loss_G: 5.9857\n",
            "[3/25][3/782] Loss_D: 2.2340 Loss_G: 0.2067\n",
            "[3/25][4/782] Loss_D: 2.4288 Loss_G: 5.3400\n",
            "[3/25][5/782] Loss_D: 1.5146 Loss_G: 0.1051\n",
            "[3/25][6/782] Loss_D: 3.9155 Loss_G: 4.8053\n",
            "[3/25][7/782] Loss_D: 1.9871 Loss_G: 1.3393\n",
            "[3/25][8/782] Loss_D: 1.1955 Loss_G: 2.0821\n",
            "[3/25][9/782] Loss_D: 1.3946 Loss_G: 4.7948\n",
            "[3/25][10/782] Loss_D: 2.0361 Loss_G: 0.9536\n",
            "[3/25][11/782] Loss_D: 1.6089 Loss_G: 3.6179\n",
            "[3/25][12/782] Loss_D: 2.3121 Loss_G: 0.6214\n",
            "[3/25][13/782] Loss_D: 1.7758 Loss_G: 5.3575\n",
            "[3/25][14/782] Loss_D: 1.7563 Loss_G: 1.2642\n",
            "[3/25][15/782] Loss_D: 1.4417 Loss_G: 3.6718\n",
            "[3/25][16/782] Loss_D: 0.6248 Loss_G: 3.6114\n",
            "[3/25][17/782] Loss_D: 0.6855 Loss_G: 1.6558\n",
            "[3/25][18/782] Loss_D: 0.7252 Loss_G: 4.1011\n",
            "[3/25][19/782] Loss_D: 0.9950 Loss_G: 1.4796\n",
            "[3/25][20/782] Loss_D: 0.9931 Loss_G: 4.7372\n",
            "[3/25][21/782] Loss_D: 0.7097 Loss_G: 2.0068\n",
            "[3/25][22/782] Loss_D: 0.8114 Loss_G: 3.5244\n",
            "[3/25][23/782] Loss_D: 0.9123 Loss_G: 2.3337\n",
            "[3/25][24/782] Loss_D: 0.6446 Loss_G: 3.1176\n",
            "[3/25][25/782] Loss_D: 0.7876 Loss_G: 1.5449\n",
            "[3/25][26/782] Loss_D: 0.9216 Loss_G: 3.5897\n",
            "[3/25][27/782] Loss_D: 0.7384 Loss_G: 2.0973\n",
            "[3/25][28/782] Loss_D: 0.6689 Loss_G: 2.4108\n",
            "[3/25][29/782] Loss_D: 0.5564 Loss_G: 2.7488\n",
            "[3/25][30/782] Loss_D: 0.4697 Loss_G: 2.9826\n",
            "[3/25][31/782] Loss_D: 0.6293 Loss_G: 2.4369\n",
            "[3/25][32/782] Loss_D: 0.8184 Loss_G: 2.4161\n",
            "[3/25][33/782] Loss_D: 0.4938 Loss_G: 3.0460\n",
            "[3/25][34/782] Loss_D: 0.5553 Loss_G: 3.3758\n",
            "[3/25][35/782] Loss_D: 1.1733 Loss_G: 0.7420\n",
            "[3/25][36/782] Loss_D: 1.4542 Loss_G: 5.7491\n",
            "[3/25][37/782] Loss_D: 0.7732 Loss_G: 3.7748\n",
            "[3/25][38/782] Loss_D: 0.3266 Loss_G: 2.3174\n",
            "[3/25][39/782] Loss_D: 0.4485 Loss_G: 3.5474\n",
            "[3/25][40/782] Loss_D: 0.6426 Loss_G: 3.8452\n",
            "[3/25][41/782] Loss_D: 0.4431 Loss_G: 2.9641\n",
            "[3/25][42/782] Loss_D: 0.5926 Loss_G: 3.9588\n",
            "[3/25][43/782] Loss_D: 1.0875 Loss_G: 2.3614\n",
            "[3/25][44/782] Loss_D: 0.6480 Loss_G: 3.5440\n",
            "[3/25][45/782] Loss_D: 0.6039 Loss_G: 2.4820\n",
            "[3/25][46/782] Loss_D: 0.7676 Loss_G: 4.1608\n",
            "[3/25][47/782] Loss_D: 1.0611 Loss_G: 1.3020\n",
            "[3/25][48/782] Loss_D: 1.2984 Loss_G: 5.5288\n",
            "[3/25][49/782] Loss_D: 0.8090 Loss_G: 3.1227\n",
            "[3/25][50/782] Loss_D: 0.6477 Loss_G: 2.7412\n",
            "[3/25][51/782] Loss_D: 0.7864 Loss_G: 4.3075\n",
            "[3/25][52/782] Loss_D: 0.6256 Loss_G: 2.9672\n",
            "[3/25][53/782] Loss_D: 0.6412 Loss_G: 2.7006\n",
            "[3/25][54/782] Loss_D: 0.4878 Loss_G: 4.2477\n",
            "[3/25][55/782] Loss_D: 0.8143 Loss_G: 2.2147\n",
            "[3/25][56/782] Loss_D: 0.6734 Loss_G: 3.3796\n",
            "[3/25][57/782] Loss_D: 0.7272 Loss_G: 2.0125\n",
            "[3/25][58/782] Loss_D: 0.7298 Loss_G: 4.0610\n",
            "[3/25][59/782] Loss_D: 0.5772 Loss_G: 2.2051\n",
            "[3/25][60/782] Loss_D: 0.5937 Loss_G: 3.9744\n",
            "[3/25][61/782] Loss_D: 0.4500 Loss_G: 2.8678\n",
            "[3/25][62/782] Loss_D: 0.6083 Loss_G: 1.9669\n",
            "[3/25][63/782] Loss_D: 0.7571 Loss_G: 4.0934\n",
            "[3/25][64/782] Loss_D: 0.5817 Loss_G: 2.3965\n",
            "[3/25][65/782] Loss_D: 0.5946 Loss_G: 3.5193\n",
            "[3/25][66/782] Loss_D: 0.5951 Loss_G: 2.1381\n",
            "[3/25][67/782] Loss_D: 0.3874 Loss_G: 3.6942\n",
            "[3/25][68/782] Loss_D: 0.3755 Loss_G: 2.4538\n",
            "[3/25][69/782] Loss_D: 0.5647 Loss_G: 2.7770\n",
            "[3/25][70/782] Loss_D: 0.5522 Loss_G: 3.8716\n",
            "[3/25][71/782] Loss_D: 0.5979 Loss_G: 2.0881\n",
            "[3/25][72/782] Loss_D: 0.4311 Loss_G: 3.2911\n",
            "[3/25][73/782] Loss_D: 0.4816 Loss_G: 4.5169\n",
            "[3/25][74/782] Loss_D: 0.9659 Loss_G: 0.8623\n",
            "[3/25][75/782] Loss_D: 1.1101 Loss_G: 5.6835\n",
            "[3/25][76/782] Loss_D: 2.4753 Loss_G: 0.1767\n",
            "[3/25][77/782] Loss_D: 2.4970 Loss_G: 5.6460\n",
            "[3/25][78/782] Loss_D: 1.1325 Loss_G: 0.6220\n",
            "[3/25][79/782] Loss_D: 1.9307 Loss_G: 4.7367\n",
            "[3/25][80/782] Loss_D: 2.1007 Loss_G: 1.0262\n",
            "[3/25][81/782] Loss_D: 1.2600 Loss_G: 1.9580\n",
            "[3/25][82/782] Loss_D: 0.9049 Loss_G: 3.9575\n",
            "[3/25][83/782] Loss_D: 1.2316 Loss_G: 1.6254\n",
            "[3/25][84/782] Loss_D: 1.0294 Loss_G: 3.6933\n",
            "[3/25][85/782] Loss_D: 1.2063 Loss_G: 2.0360\n",
            "[3/25][86/782] Loss_D: 0.6808 Loss_G: 3.3507\n",
            "[3/25][87/782] Loss_D: 0.8462 Loss_G: 4.8872\n",
            "[3/25][88/782] Loss_D: 1.3408 Loss_G: 0.5224\n",
            "[3/25][89/782] Loss_D: 1.8115 Loss_G: 5.3148\n",
            "[3/25][90/782] Loss_D: 0.6897 Loss_G: 2.9425\n",
            "[3/25][91/782] Loss_D: 0.5393 Loss_G: 2.8031\n",
            "[3/25][92/782] Loss_D: 0.3495 Loss_G: 3.8915\n",
            "[3/25][93/782] Loss_D: 1.0438 Loss_G: 1.4942\n",
            "[3/25][94/782] Loss_D: 0.8137 Loss_G: 3.9935\n",
            "[3/25][95/782] Loss_D: 0.7677 Loss_G: 2.6662\n",
            "[3/25][96/782] Loss_D: 0.7231 Loss_G: 3.4748\n",
            "[3/25][97/782] Loss_D: 0.6190 Loss_G: 2.8014\n",
            "[3/25][98/782] Loss_D: 1.0618 Loss_G: 1.9262\n",
            "[3/25][99/782] Loss_D: 0.6403 Loss_G: 3.3308\n",
            "[3/25][100/782] Loss_D: 0.4804 Loss_G: 2.9337\n",
            "[3/25][101/782] Loss_D: 0.4316 Loss_G: 2.7108\n",
            "[3/25][102/782] Loss_D: 0.4262 Loss_G: 3.3978\n",
            "[3/25][103/782] Loss_D: 0.8077 Loss_G: 1.7902\n",
            "[3/25][104/782] Loss_D: 0.7103 Loss_G: 3.6601\n",
            "[3/25][105/782] Loss_D: 0.6403 Loss_G: 2.5785\n",
            "[3/25][106/782] Loss_D: 0.5852 Loss_G: 3.2974\n",
            "[3/25][107/782] Loss_D: 0.3113 Loss_G: 3.3807\n",
            "[3/25][108/782] Loss_D: 0.4508 Loss_G: 2.3207\n",
            "[3/25][109/782] Loss_D: 0.8157 Loss_G: 3.0990\n",
            "[3/25][110/782] Loss_D: 0.4151 Loss_G: 3.0773\n",
            "[3/25][111/782] Loss_D: 0.3907 Loss_G: 3.1487\n",
            "[3/25][112/782] Loss_D: 0.4964 Loss_G: 2.9626\n",
            "[3/25][113/782] Loss_D: 0.5629 Loss_G: 2.2469\n",
            "[3/25][114/782] Loss_D: 0.5631 Loss_G: 3.9748\n",
            "[3/25][115/782] Loss_D: 0.3917 Loss_G: 3.0279\n",
            "[3/25][116/782] Loss_D: 0.4076 Loss_G: 3.3367\n",
            "[3/25][117/782] Loss_D: 0.4906 Loss_G: 2.6983\n",
            "[3/25][118/782] Loss_D: 0.4124 Loss_G: 3.7443\n",
            "[3/25][119/782] Loss_D: 0.4430 Loss_G: 2.7973\n",
            "[3/25][120/782] Loss_D: 0.4866 Loss_G: 3.0222\n",
            "[3/25][121/782] Loss_D: 0.5160 Loss_G: 2.1666\n",
            "[3/25][122/782] Loss_D: 0.5546 Loss_G: 4.8400\n",
            "[3/25][123/782] Loss_D: 0.8386 Loss_G: 1.7154\n",
            "[3/25][124/782] Loss_D: 0.9801 Loss_G: 5.6706\n",
            "[3/25][125/782] Loss_D: 1.0741 Loss_G: 1.8714\n",
            "[3/25][126/782] Loss_D: 0.8321 Loss_G: 4.0463\n",
            "[3/25][127/782] Loss_D: 0.4278 Loss_G: 3.4815\n",
            "[3/25][128/782] Loss_D: 0.4769 Loss_G: 3.5822\n",
            "[3/25][129/782] Loss_D: 0.3333 Loss_G: 3.2808\n",
            "[3/25][130/782] Loss_D: 0.4307 Loss_G: 2.8626\n",
            "[3/25][131/782] Loss_D: 0.3861 Loss_G: 3.7522\n",
            "[3/25][132/782] Loss_D: 0.4134 Loss_G: 3.6162\n",
            "[3/25][133/782] Loss_D: 0.5368 Loss_G: 3.3953\n",
            "[3/25][134/782] Loss_D: 0.4927 Loss_G: 2.9423\n",
            "[3/25][135/782] Loss_D: 0.4470 Loss_G: 3.7124\n",
            "[3/25][136/782] Loss_D: 0.4001 Loss_G: 2.6870\n",
            "[3/25][137/782] Loss_D: 0.4067 Loss_G: 3.0434\n",
            "[3/25][138/782] Loss_D: 0.3988 Loss_G: 3.7201\n",
            "[3/25][139/782] Loss_D: 0.4398 Loss_G: 3.9720\n",
            "[3/25][140/782] Loss_D: 0.5165 Loss_G: 2.4242\n",
            "[3/25][141/782] Loss_D: 0.6729 Loss_G: 4.2278\n",
            "[3/25][142/782] Loss_D: 0.5657 Loss_G: 1.9910\n",
            "[3/25][143/782] Loss_D: 0.9144 Loss_G: 5.0799\n",
            "[3/25][144/782] Loss_D: 0.5773 Loss_G: 2.7021\n",
            "[3/25][145/782] Loss_D: 0.4288 Loss_G: 2.4867\n",
            "[3/25][146/782] Loss_D: 0.4383 Loss_G: 4.3879\n",
            "[3/25][147/782] Loss_D: 0.4901 Loss_G: 2.6327\n",
            "[3/25][148/782] Loss_D: 0.3677 Loss_G: 2.7979\n",
            "[3/25][149/782] Loss_D: 0.6125 Loss_G: 4.4330\n",
            "[3/25][150/782] Loss_D: 0.5356 Loss_G: 2.5193\n",
            "[3/25][151/782] Loss_D: 0.5861 Loss_G: 4.5052\n",
            "[3/25][152/782] Loss_D: 0.3626 Loss_G: 3.0955\n",
            "[3/25][153/782] Loss_D: 0.4146 Loss_G: 3.2172\n",
            "[3/25][154/782] Loss_D: 0.4433 Loss_G: 3.7516\n",
            "[3/25][155/782] Loss_D: 0.4977 Loss_G: 2.3454\n",
            "[3/25][156/782] Loss_D: 0.6258 Loss_G: 4.2306\n",
            "[3/25][157/782] Loss_D: 0.8036 Loss_G: 1.0452\n",
            "[3/25][158/782] Loss_D: 1.3824 Loss_G: 8.4067\n",
            "[3/25][159/782] Loss_D: 2.3650 Loss_G: 0.9816\n",
            "[3/25][160/782] Loss_D: 0.9526 Loss_G: 5.9977\n",
            "[3/25][161/782] Loss_D: 1.5791 Loss_G: 0.5559\n",
            "[3/25][162/782] Loss_D: 2.1207 Loss_G: 7.0620\n",
            "[3/25][163/782] Loss_D: 1.7681 Loss_G: 1.5408\n",
            "[3/25][164/782] Loss_D: 1.2672 Loss_G: 4.3983\n",
            "[3/25][165/782] Loss_D: 0.5481 Loss_G: 3.1286\n",
            "[3/25][166/782] Loss_D: 0.8727 Loss_G: 2.4654\n",
            "[3/25][167/782] Loss_D: 1.0300 Loss_G: 1.9856\n",
            "[3/25][168/782] Loss_D: 1.0274 Loss_G: 4.2172\n",
            "[3/25][169/782] Loss_D: 0.9456 Loss_G: 1.8435\n",
            "[3/25][170/782] Loss_D: 0.7221 Loss_G: 3.3028\n",
            "[3/25][171/782] Loss_D: 0.3530 Loss_G: 4.0781\n",
            "[3/25][172/782] Loss_D: 0.7296 Loss_G: 2.2864\n",
            "[3/25][173/782] Loss_D: 0.5341 Loss_G: 2.9168\n",
            "[3/25][174/782] Loss_D: 0.9238 Loss_G: 2.8271\n",
            "[3/25][175/782] Loss_D: 0.4391 Loss_G: 3.1550\n",
            "[3/25][176/782] Loss_D: 0.7341 Loss_G: 3.5863\n",
            "[3/25][177/782] Loss_D: 0.8381 Loss_G: 2.6923\n",
            "[3/25][178/782] Loss_D: 0.8196 Loss_G: 2.9449\n",
            "[3/25][179/782] Loss_D: 0.7300 Loss_G: 3.9412\n",
            "[3/25][180/782] Loss_D: 0.7466 Loss_G: 2.3565\n",
            "[3/25][181/782] Loss_D: 0.6320 Loss_G: 4.8398\n",
            "[3/25][182/782] Loss_D: 0.6673 Loss_G: 2.4529\n",
            "[3/25][183/782] Loss_D: 0.7211 Loss_G: 4.9748\n",
            "[3/25][184/782] Loss_D: 0.4855 Loss_G: 3.6183\n",
            "[3/25][185/782] Loss_D: 0.2930 Loss_G: 3.0622\n",
            "[3/25][186/782] Loss_D: 0.6345 Loss_G: 4.7622\n",
            "[3/25][187/782] Loss_D: 0.7818 Loss_G: 2.1786\n",
            "[3/25][188/782] Loss_D: 0.9978 Loss_G: 5.7517\n",
            "[3/25][189/782] Loss_D: 1.0553 Loss_G: 1.5973\n",
            "[3/25][190/782] Loss_D: 1.3469 Loss_G: 4.7624\n",
            "[3/25][191/782] Loss_D: 0.6759 Loss_G: 2.9078\n",
            "[3/25][192/782] Loss_D: 0.4983 Loss_G: 3.3530\n",
            "[3/25][193/782] Loss_D: 0.5881 Loss_G: 3.1048\n",
            "[3/25][194/782] Loss_D: 0.6870 Loss_G: 4.0191\n",
            "[3/25][195/782] Loss_D: 0.6892 Loss_G: 1.9573\n",
            "[3/25][196/782] Loss_D: 0.9636 Loss_G: 6.1157\n",
            "[3/25][197/782] Loss_D: 1.0192 Loss_G: 1.9655\n",
            "[3/25][198/782] Loss_D: 0.8476 Loss_G: 6.1086\n",
            "[3/25][199/782] Loss_D: 0.9985 Loss_G: 1.7778\n",
            "[3/25][200/782] Loss_D: 0.9315 Loss_G: 6.4111\n",
            "[3/25][201/782] Loss_D: 0.7650 Loss_G: 2.2636\n",
            "[3/25][202/782] Loss_D: 0.7576 Loss_G: 5.0604\n",
            "[3/25][203/782] Loss_D: 0.6955 Loss_G: 2.3666\n",
            "[3/25][204/782] Loss_D: 0.7998 Loss_G: 4.2454\n",
            "[3/25][205/782] Loss_D: 0.9095 Loss_G: 2.1264\n",
            "[3/25][206/782] Loss_D: 0.6279 Loss_G: 3.7248\n",
            "[3/25][207/782] Loss_D: 0.6481 Loss_G: 3.2457\n",
            "[3/25][208/782] Loss_D: 0.3695 Loss_G: 3.2449\n",
            "[3/25][209/782] Loss_D: 0.4533 Loss_G: 3.0612\n",
            "[3/25][210/782] Loss_D: 0.7202 Loss_G: 1.6338\n",
            "[3/25][211/782] Loss_D: 0.8221 Loss_G: 5.7413\n",
            "[3/25][212/782] Loss_D: 1.1805 Loss_G: 1.5053\n",
            "[3/25][213/782] Loss_D: 0.6559 Loss_G: 4.5285\n",
            "[3/25][214/782] Loss_D: 0.3970 Loss_G: 3.2066\n",
            "[3/25][215/782] Loss_D: 0.5550 Loss_G: 1.9682\n",
            "[3/25][216/782] Loss_D: 0.5317 Loss_G: 3.7656\n",
            "[3/25][217/782] Loss_D: 0.5394 Loss_G: 4.1092\n",
            "[3/25][218/782] Loss_D: 0.9113 Loss_G: 1.5483\n",
            "[3/25][219/782] Loss_D: 0.9459 Loss_G: 4.5737\n",
            "[3/25][220/782] Loss_D: 0.9429 Loss_G: 1.5628\n",
            "[3/25][221/782] Loss_D: 0.9749 Loss_G: 5.0873\n",
            "[3/25][222/782] Loss_D: 0.4633 Loss_G: 3.6039\n",
            "[3/25][223/782] Loss_D: 0.3784 Loss_G: 2.2925\n",
            "[3/25][224/782] Loss_D: 0.3990 Loss_G: 3.5037\n",
            "[3/25][225/782] Loss_D: 0.6618 Loss_G: 2.7352\n",
            "[3/25][226/782] Loss_D: 0.3485 Loss_G: 3.8802\n",
            "[3/25][227/782] Loss_D: 0.6660 Loss_G: 1.9561\n",
            "[3/25][228/782] Loss_D: 0.4837 Loss_G: 3.0343\n",
            "[3/25][229/782] Loss_D: 0.5835 Loss_G: 3.0484\n",
            "[3/25][230/782] Loss_D: 0.4802 Loss_G: 3.3196\n",
            "[3/25][231/782] Loss_D: 0.4392 Loss_G: 2.0388\n",
            "[3/25][232/782] Loss_D: 0.7067 Loss_G: 4.7718\n",
            "[3/25][233/782] Loss_D: 0.7519 Loss_G: 2.1965\n",
            "[3/25][234/782] Loss_D: 0.6510 Loss_G: 4.2758\n",
            "[3/25][235/782] Loss_D: 0.5822 Loss_G: 2.2262\n",
            "[3/25][236/782] Loss_D: 0.4920 Loss_G: 3.9718\n",
            "[3/25][237/782] Loss_D: 0.4386 Loss_G: 3.1431\n",
            "[3/25][238/782] Loss_D: 0.6032 Loss_G: 1.8212\n",
            "[3/25][239/782] Loss_D: 0.6924 Loss_G: 4.8738\n",
            "[3/25][240/782] Loss_D: 1.1658 Loss_G: 1.4502\n",
            "[3/25][241/782] Loss_D: 0.9839 Loss_G: 6.1594\n",
            "[3/25][242/782] Loss_D: 1.4263 Loss_G: 1.3810\n",
            "[3/25][243/782] Loss_D: 0.8015 Loss_G: 4.4024\n",
            "[3/25][244/782] Loss_D: 0.2682 Loss_G: 4.2873\n",
            "[3/25][245/782] Loss_D: 0.6134 Loss_G: 2.0260\n",
            "[3/25][246/782] Loss_D: 0.9530 Loss_G: 4.9659\n",
            "[3/25][247/782] Loss_D: 0.5470 Loss_G: 2.9704\n",
            "[3/25][248/782] Loss_D: 0.7171 Loss_G: 2.3627\n",
            "[3/25][249/782] Loss_D: 0.4445 Loss_G: 4.0312\n",
            "[3/25][250/782] Loss_D: 0.4706 Loss_G: 3.2029\n",
            "[3/25][251/782] Loss_D: 0.3049 Loss_G: 2.9898\n",
            "[3/25][252/782] Loss_D: 0.4593 Loss_G: 3.9654\n",
            "[3/25][253/782] Loss_D: 0.5628 Loss_G: 3.2540\n",
            "[3/25][254/782] Loss_D: 0.6003 Loss_G: 2.3813\n",
            "[3/25][255/782] Loss_D: 0.4995 Loss_G: 3.5370\n",
            "[3/25][256/782] Loss_D: 0.4419 Loss_G: 2.7669\n",
            "[3/25][257/782] Loss_D: 0.6861 Loss_G: 4.7501\n",
            "[3/25][258/782] Loss_D: 1.0021 Loss_G: 1.3534\n",
            "[3/25][259/782] Loss_D: 0.5824 Loss_G: 4.4640\n",
            "[3/25][260/782] Loss_D: 0.2644 Loss_G: 3.8017\n",
            "[3/25][261/782] Loss_D: 0.3003 Loss_G: 2.9407\n",
            "[3/25][262/782] Loss_D: 0.3604 Loss_G: 3.4174\n",
            "[3/25][263/782] Loss_D: 0.3029 Loss_G: 3.5790\n",
            "[3/25][264/782] Loss_D: 0.3567 Loss_G: 2.8446\n",
            "[3/25][265/782] Loss_D: 0.5208 Loss_G: 3.4904\n",
            "[3/25][266/782] Loss_D: 0.6178 Loss_G: 2.1169\n",
            "[3/25][267/782] Loss_D: 0.7485 Loss_G: 4.5799\n",
            "[3/25][268/782] Loss_D: 0.5586 Loss_G: 1.9083\n",
            "[3/25][269/782] Loss_D: 0.5020 Loss_G: 4.3027\n",
            "[3/25][270/782] Loss_D: 0.3543 Loss_G: 2.8392\n",
            "[3/25][271/782] Loss_D: 0.4054 Loss_G: 3.9462\n",
            "[3/25][272/782] Loss_D: 0.2574 Loss_G: 3.2582\n",
            "[3/25][273/782] Loss_D: 0.3048 Loss_G: 3.5190\n",
            "[3/25][274/782] Loss_D: 0.3229 Loss_G: 3.5634\n",
            "[3/25][275/782] Loss_D: 0.2891 Loss_G: 3.0896\n",
            "[3/25][276/782] Loss_D: 0.7803 Loss_G: 5.3105\n",
            "[3/25][277/782] Loss_D: 0.9275 Loss_G: 1.6592\n",
            "[3/25][278/782] Loss_D: 0.9159 Loss_G: 6.9109\n",
            "[3/25][279/782] Loss_D: 2.5914 Loss_G: 0.3664\n",
            "[3/25][280/782] Loss_D: 1.6447 Loss_G: 6.5900\n",
            "[3/25][281/782] Loss_D: 1.1521 Loss_G: 0.6281\n",
            "[3/25][282/782] Loss_D: 1.8369 Loss_G: 8.1821\n",
            "[3/25][283/782] Loss_D: 1.8179 Loss_G: 1.7659\n",
            "[3/25][284/782] Loss_D: 1.3451 Loss_G: 5.4330\n",
            "[3/25][285/782] Loss_D: 0.7252 Loss_G: 2.6114\n",
            "[3/25][286/782] Loss_D: 1.7439 Loss_G: 6.1689\n",
            "[3/25][287/782] Loss_D: 1.8460 Loss_G: 1.0288\n",
            "[3/25][288/782] Loss_D: 1.6494 Loss_G: 6.4467\n",
            "[3/25][289/782] Loss_D: 1.4940 Loss_G: 1.2918\n",
            "[3/25][290/782] Loss_D: 1.4073 Loss_G: 4.5643\n",
            "[3/25][291/782] Loss_D: 0.9003 Loss_G: 2.4748\n",
            "[3/25][292/782] Loss_D: 0.7321 Loss_G: 2.7831\n",
            "[3/25][293/782] Loss_D: 0.8861 Loss_G: 2.6296\n",
            "[3/25][294/782] Loss_D: 0.8233 Loss_G: 3.8814\n",
            "[3/25][295/782] Loss_D: 0.9191 Loss_G: 1.3436\n",
            "[3/25][296/782] Loss_D: 1.5964 Loss_G: 6.1874\n",
            "[3/25][297/782] Loss_D: 1.8417 Loss_G: 1.6832\n",
            "[3/25][298/782] Loss_D: 1.0294 Loss_G: 4.9944\n",
            "[3/25][299/782] Loss_D: 0.8797 Loss_G: 2.0821\n",
            "[3/25][300/782] Loss_D: 0.9454 Loss_G: 3.5867\n",
            "[3/25][301/782] Loss_D: 0.7108 Loss_G: 2.9975\n",
            "[3/25][302/782] Loss_D: 0.6906 Loss_G: 4.3910\n",
            "[3/25][303/782] Loss_D: 0.8631 Loss_G: 1.9347\n",
            "[3/25][304/782] Loss_D: 0.8410 Loss_G: 4.7980\n",
            "[3/25][305/782] Loss_D: 0.9166 Loss_G: 2.0607\n",
            "[3/25][306/782] Loss_D: 0.9423 Loss_G: 4.4294\n",
            "[3/25][307/782] Loss_D: 0.5419 Loss_G: 3.1820\n",
            "[3/25][308/782] Loss_D: 0.5925 Loss_G: 2.2312\n",
            "[3/25][309/782] Loss_D: 0.6824 Loss_G: 3.9728\n",
            "[3/25][310/782] Loss_D: 0.5679 Loss_G: 2.9196\n",
            "[3/25][311/782] Loss_D: 0.5378 Loss_G: 4.2369\n",
            "[3/25][312/782] Loss_D: 0.4562 Loss_G: 3.2285\n",
            "[3/25][313/782] Loss_D: 0.5506 Loss_G: 2.3610\n",
            "[3/25][314/782] Loss_D: 0.4355 Loss_G: 4.0828\n",
            "[3/25][315/782] Loss_D: 0.3244 Loss_G: 3.7423\n",
            "[3/25][316/782] Loss_D: 0.6098 Loss_G: 2.3335\n",
            "[3/25][317/782] Loss_D: 0.3833 Loss_G: 3.5788\n",
            "[3/25][318/782] Loss_D: 0.3679 Loss_G: 3.5316\n",
            "[3/25][319/782] Loss_D: 0.4794 Loss_G: 2.8876\n",
            "[3/25][320/782] Loss_D: 0.4733 Loss_G: 2.3792\n",
            "[3/25][321/782] Loss_D: 0.6653 Loss_G: 3.5398\n",
            "[3/25][322/782] Loss_D: 0.4930 Loss_G: 2.8160\n",
            "[3/25][323/782] Loss_D: 0.5539 Loss_G: 4.9164\n",
            "[3/25][324/782] Loss_D: 0.8438 Loss_G: 1.5773\n",
            "[3/25][325/782] Loss_D: 0.8226 Loss_G: 5.2606\n",
            "[3/25][326/782] Loss_D: 0.6245 Loss_G: 2.3336\n",
            "[3/25][327/782] Loss_D: 0.6536 Loss_G: 4.0527\n",
            "[3/25][328/782] Loss_D: 0.6847 Loss_G: 1.9774\n",
            "[3/25][329/782] Loss_D: 0.6122 Loss_G: 4.3732\n",
            "[3/25][330/782] Loss_D: 0.5655 Loss_G: 2.3969\n",
            "[3/25][331/782] Loss_D: 0.5640 Loss_G: 4.1495\n",
            "[3/25][332/782] Loss_D: 0.3254 Loss_G: 3.5492\n",
            "[3/25][333/782] Loss_D: 0.4267 Loss_G: 2.2204\n",
            "[3/25][334/782] Loss_D: 0.5725 Loss_G: 4.6930\n",
            "[3/25][335/782] Loss_D: 0.5309 Loss_G: 2.7834\n",
            "[3/25][336/782] Loss_D: 0.3141 Loss_G: 3.1151\n",
            "[3/25][337/782] Loss_D: 0.2934 Loss_G: 3.3619\n",
            "[3/25][338/782] Loss_D: 0.3109 Loss_G: 3.3647\n",
            "[3/25][339/782] Loss_D: 0.2976 Loss_G: 3.5421\n",
            "[3/25][340/782] Loss_D: 0.3400 Loss_G: 3.3292\n",
            "[3/25][341/782] Loss_D: 0.2477 Loss_G: 3.1744\n",
            "[3/25][342/782] Loss_D: 0.3337 Loss_G: 4.4295\n",
            "[3/25][343/782] Loss_D: 0.3621 Loss_G: 3.1957\n",
            "[3/25][344/782] Loss_D: 0.3404 Loss_G: 3.6750\n",
            "[3/25][345/782] Loss_D: 0.2597 Loss_G: 3.4702\n",
            "[3/25][346/782] Loss_D: 0.4523 Loss_G: 2.4350\n",
            "[3/25][347/782] Loss_D: 0.3405 Loss_G: 4.4633\n",
            "[3/25][348/782] Loss_D: 0.4436 Loss_G: 2.3192\n",
            "[3/25][349/782] Loss_D: 0.3975 Loss_G: 5.0643\n",
            "[3/25][350/782] Loss_D: 0.3552 Loss_G: 3.2241\n",
            "[3/25][351/782] Loss_D: 0.2886 Loss_G: 3.7101\n",
            "[3/25][352/782] Loss_D: 0.4606 Loss_G: 2.8229\n",
            "[3/25][353/782] Loss_D: 0.3496 Loss_G: 5.0854\n",
            "[3/25][354/782] Loss_D: 0.3203 Loss_G: 3.1118\n",
            "[3/25][355/782] Loss_D: 0.2868 Loss_G: 3.4931\n",
            "[3/25][356/782] Loss_D: 0.5426 Loss_G: 5.3287\n",
            "[3/25][357/782] Loss_D: 0.8938 Loss_G: 1.6891\n",
            "[3/25][358/782] Loss_D: 0.7345 Loss_G: 7.0716\n",
            "[3/25][359/782] Loss_D: 3.0597 Loss_G: 0.0533\n",
            "[3/25][360/782] Loss_D: 4.1171 Loss_G: 6.1782\n",
            "[3/25][361/782] Loss_D: 1.6891 Loss_G: 0.8694\n",
            "[3/25][362/782] Loss_D: 1.5166 Loss_G: 6.4256\n",
            "[3/25][363/782] Loss_D: 1.3401 Loss_G: 2.4323\n",
            "[3/25][364/782] Loss_D: 0.7254 Loss_G: 2.8887\n",
            "[3/25][365/782] Loss_D: 1.2297 Loss_G: 4.4844\n",
            "[3/25][366/782] Loss_D: 1.1492 Loss_G: 1.2855\n",
            "[3/25][367/782] Loss_D: 1.2314 Loss_G: 5.2243\n",
            "[3/25][368/782] Loss_D: 0.8773 Loss_G: 2.8643\n",
            "[3/25][369/782] Loss_D: 0.5108 Loss_G: 3.3556\n",
            "[3/25][370/782] Loss_D: 0.4147 Loss_G: 3.0384\n",
            "[3/25][371/782] Loss_D: 0.6158 Loss_G: 4.5346\n",
            "[3/25][372/782] Loss_D: 0.8987 Loss_G: 1.2760\n",
            "[3/25][373/782] Loss_D: 1.2547 Loss_G: 6.3039\n",
            "[3/25][374/782] Loss_D: 1.6108 Loss_G: 1.8498\n",
            "[3/25][375/782] Loss_D: 1.1276 Loss_G: 4.7285\n",
            "[3/25][376/782] Loss_D: 1.1652 Loss_G: 1.6003\n",
            "[3/25][377/782] Loss_D: 0.8406 Loss_G: 3.9624\n",
            "[3/25][378/782] Loss_D: 0.6542 Loss_G: 3.6190\n",
            "[3/25][379/782] Loss_D: 0.7791 Loss_G: 1.5225\n",
            "[3/25][380/782] Loss_D: 0.8080 Loss_G: 4.4845\n",
            "[3/25][381/782] Loss_D: 0.5870 Loss_G: 2.7280\n",
            "[3/25][382/782] Loss_D: 0.4490 Loss_G: 3.2652\n",
            "[3/25][383/782] Loss_D: 0.6167 Loss_G: 2.4205\n",
            "[3/25][384/782] Loss_D: 0.7302 Loss_G: 5.4045\n",
            "[3/25][385/782] Loss_D: 0.7599 Loss_G: 2.7438\n",
            "[3/25][386/782] Loss_D: 0.5489 Loss_G: 2.9244\n",
            "[3/25][387/782] Loss_D: 0.6912 Loss_G: 3.7875\n",
            "[3/25][388/782] Loss_D: 0.6493 Loss_G: 2.1537\n",
            "[3/25][389/782] Loss_D: 1.0187 Loss_G: 6.3019\n",
            "[3/25][390/782] Loss_D: 2.0415 Loss_G: 1.4103\n",
            "[3/25][391/782] Loss_D: 1.5484 Loss_G: 6.6291\n",
            "[3/25][392/782] Loss_D: 2.8983 Loss_G: 0.4674\n",
            "[3/25][393/782] Loss_D: 2.1607 Loss_G: 4.9602\n",
            "[3/25][394/782] Loss_D: 1.2595 Loss_G: 0.8689\n",
            "[3/25][395/782] Loss_D: 1.6056 Loss_G: 5.5040\n",
            "[3/25][396/782] Loss_D: 0.9852 Loss_G: 2.8114\n",
            "[3/25][397/782] Loss_D: 0.6739 Loss_G: 1.8522\n",
            "[3/25][398/782] Loss_D: 1.6353 Loss_G: 3.4326\n",
            "[3/25][399/782] Loss_D: 1.6124 Loss_G: 1.6350\n",
            "[3/25][400/782] Loss_D: 1.2381 Loss_G: 2.8600\n",
            "[3/25][401/782] Loss_D: 1.0660 Loss_G: 1.4065\n",
            "[3/25][402/782] Loss_D: 1.7196 Loss_G: 3.5970\n",
            "[3/25][403/782] Loss_D: 0.8421 Loss_G: 2.8109\n",
            "[3/25][404/782] Loss_D: 1.0547 Loss_G: 1.9889\n",
            "[3/25][405/782] Loss_D: 0.9536 Loss_G: 2.3968\n",
            "[3/25][406/782] Loss_D: 0.7382 Loss_G: 3.0159\n",
            "[3/25][407/782] Loss_D: 0.6282 Loss_G: 4.0371\n",
            "[3/25][408/782] Loss_D: 0.9841 Loss_G: 1.7967\n",
            "[3/25][409/782] Loss_D: 0.6998 Loss_G: 3.7972\n",
            "[3/25][410/782] Loss_D: 0.6265 Loss_G: 3.2191\n",
            "[3/25][411/782] Loss_D: 0.6742 Loss_G: 1.9980\n",
            "[3/25][412/782] Loss_D: 0.8741 Loss_G: 4.4373\n",
            "[3/25][413/782] Loss_D: 0.5029 Loss_G: 3.6386\n",
            "[3/25][414/782] Loss_D: 0.2966 Loss_G: 2.7639\n",
            "[3/25][415/782] Loss_D: 0.5869 Loss_G: 3.7137\n",
            "[3/25][416/782] Loss_D: 0.4970 Loss_G: 2.6820\n",
            "[3/25][417/782] Loss_D: 0.3540 Loss_G: 2.8278\n",
            "[3/25][418/782] Loss_D: 0.4507 Loss_G: 3.6061\n",
            "[3/25][419/782] Loss_D: 0.3754 Loss_G: 3.0674\n",
            "[3/25][420/782] Loss_D: 0.4829 Loss_G: 3.2474\n",
            "[3/25][421/782] Loss_D: 0.5013 Loss_G: 2.6068\n",
            "[3/25][422/782] Loss_D: 0.5175 Loss_G: 2.8153\n",
            "[3/25][423/782] Loss_D: 0.4132 Loss_G: 2.5877\n",
            "[3/25][424/782] Loss_D: 0.5142 Loss_G: 3.6728\n",
            "[3/25][425/782] Loss_D: 0.4052 Loss_G: 3.0921\n",
            "[3/25][426/782] Loss_D: 0.4159 Loss_G: 2.9343\n",
            "[3/25][427/782] Loss_D: 0.4891 Loss_G: 3.0122\n",
            "[3/25][428/782] Loss_D: 0.4402 Loss_G: 4.2362\n",
            "[3/25][429/782] Loss_D: 0.5145 Loss_G: 2.7706\n",
            "[3/25][430/782] Loss_D: 0.4006 Loss_G: 3.2151\n",
            "[3/25][431/782] Loss_D: 0.4927 Loss_G: 4.1124\n",
            "[3/25][432/782] Loss_D: 0.8061 Loss_G: 1.6367\n",
            "[3/25][433/782] Loss_D: 0.7999 Loss_G: 6.3215\n",
            "[3/25][434/782] Loss_D: 1.9337 Loss_G: 0.3974\n",
            "[3/25][435/782] Loss_D: 1.8318 Loss_G: 6.7597\n",
            "[3/25][436/782] Loss_D: 1.5376 Loss_G: 2.4718\n",
            "[3/25][437/782] Loss_D: 0.7329 Loss_G: 2.6490\n",
            "[3/25][438/782] Loss_D: 0.6513 Loss_G: 3.6688\n",
            "[3/25][439/782] Loss_D: 1.1269 Loss_G: 1.6528\n",
            "[3/25][440/782] Loss_D: 1.0778 Loss_G: 5.1372\n",
            "[3/25][441/782] Loss_D: 1.1012 Loss_G: 2.1933\n",
            "[3/25][442/782] Loss_D: 0.5767 Loss_G: 2.3479\n",
            "[3/25][443/782] Loss_D: 0.8230 Loss_G: 4.1953\n",
            "[3/25][444/782] Loss_D: 0.7701 Loss_G: 2.1653\n",
            "[3/25][445/782] Loss_D: 0.3904 Loss_G: 2.6648\n",
            "[3/25][446/782] Loss_D: 0.3782 Loss_G: 3.5910\n",
            "[3/25][447/782] Loss_D: 0.4869 Loss_G: 2.9698\n",
            "[3/25][448/782] Loss_D: 0.3324 Loss_G: 2.5548\n",
            "[3/25][449/782] Loss_D: 0.5367 Loss_G: 2.6618\n",
            "[3/25][450/782] Loss_D: 0.4668 Loss_G: 3.6560\n",
            "[3/25][451/782] Loss_D: 0.5601 Loss_G: 2.1422\n",
            "[3/25][452/782] Loss_D: 0.3965 Loss_G: 2.5765\n",
            "[3/25][453/782] Loss_D: 0.8234 Loss_G: 4.6632\n",
            "[3/25][454/782] Loss_D: 1.2350 Loss_G: 1.2922\n",
            "[3/25][455/782] Loss_D: 0.9715 Loss_G: 4.2648\n",
            "[3/25][456/782] Loss_D: 0.6893 Loss_G: 1.9974\n",
            "[3/25][457/782] Loss_D: 0.6651 Loss_G: 3.7802\n",
            "[3/25][458/782] Loss_D: 0.3515 Loss_G: 3.3264\n",
            "[3/25][459/782] Loss_D: 0.3440 Loss_G: 2.2662\n",
            "[3/25][460/782] Loss_D: 0.5815 Loss_G: 3.8825\n",
            "[3/25][461/782] Loss_D: 0.5027 Loss_G: 2.7922\n",
            "[3/25][462/782] Loss_D: 0.4083 Loss_G: 2.6350\n",
            "[3/25][463/782] Loss_D: 0.2490 Loss_G: 3.5869\n",
            "[3/25][464/782] Loss_D: 0.3702 Loss_G: 3.3753\n",
            "[3/25][465/782] Loss_D: 0.3267 Loss_G: 3.0488\n",
            "[3/25][466/782] Loss_D: 0.3608 Loss_G: 4.3882\n",
            "[3/25][467/782] Loss_D: 0.4934 Loss_G: 2.3961\n",
            "[3/25][468/782] Loss_D: 0.3629 Loss_G: 3.5763\n",
            "[3/25][469/782] Loss_D: 0.3849 Loss_G: 4.4845\n",
            "[3/25][470/782] Loss_D: 0.5504 Loss_G: 2.1932\n",
            "[3/25][471/782] Loss_D: 0.1368 Loss_G: 3.1896\n",
            "[3/25][472/782] Loss_D: 0.1567 Loss_G: 3.6750\n",
            "[3/25][473/782] Loss_D: 0.4056 Loss_G: 4.9650\n",
            "[3/25][474/782] Loss_D: 0.5464 Loss_G: 2.8591\n",
            "[3/25][475/782] Loss_D: 0.1972 Loss_G: 2.5941\n",
            "[3/25][476/782] Loss_D: 0.8208 Loss_G: 6.3504\n",
            "[3/25][477/782] Loss_D: 1.3235 Loss_G: 2.6178\n",
            "[3/25][478/782] Loss_D: 0.6162 Loss_G: 4.9401\n",
            "[3/25][479/782] Loss_D: 1.1064 Loss_G: 0.4058\n",
            "[3/25][480/782] Loss_D: 1.9698 Loss_G: 6.2463\n",
            "[3/25][481/782] Loss_D: 0.3924 Loss_G: 4.8421\n",
            "[3/25][482/782] Loss_D: 0.2778 Loss_G: 2.9541\n",
            "[3/25][483/782] Loss_D: 0.4353 Loss_G: 3.7226\n",
            "[3/25][484/782] Loss_D: 0.4544 Loss_G: 3.0767\n",
            "[3/25][485/782] Loss_D: 0.5349 Loss_G: 3.2004\n",
            "[3/25][486/782] Loss_D: 0.8841 Loss_G: 2.1126\n",
            "[3/25][487/782] Loss_D: 0.6019 Loss_G: 4.5593\n",
            "[3/25][488/782] Loss_D: 0.8649 Loss_G: 1.5137\n",
            "[3/25][489/782] Loss_D: 0.9025 Loss_G: 5.6963\n",
            "[3/25][490/782] Loss_D: 0.9049 Loss_G: 1.8635\n",
            "[3/25][491/782] Loss_D: 0.4620 Loss_G: 3.7853\n",
            "[3/25][492/782] Loss_D: 0.5082 Loss_G: 4.7796\n",
            "[3/25][493/782] Loss_D: 0.7268 Loss_G: 2.0902\n",
            "[3/25][494/782] Loss_D: 0.8504 Loss_G: 4.6144\n",
            "[3/25][495/782] Loss_D: 0.7530 Loss_G: 1.7936\n",
            "[3/25][496/782] Loss_D: 0.5920 Loss_G: 4.2950\n",
            "[3/25][497/782] Loss_D: 0.2559 Loss_G: 3.7891\n",
            "[3/25][498/782] Loss_D: 0.5384 Loss_G: 2.0214\n",
            "[3/25][499/782] Loss_D: 0.4024 Loss_G: 4.3967\n",
            "[3/25][500/782] Loss_D: 0.2375 Loss_G: 4.2552\n",
            "[3/25][501/782] Loss_D: 0.4758 Loss_G: 2.3669\n",
            "[3/25][502/782] Loss_D: 0.4469 Loss_G: 5.1767\n",
            "[3/25][503/782] Loss_D: 0.8127 Loss_G: 1.8535\n",
            "[3/25][504/782] Loss_D: 0.5996 Loss_G: 4.9786\n",
            "[3/25][505/782] Loss_D: 0.9309 Loss_G: 1.2230\n",
            "[3/25][506/782] Loss_D: 0.7100 Loss_G: 5.5008\n",
            "[3/25][507/782] Loss_D: 0.2732 Loss_G: 4.0823\n",
            "[3/25][508/782] Loss_D: 0.3619 Loss_G: 2.3580\n",
            "[3/25][509/782] Loss_D: 0.4508 Loss_G: 4.7119\n",
            "[3/25][510/782] Loss_D: 0.3071 Loss_G: 4.6270\n",
            "[3/25][511/782] Loss_D: 0.3585 Loss_G: 2.7956\n",
            "[3/25][512/782] Loss_D: 0.5519 Loss_G: 4.3370\n",
            "[3/25][513/782] Loss_D: 0.5740 Loss_G: 3.2022\n",
            "[3/25][514/782] Loss_D: 0.3981 Loss_G: 4.8846\n",
            "[3/25][515/782] Loss_D: 0.6606 Loss_G: 2.1416\n",
            "[3/25][516/782] Loss_D: 0.6719 Loss_G: 6.1467\n",
            "[3/25][517/782] Loss_D: 0.9259 Loss_G: 2.1638\n",
            "[3/25][518/782] Loss_D: 0.7128 Loss_G: 6.2523\n",
            "[3/25][519/782] Loss_D: 0.7298 Loss_G: 2.0227\n",
            "[3/25][520/782] Loss_D: 0.9490 Loss_G: 6.1495\n",
            "[3/25][521/782] Loss_D: 0.3729 Loss_G: 4.6813\n",
            "[3/25][522/782] Loss_D: 0.4933 Loss_G: 2.0066\n",
            "[3/25][523/782] Loss_D: 0.6413 Loss_G: 5.2005\n",
            "[3/25][524/782] Loss_D: 0.9475 Loss_G: 1.4965\n",
            "[3/25][525/782] Loss_D: 0.8566 Loss_G: 6.1251\n",
            "[3/25][526/782] Loss_D: 0.5993 Loss_G: 2.2337\n",
            "[3/25][527/782] Loss_D: 0.4028 Loss_G: 2.7917\n",
            "[3/25][528/782] Loss_D: 0.6744 Loss_G: 6.6823\n",
            "[3/25][529/782] Loss_D: 1.7284 Loss_G: 1.9925\n",
            "[3/25][530/782] Loss_D: 0.9479 Loss_G: 5.6408\n",
            "[3/25][531/782] Loss_D: 1.3394 Loss_G: 0.9134\n",
            "[3/25][532/782] Loss_D: 0.9974 Loss_G: 5.7216\n",
            "[3/25][533/782] Loss_D: 0.7762 Loss_G: 2.6328\n",
            "[3/25][534/782] Loss_D: 0.4291 Loss_G: 4.5506\n",
            "[3/25][535/782] Loss_D: 0.2827 Loss_G: 3.6818\n",
            "[3/25][536/782] Loss_D: 0.4006 Loss_G: 2.6518\n",
            "[3/25][537/782] Loss_D: 0.5310 Loss_G: 3.5988\n",
            "[3/25][538/782] Loss_D: 0.4941 Loss_G: 3.2867\n",
            "[3/25][539/782] Loss_D: 0.5720 Loss_G: 2.3820\n",
            "[3/25][540/782] Loss_D: 0.5379 Loss_G: 4.2477\n",
            "[3/25][541/782] Loss_D: 0.6680 Loss_G: 2.0156\n",
            "[3/25][542/782] Loss_D: 0.7589 Loss_G: 5.1929\n",
            "[3/25][543/782] Loss_D: 0.5137 Loss_G: 3.2107\n",
            "[3/25][544/782] Loss_D: 0.2474 Loss_G: 2.8508\n",
            "[3/25][545/782] Loss_D: 0.1728 Loss_G: 3.4901\n",
            "[3/25][546/782] Loss_D: 0.4304 Loss_G: 4.3630\n",
            "[3/25][547/782] Loss_D: 0.2698 Loss_G: 4.1129\n",
            "[3/25][548/782] Loss_D: 0.3330 Loss_G: 3.4282\n",
            "[3/25][549/782] Loss_D: 0.2351 Loss_G: 3.4084\n",
            "[3/25][550/782] Loss_D: 0.2637 Loss_G: 2.9122\n",
            "[3/25][551/782] Loss_D: 0.3705 Loss_G: 4.2654\n",
            "[3/25][552/782] Loss_D: 0.4143 Loss_G: 2.8839\n",
            "[3/25][553/782] Loss_D: 0.1873 Loss_G: 3.2534\n",
            "[3/25][554/782] Loss_D: 0.1879 Loss_G: 3.9166\n",
            "[3/25][555/782] Loss_D: 0.3277 Loss_G: 3.5544\n",
            "[3/25][556/782] Loss_D: 0.1743 Loss_G: 3.7523\n",
            "[3/25][557/782] Loss_D: 0.4274 Loss_G: 2.6723\n",
            "[3/25][558/782] Loss_D: 0.2113 Loss_G: 3.6032\n",
            "[3/25][559/782] Loss_D: 0.2817 Loss_G: 2.8526\n",
            "[3/25][560/782] Loss_D: 0.3484 Loss_G: 5.0167\n",
            "[3/25][561/782] Loss_D: 0.2512 Loss_G: 4.3943\n",
            "[3/25][562/782] Loss_D: 0.2191 Loss_G: 3.2779\n",
            "[3/25][563/782] Loss_D: 0.3560 Loss_G: 3.4771\n",
            "[3/25][564/782] Loss_D: 0.1482 Loss_G: 4.1600\n",
            "[3/25][565/782] Loss_D: 0.2303 Loss_G: 4.2240\n",
            "[3/25][566/782] Loss_D: 0.2207 Loss_G: 3.8606\n",
            "[3/25][567/782] Loss_D: 0.2638 Loss_G: 3.1294\n",
            "[3/25][568/782] Loss_D: 0.1216 Loss_G: 3.7194\n",
            "[3/25][569/782] Loss_D: 0.3267 Loss_G: 6.2686\n",
            "[3/25][570/782] Loss_D: 0.5994 Loss_G: 3.4664\n",
            "[3/25][571/782] Loss_D: 0.3520 Loss_G: 3.5477\n",
            "[3/25][572/782] Loss_D: 0.2897 Loss_G: 1.9233\n",
            "[3/25][573/782] Loss_D: 0.2874 Loss_G: 5.8388\n",
            "[3/25][574/782] Loss_D: 0.1841 Loss_G: 4.4582\n",
            "[3/25][575/782] Loss_D: 0.1608 Loss_G: 3.1591\n",
            "[3/25][576/782] Loss_D: 0.0791 Loss_G: 3.8092\n",
            "[3/25][577/782] Loss_D: 0.1382 Loss_G: 4.6674\n",
            "[3/25][578/782] Loss_D: 0.1325 Loss_G: 4.0680\n",
            "[3/25][579/782] Loss_D: 0.1286 Loss_G: 3.7073\n",
            "[3/25][580/782] Loss_D: 0.2274 Loss_G: 5.0812\n",
            "[3/25][581/782] Loss_D: 0.2535 Loss_G: 3.6508\n",
            "[3/25][582/782] Loss_D: 0.0915 Loss_G: 3.4577\n",
            "[3/25][583/782] Loss_D: 0.2670 Loss_G: 4.6069\n",
            "[3/25][584/782] Loss_D: 0.4626 Loss_G: 2.4592\n",
            "[3/25][585/782] Loss_D: 0.4956 Loss_G: 5.9009\n",
            "[3/25][586/782] Loss_D: 0.2325 Loss_G: 4.4992\n",
            "[3/25][587/782] Loss_D: 0.0933 Loss_G: 3.7535\n",
            "[3/25][588/782] Loss_D: 0.1318 Loss_G: 3.9026\n",
            "[3/25][589/782] Loss_D: 0.0795 Loss_G: 4.2430\n",
            "[3/25][590/782] Loss_D: 0.1563 Loss_G: 4.5242\n",
            "[3/25][591/782] Loss_D: 0.0732 Loss_G: 4.9865\n",
            "[3/25][592/782] Loss_D: 0.1963 Loss_G: 4.6710\n",
            "[3/25][593/782] Loss_D: 0.2266 Loss_G: 4.0005\n",
            "[3/25][594/782] Loss_D: 0.2772 Loss_G: 5.8094\n",
            "[3/25][595/782] Loss_D: 0.2632 Loss_G: 4.1358\n",
            "[3/25][596/782] Loss_D: 0.1091 Loss_G: 3.6247\n",
            "[3/25][597/782] Loss_D: 0.1438 Loss_G: 4.6884\n",
            "[3/25][598/782] Loss_D: 0.1698 Loss_G: 4.4871\n",
            "[3/25][599/782] Loss_D: 0.0770 Loss_G: 4.4427\n",
            "[3/25][600/782] Loss_D: 0.0877 Loss_G: 3.9840\n",
            "[3/25][601/782] Loss_D: 0.0862 Loss_G: 3.9889\n",
            "[3/25][602/782] Loss_D: 0.1250 Loss_G: 3.7486\n",
            "[3/25][603/782] Loss_D: 0.1839 Loss_G: 5.3409\n",
            "[3/25][604/782] Loss_D: 0.1295 Loss_G: 4.8010\n",
            "[3/25][605/782] Loss_D: 0.2852 Loss_G: 2.3698\n",
            "[3/25][606/782] Loss_D: 0.2785 Loss_G: 4.9669\n",
            "[3/25][607/782] Loss_D: 0.1581 Loss_G: 4.3111\n",
            "[3/25][608/782] Loss_D: 0.1268 Loss_G: 3.2989\n",
            "[3/25][609/782] Loss_D: 0.1158 Loss_G: 3.8575\n",
            "[3/25][610/782] Loss_D: 0.0826 Loss_G: 4.0267\n",
            "[3/25][611/782] Loss_D: 0.2631 Loss_G: 6.3229\n",
            "[3/25][612/782] Loss_D: 0.5318 Loss_G: 3.3446\n",
            "[3/25][613/782] Loss_D: 0.3487 Loss_G: 5.5539\n",
            "[3/25][614/782] Loss_D: 0.6634 Loss_G: 0.6819\n",
            "[3/25][615/782] Loss_D: 2.4160 Loss_G: 13.1969\n",
            "[3/25][616/782] Loss_D: 6.8391 Loss_G: 1.7470\n",
            "[3/25][617/782] Loss_D: 0.6177 Loss_G: 3.0623\n",
            "[3/25][618/782] Loss_D: 0.6940 Loss_G: 5.8458\n",
            "[3/25][619/782] Loss_D: 2.8418 Loss_G: 0.1081\n",
            "[3/25][620/782] Loss_D: 3.2879 Loss_G: 5.1179\n",
            "[3/25][621/782] Loss_D: 1.4563 Loss_G: 2.1963\n",
            "[3/25][622/782] Loss_D: 1.2593 Loss_G: 3.0452\n",
            "[3/25][623/782] Loss_D: 0.9437 Loss_G: 2.9900\n",
            "[3/25][624/782] Loss_D: 1.1969 Loss_G: 1.7007\n",
            "[3/25][625/782] Loss_D: 0.8391 Loss_G: 5.6127\n",
            "[3/25][626/782] Loss_D: 1.1450 Loss_G: 1.9848\n",
            "[3/25][627/782] Loss_D: 0.8124 Loss_G: 4.6498\n",
            "[3/25][628/782] Loss_D: 0.3380 Loss_G: 4.0195\n",
            "[3/25][629/782] Loss_D: 0.8649 Loss_G: 1.6817\n",
            "[3/25][630/782] Loss_D: 0.5975 Loss_G: 4.2868\n",
            "[3/25][631/782] Loss_D: 0.2540 Loss_G: 4.5720\n",
            "[3/25][632/782] Loss_D: 0.5295 Loss_G: 2.5402\n",
            "[3/25][633/782] Loss_D: 0.5047 Loss_G: 3.3430\n",
            "[3/25][634/782] Loss_D: 0.2735 Loss_G: 3.9870\n",
            "[3/25][635/782] Loss_D: 0.2411 Loss_G: 3.5560\n",
            "[3/25][636/782] Loss_D: 0.4814 Loss_G: 2.1914\n",
            "[3/25][637/782] Loss_D: 0.7268 Loss_G: 3.5779\n",
            "[3/25][638/782] Loss_D: 0.3699 Loss_G: 3.5545\n",
            "[3/25][639/782] Loss_D: 0.5784 Loss_G: 2.5925\n",
            "[3/25][640/782] Loss_D: 0.5010 Loss_G: 5.3609\n",
            "[3/25][641/782] Loss_D: 0.3811 Loss_G: 3.6878\n",
            "[3/25][642/782] Loss_D: 0.1736 Loss_G: 3.0144\n",
            "[3/25][643/782] Loss_D: 0.2963 Loss_G: 4.2561\n",
            "[3/25][644/782] Loss_D: 0.2246 Loss_G: 4.9442\n",
            "[3/25][645/782] Loss_D: 0.5399 Loss_G: 2.3078\n",
            "[3/25][646/782] Loss_D: 0.8446 Loss_G: 6.8317\n",
            "[3/25][647/782] Loss_D: 1.6163 Loss_G: 3.1594\n",
            "[3/25][648/782] Loss_D: 0.4371 Loss_G: 5.1698\n",
            "[3/25][649/782] Loss_D: 0.8058 Loss_G: 0.6337\n",
            "[3/25][650/782] Loss_D: 3.0937 Loss_G: 9.5964\n",
            "[3/25][651/782] Loss_D: 6.1003 Loss_G: 2.3016\n",
            "[3/25][652/782] Loss_D: 1.3960 Loss_G: 0.6514\n",
            "[3/25][653/782] Loss_D: 2.4628 Loss_G: 3.5331\n",
            "[3/25][654/782] Loss_D: 2.1138 Loss_G: 1.1764\n",
            "[3/25][655/782] Loss_D: 1.2797 Loss_G: 2.6916\n",
            "[3/25][656/782] Loss_D: 0.9747 Loss_G: 3.2567\n",
            "[3/25][657/782] Loss_D: 1.0657 Loss_G: 1.2123\n",
            "[3/25][658/782] Loss_D: 1.5532 Loss_G: 2.5144\n",
            "[3/25][659/782] Loss_D: 1.0489 Loss_G: 2.4707\n",
            "[3/25][660/782] Loss_D: 1.0665 Loss_G: 1.2543\n",
            "[3/25][661/782] Loss_D: 1.1960 Loss_G: 3.7434\n",
            "[3/25][662/782] Loss_D: 1.0895 Loss_G: 1.8272\n",
            "[3/25][663/782] Loss_D: 0.7647 Loss_G: 2.5784\n",
            "[3/25][664/782] Loss_D: 1.1512 Loss_G: 2.9901\n",
            "[3/25][665/782] Loss_D: 0.8229 Loss_G: 1.9809\n",
            "[3/25][666/782] Loss_D: 1.0179 Loss_G: 2.1140\n",
            "[3/25][667/782] Loss_D: 1.0492 Loss_G: 2.6163\n",
            "[3/25][668/782] Loss_D: 0.7649 Loss_G: 2.3547\n",
            "[3/25][669/782] Loss_D: 0.6587 Loss_G: 2.7617\n",
            "[3/25][670/782] Loss_D: 0.6659 Loss_G: 3.7293\n",
            "[3/25][671/782] Loss_D: 1.0230 Loss_G: 1.4508\n",
            "[3/25][672/782] Loss_D: 1.5094 Loss_G: 4.5686\n",
            "[3/25][673/782] Loss_D: 1.7941 Loss_G: 1.2517\n",
            "[3/25][674/782] Loss_D: 1.3895 Loss_G: 3.0349\n",
            "[3/25][675/782] Loss_D: 0.7429 Loss_G: 2.3133\n",
            "[3/25][676/782] Loss_D: 0.6947 Loss_G: 3.3205\n",
            "[3/25][677/782] Loss_D: 0.6966 Loss_G: 2.3485\n",
            "[3/25][678/782] Loss_D: 0.9233 Loss_G: 1.9057\n",
            "[3/25][679/782] Loss_D: 0.9363 Loss_G: 3.0037\n",
            "[3/25][680/782] Loss_D: 0.9363 Loss_G: 2.4762\n",
            "[3/25][681/782] Loss_D: 0.8396 Loss_G: 1.9758\n",
            "[3/25][682/782] Loss_D: 0.7185 Loss_G: 2.7366\n",
            "[3/25][683/782] Loss_D: 0.5180 Loss_G: 2.5273\n",
            "[3/25][684/782] Loss_D: 0.4726 Loss_G: 2.7249\n",
            "[3/25][685/782] Loss_D: 0.5678 Loss_G: 2.5334\n",
            "[3/25][686/782] Loss_D: 0.6523 Loss_G: 1.9100\n",
            "[3/25][687/782] Loss_D: 0.7411 Loss_G: 3.8284\n",
            "[3/25][688/782] Loss_D: 0.5824 Loss_G: 2.4533\n",
            "[3/25][689/782] Loss_D: 0.4590 Loss_G: 2.5417\n",
            "[3/25][690/782] Loss_D: 0.7368 Loss_G: 3.4543\n",
            "[3/25][691/782] Loss_D: 0.3741 Loss_G: 3.5006\n",
            "[3/25][692/782] Loss_D: 0.5061 Loss_G: 2.5410\n",
            "[3/25][693/782] Loss_D: 0.3455 Loss_G: 3.4368\n",
            "[3/25][694/782] Loss_D: 0.2860 Loss_G: 3.7211\n",
            "[3/25][695/782] Loss_D: 0.4796 Loss_G: 1.9795\n",
            "[3/25][696/782] Loss_D: 0.8106 Loss_G: 5.6699\n",
            "[3/25][697/782] Loss_D: 0.6421 Loss_G: 3.3728\n",
            "[3/25][698/782] Loss_D: 0.2095 Loss_G: 3.0728\n",
            "[3/25][699/782] Loss_D: 0.2928 Loss_G: 3.5311\n",
            "[3/25][700/782] Loss_D: 0.3094 Loss_G: 3.1102\n",
            "[3/25][701/782] Loss_D: 0.5808 Loss_G: 2.5176\n",
            "[3/25][702/782] Loss_D: 0.6074 Loss_G: 5.9131\n",
            "[3/25][703/782] Loss_D: 1.4195 Loss_G: 1.7592\n",
            "[3/25][704/782] Loss_D: 0.9569 Loss_G: 5.9344\n",
            "[3/25][705/782] Loss_D: 1.2031 Loss_G: 0.8034\n",
            "[3/25][706/782] Loss_D: 1.6612 Loss_G: 6.2864\n",
            "[3/25][707/782] Loss_D: 0.9325 Loss_G: 1.1856\n",
            "[3/25][708/782] Loss_D: 2.1661 Loss_G: 6.6294\n",
            "[3/25][709/782] Loss_D: 2.1443 Loss_G: 1.6794\n",
            "[3/25][710/782] Loss_D: 1.1478 Loss_G: 2.9346\n",
            "[3/25][711/782] Loss_D: 1.5614 Loss_G: 3.5410\n",
            "[3/25][712/782] Loss_D: 1.3435 Loss_G: 2.1982\n",
            "[3/25][713/782] Loss_D: 1.2086 Loss_G: 2.2400\n",
            "[3/25][714/782] Loss_D: 1.3845 Loss_G: 4.7575\n",
            "[3/25][715/782] Loss_D: 1.7664 Loss_G: 0.6618\n",
            "[3/25][716/782] Loss_D: 2.4314 Loss_G: 4.7450\n",
            "[3/25][717/782] Loss_D: 0.9446 Loss_G: 2.4491\n",
            "[3/25][718/782] Loss_D: 0.5056 Loss_G: 3.4168\n",
            "[3/25][719/782] Loss_D: 0.4045 Loss_G: 3.2301\n",
            "[3/25][720/782] Loss_D: 0.7128 Loss_G: 3.6531\n",
            "[3/25][721/782] Loss_D: 0.4662 Loss_G: 3.2172\n",
            "[3/25][722/782] Loss_D: 0.5903 Loss_G: 2.1407\n",
            "[3/25][723/782] Loss_D: 0.6219 Loss_G: 3.6213\n",
            "[3/25][724/782] Loss_D: 0.6252 Loss_G: 2.4752\n",
            "[3/25][725/782] Loss_D: 0.4469 Loss_G: 3.5813\n",
            "[3/25][726/782] Loss_D: 0.3097 Loss_G: 3.5677\n",
            "[3/25][727/782] Loss_D: 0.4118 Loss_G: 2.7651\n",
            "[3/25][728/782] Loss_D: 0.5916 Loss_G: 3.5741\n",
            "[3/25][729/782] Loss_D: 0.6333 Loss_G: 2.2230\n",
            "[3/25][730/782] Loss_D: 0.7076 Loss_G: 3.6561\n",
            "[3/25][731/782] Loss_D: 0.3557 Loss_G: 3.9119\n",
            "[3/25][732/782] Loss_D: 0.3713 Loss_G: 2.7044\n",
            "[3/25][733/782] Loss_D: 0.4901 Loss_G: 3.2774\n",
            "[3/25][734/782] Loss_D: 0.3020 Loss_G: 3.6651\n",
            "[3/25][735/782] Loss_D: 0.2789 Loss_G: 3.0467\n",
            "[3/25][736/782] Loss_D: 0.3665 Loss_G: 2.3290\n",
            "[3/25][737/782] Loss_D: 0.5948 Loss_G: 5.7806\n",
            "[3/25][738/782] Loss_D: 0.6117 Loss_G: 2.8899\n",
            "[3/25][739/782] Loss_D: 0.2768 Loss_G: 2.9975\n",
            "[3/25][740/782] Loss_D: 0.2656 Loss_G: 4.5958\n",
            "[3/25][741/782] Loss_D: 0.4625 Loss_G: 2.7961\n",
            "[3/25][742/782] Loss_D: 0.4436 Loss_G: 5.3910\n",
            "[3/25][743/782] Loss_D: 0.6135 Loss_G: 1.7065\n",
            "[3/25][744/782] Loss_D: 0.5819 Loss_G: 5.8806\n",
            "[3/25][745/782] Loss_D: 0.8987 Loss_G: 1.5755\n",
            "[3/25][746/782] Loss_D: 0.7476 Loss_G: 7.5000\n",
            "[3/25][747/782] Loss_D: 2.8870 Loss_G: 0.2566\n",
            "[3/25][748/782] Loss_D: 2.3403 Loss_G: 6.5200\n",
            "[3/25][749/782] Loss_D: 0.5811 Loss_G: 3.7563\n",
            "[3/25][750/782] Loss_D: 0.2723 Loss_G: 2.5033\n",
            "[3/25][751/782] Loss_D: 0.6390 Loss_G: 5.4349\n",
            "[3/25][752/782] Loss_D: 0.8991 Loss_G: 1.6687\n",
            "[3/25][753/782] Loss_D: 0.7251 Loss_G: 3.3006\n",
            "[3/25][754/782] Loss_D: 0.4960 Loss_G: 3.7196\n",
            "[3/25][755/782] Loss_D: 0.7238 Loss_G: 2.4811\n",
            "[3/25][756/782] Loss_D: 0.3946 Loss_G: 4.9854\n",
            "[3/25][757/782] Loss_D: 0.6081 Loss_G: 1.9184\n",
            "[3/25][758/782] Loss_D: 0.5759 Loss_G: 5.3954\n",
            "[3/25][759/782] Loss_D: 0.7344 Loss_G: 1.9757\n",
            "[3/25][760/782] Loss_D: 0.5436 Loss_G: 4.4905\n",
            "[3/25][761/782] Loss_D: 0.3983 Loss_G: 3.2480\n",
            "[3/25][762/782] Loss_D: 0.3528 Loss_G: 2.4043\n",
            "[3/25][763/782] Loss_D: 0.2983 Loss_G: 4.7785\n",
            "[3/25][764/782] Loss_D: 0.2390 Loss_G: 4.1117\n",
            "[3/25][765/782] Loss_D: 0.2775 Loss_G: 3.0195\n",
            "[3/25][766/782] Loss_D: 0.5773 Loss_G: 5.5113\n",
            "[3/25][767/782] Loss_D: 0.6777 Loss_G: 3.1389\n",
            "[3/25][768/782] Loss_D: 0.2046 Loss_G: 3.2221\n",
            "[3/25][769/782] Loss_D: 0.2796 Loss_G: 2.8848\n",
            "[3/25][770/782] Loss_D: 0.4760 Loss_G: 5.2130\n",
            "[3/25][771/782] Loss_D: 0.3335 Loss_G: 3.6703\n",
            "[3/25][772/782] Loss_D: 0.2057 Loss_G: 3.3187\n",
            "[3/25][773/782] Loss_D: 0.3429 Loss_G: 4.6398\n",
            "[3/25][774/782] Loss_D: 0.4399 Loss_G: 3.8655\n",
            "[3/25][775/782] Loss_D: 0.3459 Loss_G: 4.9380\n",
            "[3/25][776/782] Loss_D: 0.7829 Loss_G: 1.9303\n",
            "[3/25][777/782] Loss_D: 0.5933 Loss_G: 5.5874\n",
            "[3/25][778/782] Loss_D: 0.7384 Loss_G: 0.9341\n",
            "[3/25][779/782] Loss_D: 1.2780 Loss_G: 6.7746\n",
            "[3/25][780/782] Loss_D: 0.7099 Loss_G: 4.4672\n",
            "[3/25][781/782] Loss_D: 0.2772 Loss_G: 4.6080\n",
            "[4/25][0/782] Loss_D: 0.4257 Loss_G: 3.5141\n",
            "[4/25][1/782] Loss_D: 0.8731 Loss_G: 2.6666\n",
            "[4/25][2/782] Loss_D: 0.9304 Loss_G: 9.0259\n",
            "[4/25][3/782] Loss_D: 1.4906 Loss_G: 5.1099\n",
            "[4/25][4/782] Loss_D: 0.0730 Loss_G: 2.4860\n",
            "[4/25][5/782] Loss_D: 0.7127 Loss_G: 6.7980\n",
            "[4/25][6/782] Loss_D: 0.4986 Loss_G: 3.5194\n",
            "[4/25][7/782] Loss_D: 0.5268 Loss_G: 4.3491\n",
            "[4/25][8/782] Loss_D: 0.3203 Loss_G: 3.9898\n",
            "[4/25][9/782] Loss_D: 0.3173 Loss_G: 3.2169\n",
            "[4/25][10/782] Loss_D: 0.4492 Loss_G: 4.4808\n",
            "[4/25][11/782] Loss_D: 0.6019 Loss_G: 3.0087\n",
            "[4/25][12/782] Loss_D: 0.2866 Loss_G: 3.7776\n",
            "[4/25][13/782] Loss_D: 0.2902 Loss_G: 4.5271\n",
            "[4/25][14/782] Loss_D: 0.2869 Loss_G: 3.5592\n",
            "[4/25][15/782] Loss_D: 0.2189 Loss_G: 3.3131\n",
            "[4/25][16/782] Loss_D: 0.2779 Loss_G: 4.2207\n",
            "[4/25][17/782] Loss_D: 0.2844 Loss_G: 4.7183\n",
            "[4/25][18/782] Loss_D: 0.9171 Loss_G: 0.9295\n",
            "[4/25][19/782] Loss_D: 1.5205 Loss_G: 7.5713\n",
            "[4/25][20/782] Loss_D: 2.3180 Loss_G: 2.4853\n",
            "[4/25][21/782] Loss_D: 1.3686 Loss_G: 8.2161\n",
            "[4/25][22/782] Loss_D: 3.7180 Loss_G: 0.4594\n",
            "[4/25][23/782] Loss_D: 2.1945 Loss_G: 4.7455\n",
            "[4/25][24/782] Loss_D: 1.1497 Loss_G: 2.3743\n",
            "[4/25][25/782] Loss_D: 1.3669 Loss_G: 1.8834\n",
            "[4/25][26/782] Loss_D: 0.7089 Loss_G: 3.5286\n",
            "[4/25][27/782] Loss_D: 0.6582 Loss_G: 2.6322\n",
            "[4/25][28/782] Loss_D: 1.0037 Loss_G: 3.2907\n",
            "[4/25][29/782] Loss_D: 0.7190 Loss_G: 2.4388\n",
            "[4/25][30/782] Loss_D: 1.0340 Loss_G: 4.5950\n",
            "[4/25][31/782] Loss_D: 0.9790 Loss_G: 2.1570\n",
            "[4/25][32/782] Loss_D: 1.0164 Loss_G: 4.5815\n",
            "[4/25][33/782] Loss_D: 0.8250 Loss_G: 1.7650\n",
            "[4/25][34/782] Loss_D: 1.0463 Loss_G: 6.0263\n",
            "[4/25][35/782] Loss_D: 0.4041 Loss_G: 4.5675\n",
            "[4/25][36/782] Loss_D: 0.1954 Loss_G: 3.4262\n",
            "[4/25][37/782] Loss_D: 0.3583 Loss_G: 3.7379\n",
            "[4/25][38/782] Loss_D: 0.5489 Loss_G: 2.7387\n",
            "[4/25][39/782] Loss_D: 0.2557 Loss_G: 4.3375\n",
            "[4/25][40/782] Loss_D: 0.6664 Loss_G: 4.3153\n",
            "[4/25][41/782] Loss_D: 0.6605 Loss_G: 2.0693\n",
            "[4/25][42/782] Loss_D: 0.7681 Loss_G: 5.2746\n",
            "[4/25][43/782] Loss_D: 1.0266 Loss_G: 1.9709\n",
            "[4/25][44/782] Loss_D: 0.7327 Loss_G: 5.0035\n",
            "[4/25][45/782] Loss_D: 0.3203 Loss_G: 4.3819\n",
            "[4/25][46/782] Loss_D: 0.1202 Loss_G: 3.5884\n",
            "[4/25][47/782] Loss_D: 0.1265 Loss_G: 4.0330\n",
            "[4/25][48/782] Loss_D: 0.1666 Loss_G: 3.8867\n",
            "[4/25][49/782] Loss_D: 0.1814 Loss_G: 3.7413\n",
            "[4/25][50/782] Loss_D: 0.3652 Loss_G: 5.2306\n",
            "[4/25][51/782] Loss_D: 0.4129 Loss_G: 3.4989\n",
            "[4/25][52/782] Loss_D: 0.1599 Loss_G: 2.7531\n",
            "[4/25][53/782] Loss_D: 0.3091 Loss_G: 4.1805\n",
            "[4/25][54/782] Loss_D: 0.2048 Loss_G: 3.7187\n",
            "[4/25][55/782] Loss_D: 0.2300 Loss_G: 3.1716\n",
            "[4/25][56/782] Loss_D: 0.4113 Loss_G: 5.2916\n",
            "[4/25][57/782] Loss_D: 0.4375 Loss_G: 3.0095\n",
            "[4/25][58/782] Loss_D: 0.1636 Loss_G: 2.7076\n",
            "[4/25][59/782] Loss_D: 0.8281 Loss_G: 7.9879\n",
            "[4/25][60/782] Loss_D: 2.4979 Loss_G: 3.4071\n",
            "[4/25][61/782] Loss_D: 0.6999 Loss_G: 0.1513\n",
            "[4/25][62/782] Loss_D: 2.6583 Loss_G: 8.4666\n",
            "[4/25][63/782] Loss_D: 4.3341 Loss_G: 1.0690\n",
            "[4/25][64/782] Loss_D: 0.8912 Loss_G: 1.7284\n",
            "[4/25][65/782] Loss_D: 1.1182 Loss_G: 4.7858\n",
            "[4/25][66/782] Loss_D: 1.2791 Loss_G: 1.9175\n",
            "[4/25][67/782] Loss_D: 0.8607 Loss_G: 1.9855\n",
            "[4/25][68/782] Loss_D: 0.8822 Loss_G: 3.9160\n",
            "[4/25][69/782] Loss_D: 0.8917 Loss_G: 2.1202\n",
            "[4/25][70/782] Loss_D: 1.1386 Loss_G: 4.2554\n",
            "[4/25][71/782] Loss_D: 1.4034 Loss_G: 1.2462\n",
            "[4/25][72/782] Loss_D: 1.2612 Loss_G: 2.9555\n",
            "[4/25][73/782] Loss_D: 1.3098 Loss_G: 1.8408\n",
            "[4/25][74/782] Loss_D: 0.9264 Loss_G: 3.7097\n",
            "[4/25][75/782] Loss_D: 1.0875 Loss_G: 1.4700\n",
            "[4/25][76/782] Loss_D: 0.8204 Loss_G: 3.8878\n",
            "[4/25][77/782] Loss_D: 0.7786 Loss_G: 2.7852\n",
            "[4/25][78/782] Loss_D: 1.0257 Loss_G: 1.2936\n",
            "[4/25][79/782] Loss_D: 1.3250 Loss_G: 4.9044\n",
            "[4/25][80/782] Loss_D: 0.9301 Loss_G: 2.9109\n",
            "[4/25][81/782] Loss_D: 0.3759 Loss_G: 2.8307\n",
            "[4/25][82/782] Loss_D: 0.6089 Loss_G: 4.9108\n",
            "[4/25][83/782] Loss_D: 0.5991 Loss_G: 2.3648\n",
            "[4/25][84/782] Loss_D: 0.5389 Loss_G: 4.2023\n",
            "[4/25][85/782] Loss_D: 0.3108 Loss_G: 3.7128\n",
            "[4/25][86/782] Loss_D: 0.7241 Loss_G: 5.7518\n",
            "[4/25][87/782] Loss_D: 1.0771 Loss_G: 1.7997\n",
            "[4/25][88/782] Loss_D: 1.0969 Loss_G: 6.5213\n",
            "[4/25][89/782] Loss_D: 0.8065 Loss_G: 3.7360\n",
            "[4/25][90/782] Loss_D: 0.2477 Loss_G: 2.5807\n",
            "[4/25][91/782] Loss_D: 0.6138 Loss_G: 4.6263\n",
            "[4/25][92/782] Loss_D: 0.4753 Loss_G: 3.1120\n",
            "[4/25][93/782] Loss_D: 0.6414 Loss_G: 2.9262\n",
            "[4/25][94/782] Loss_D: 0.4874 Loss_G: 2.6934\n",
            "[4/25][95/782] Loss_D: 0.4325 Loss_G: 3.7999\n",
            "[4/25][96/782] Loss_D: 0.2648 Loss_G: 3.7089\n",
            "[4/25][97/782] Loss_D: 0.4893 Loss_G: 4.1286\n",
            "[4/25][98/782] Loss_D: 0.5670 Loss_G: 1.9361\n",
            "[4/25][99/782] Loss_D: 0.8804 Loss_G: 5.2710\n",
            "[4/25][100/782] Loss_D: 0.9004 Loss_G: 2.7131\n",
            "[4/25][101/782] Loss_D: 0.1177 Loss_G: 3.2208\n",
            "[4/25][102/782] Loss_D: 0.6566 Loss_G: 5.9079\n",
            "[4/25][103/782] Loss_D: 0.6818 Loss_G: 3.4306\n",
            "[4/25][104/782] Loss_D: 0.1415 Loss_G: 3.4029\n",
            "[4/25][105/782] Loss_D: 0.2232 Loss_G: 3.5352\n",
            "[4/25][106/782] Loss_D: 0.3481 Loss_G: 3.9065\n",
            "[4/25][107/782] Loss_D: 0.3560 Loss_G: 2.7285\n",
            "[4/25][108/782] Loss_D: 0.2975 Loss_G: 3.8220\n",
            "[4/25][109/782] Loss_D: 0.2735 Loss_G: 3.7042\n",
            "[4/25][110/782] Loss_D: 0.1641 Loss_G: 3.6273\n",
            "[4/25][111/782] Loss_D: 0.2055 Loss_G: 3.7080\n",
            "[4/25][112/782] Loss_D: 0.2493 Loss_G: 3.2728\n",
            "[4/25][113/782] Loss_D: 0.1716 Loss_G: 3.2549\n",
            "[4/25][114/782] Loss_D: 0.4397 Loss_G: 5.0258\n",
            "[4/25][115/782] Loss_D: 0.2729 Loss_G: 4.2391\n",
            "[4/25][116/782] Loss_D: 0.2995 Loss_G: 2.4158\n",
            "[4/25][117/782] Loss_D: 0.1404 Loss_G: 3.3497\n",
            "[4/25][118/782] Loss_D: 0.1617 Loss_G: 3.9760\n",
            "[4/25][119/782] Loss_D: 0.4910 Loss_G: 4.6228\n",
            "[4/25][120/782] Loss_D: 0.2775 Loss_G: 4.0671\n",
            "[4/25][121/782] Loss_D: 0.1425 Loss_G: 3.5871\n",
            "[4/25][122/782] Loss_D: 0.2895 Loss_G: 4.4098\n",
            "[4/25][123/782] Loss_D: 0.1286 Loss_G: 4.3509\n",
            "[4/25][124/782] Loss_D: 0.1948 Loss_G: 3.5648\n",
            "[4/25][125/782] Loss_D: 0.0738 Loss_G: 3.9590\n",
            "[4/25][126/782] Loss_D: 0.0843 Loss_G: 3.8902\n",
            "[4/25][127/782] Loss_D: 0.2075 Loss_G: 4.9047\n",
            "[4/25][128/782] Loss_D: 0.1576 Loss_G: 4.6638\n",
            "[4/25][129/782] Loss_D: 0.1574 Loss_G: 3.4821\n",
            "[4/25][130/782] Loss_D: 0.0817 Loss_G: 3.5270\n",
            "[4/25][131/782] Loss_D: 0.1277 Loss_G: 3.8882\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XFDHgTI_FLol",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}